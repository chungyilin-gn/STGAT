{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm_JdO1Vu4nR",
        "colab_type": "text"
      },
      "source": [
        "## Colab & Drive環境設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tGaekNkUp8_",
        "colab_type": "text"
      },
      "source": [
        "### Drive連結"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnHuSwLjt8yG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e9c21de5-516b-4ac0-c15c-de4ac2cdfb65"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGynxt4w_yNB",
        "colab_type": "text"
      },
      "source": [
        "### 切換路徑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFXiA5d01lx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6120548-78be-41cf-86cc-ed0b3551da95"
      },
      "source": [
        "cd drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po_QpEIAHgTY",
        "colab_type": "text"
      },
      "source": [
        "# 程式碼"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOVacf1YMmcQ",
        "colab_type": "text"
      },
      "source": [
        "## check py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv4-pPxRMl7M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea2f7287-954d-4d25-e0b3-6b3d99b019b5"
      },
      "source": [
        "!ls *.py\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "draw_trajectory.py  __init__.py  models.py  trajectories.py\n",
            "evaluate_model.py   loader.py\t train.py   utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myccGTZdHiy_",
        "colab_type": "text"
      },
      "source": [
        "## 安裝easydict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBPZxBJqGPeh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "13e66793-4c70-480b-a93b-a2f5e8f8dc77"
      },
      "source": [
        "pip install easydict"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement trajectories (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for trajectories\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5hz3HrdRlLR",
        "colab_type": "text"
      },
      "source": [
        "## Train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6y3VbKnSrwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "e3362de9-3363-4c45-c24d-6d6dad8f9fee"
      },
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import utils\n",
        "from loader.py import data_loader\n",
        "from models.py import TrajectoryGenerator\n",
        "from utils.py import (\n",
        "    displacement_error,\n",
        "    final_displacement_error,\n",
        "    get_dset_path,\n",
        "    int_tuple,\n",
        "    l2_loss,\n",
        "    relative_to_abs,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "import easydict\n",
        "args = easydict.EasyDict({\n",
        "        \"log_dir\": \"./\",\n",
        "        \"dataset_name\": \"zara2\",\n",
        "        \"delim\": \"\\t\",\n",
        "        \"loader_num_workers\": 4,\n",
        "        \"obs_len\": 12,\n",
        "        \"skip\": 1,\n",
        "        \"seed\": 72,\n",
        "        \"batch_size\":64,\n",
        "        \"num_epochs\":400,\n",
        "        \"noise_dim\":(16,),\n",
        "        \"noise_type\":\"gaussian\",\n",
        "        \"traj_lstm_input_size\":2,\n",
        "        \"traj_lstm_hidden_size\":32,\n",
        "        \"heads\":\"4,1\",\n",
        "        \"hidden-units\":16,\n",
        "        \"graph_network_out_dims\":32,\n",
        "        \"graph_lstm_hidden_size\":32,\n",
        "        \"dropout\":0,\n",
        "        \"alpha\": 0.2,\n",
        "        \"lr\":1e-3,\n",
        "        \"start-epoch\":0,\n",
        "        \"best_k\":20,\n",
        "        \"print_every\":10,\n",
        "        \"use_gpu\":1,\n",
        "        \"gpu_num\":0,\n",
        "        \"resume\":\"\"\n",
        "\n",
        "\n",
        "\n",
        "})\n",
        "\n",
        "\n",
        "best_ade = 100\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_num\n",
        "    train_path = get_dset_path(args.dataset_name, \"train\")\n",
        "    val_path = get_dset_path(args.dataset_name, \"test\")\n",
        "\n",
        "    logging.info(\"Initializing train dataset\")\n",
        "    train_dset, train_loader = data_loader(args, train_path)\n",
        "    logging.info(\"Initializing val dataset\")\n",
        "    _, val_loader = data_loader(args, val_path)\n",
        "\n",
        "    writer = SummaryWriter()\n",
        "\n",
        "    n_units = (\n",
        "        [args.traj_lstm_hidden_size]\n",
        "        + [int(x) for x in args.hidden_units.strip().split(\",\")]\n",
        "        + [args.graph_lstm_hidden_size]\n",
        "    )\n",
        "    n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n",
        "\n",
        "    model = TrajectoryGenerator(\n",
        "        obs_len=args.obs_len,\n",
        "        pred_len=args.pred_len,\n",
        "        traj_lstm_input_size=args.traj_lstm_input_size,\n",
        "        traj_lstm_hidden_size=args.traj_lstm_hidden_size,\n",
        "        n_units=n_units,\n",
        "        n_heads=n_heads,\n",
        "        graph_network_out_dims=args.graph_network_out_dims,\n",
        "        dropout=args.dropout,\n",
        "        alpha=args.alpha,\n",
        "        graph_lstm_hidden_size=args.graph_lstm_hidden_size,\n",
        "        noise_dim=args.noise_dim,\n",
        "        noise_type=args.noise_type,\n",
        "    )\n",
        "    model.cuda()\n",
        "    optimizer = optim.Adam(\n",
        "        [\n",
        "            {\"params\": model.traj_lstm_model.parameters(), \"lr\": 1e-2},\n",
        "            {\"params\": model.traj_hidden2pos.parameters()},\n",
        "            {\"params\": model.gatencoder.parameters(), \"lr\": 3e-2},\n",
        "            {\"params\": model.graph_lstm_model.parameters(), \"lr\": 1e-2},\n",
        "            {\"params\": model.traj_gat_hidden2pos.parameters()},\n",
        "            {\"params\": model.pred_lstm_model.parameters()},\n",
        "            {\"params\": model.pred_hidden2pos.parameters()},\n",
        "        ],\n",
        "        lr=args.lr,\n",
        "    )\n",
        "    global best_ade\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            logging.info(\"Restoring from checkpoint {}\".format(args.resume))\n",
        "            checkpoint = torch.load(args.resume)\n",
        "            args.start_epoch = checkpoint[\"epoch\"]\n",
        "            model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "            logging.info(\n",
        "                \"=> loaded checkpoint '{}' (epoch {})\".format(\n",
        "                    args.resume, checkpoint[\"epoch\"]\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            logging.info(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
        "\n",
        "    training_step = 1\n",
        "    for epoch in range(args.start_epoch, args.num_epochs + 1):\n",
        "        if epoch < 150:\n",
        "            training_step = 1\n",
        "        elif epoch < 250:\n",
        "            training_step = 2\n",
        "        else:\n",
        "            if epoch == 250:\n",
        "                for param_group in optimizer.param_groups:\n",
        "                    param_group[\"lr\"] = 5e-3\n",
        "            training_step = 3\n",
        "        train(args, model, train_loader, optimizer, epoch, training_step, writer)\n",
        "        if training_step == 3:\n",
        "            ade = validate(args, model, val_loader, epoch, writer)\n",
        "            is_best = ade < best_ade\n",
        "            best_ade = min(ade, best_ade)\n",
        "\n",
        "            save_checkpoint(\n",
        "                {\n",
        "                    \"epoch\": epoch + 1,\n",
        "                    \"state_dict\": model.state_dict(),\n",
        "                    \"best_ade\": best_ade,\n",
        "                    \"optimizer\": optimizer.state_dict(),\n",
        "                },\n",
        "                is_best,\n",
        "                f\"./checkpoint/checkpoint{epoch}.pth.tar\",\n",
        "            )\n",
        "    writer.close()\n",
        "\n",
        "\n",
        "def train(args, model, train_loader, optimizer, epoch, training_step, writer):\n",
        "    losses = utils.AverageMeter(\"Loss\", \":.6f\")\n",
        "    progress = utils.ProgressMeter(\n",
        "        len(train_loader), [losses], prefix=\"Epoch: [{}]\".format(epoch)\n",
        "    )\n",
        "    model.train()\n",
        "    for batch_idx, batch in enumerate(train_loader):\n",
        "        batch = [tensor.cuda() for tensor in batch]\n",
        "        (\n",
        "            obs_traj,\n",
        "            pred_traj_gt,\n",
        "            obs_traj_rel,\n",
        "            pred_traj_gt_rel,\n",
        "            non_linear_ped,\n",
        "            loss_mask,\n",
        "            seq_start_end,\n",
        "        ) = batch\n",
        "        optimizer.zero_grad()\n",
        "        loss = torch.zeros(1).to(pred_traj_gt)\n",
        "        l2_loss_rel = []\n",
        "        loss_mask = loss_mask[:, args.obs_len :]\n",
        "\n",
        "        if training_step == 1 or training_step == 2:\n",
        "            model_input = obs_traj_rel\n",
        "            pred_traj_fake_rel = model(\n",
        "                model_input, obs_traj, seq_start_end, 1, training_step\n",
        "            )\n",
        "            l2_loss_rel.append(\n",
        "                l2_loss(pred_traj_fake_rel, model_input, loss_mask, mode=\"raw\")\n",
        "            )\n",
        "        else:\n",
        "            model_input = torch.cat((obs_traj_rel, pred_traj_gt_rel), dim=0)\n",
        "            for _ in range(args.best_k):\n",
        "                pred_traj_fake_rel = model(model_input, obs_traj, seq_start_end, 0)\n",
        "                l2_loss_rel.append(\n",
        "                    l2_loss(\n",
        "                        pred_traj_fake_rel,\n",
        "                        model_input[-args.pred_len :],\n",
        "                        loss_mask,\n",
        "                        mode=\"raw\",\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
        "        l2_loss_rel = torch.stack(l2_loss_rel, dim=1)\n",
        "        for start, end in seq_start_end.data:\n",
        "            _l2_loss_rel = torch.narrow(l2_loss_rel, 0, start, end - start)\n",
        "            _l2_loss_rel = torch.sum(_l2_loss_rel, dim=0)  # [20]\n",
        "            _l2_loss_rel = torch.min(_l2_loss_rel) / (\n",
        "                (pred_traj_fake_rel.shape[0]) * (end - start)\n",
        "            )\n",
        "            l2_loss_sum_rel += _l2_loss_rel\n",
        "\n",
        "        loss += l2_loss_sum_rel\n",
        "        losses.update(loss.item(), obs_traj.shape[1])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % args.print_every == 0:\n",
        "            progress.display(batch_idx)\n",
        "    writer.add_scalar(\"train_loss\", losses.avg, epoch)\n",
        "\n",
        "\n",
        "def validate(args, model, val_loader, epoch, writer):\n",
        "    ade = utils.AverageMeter(\"ADE\", \":.6f\")\n",
        "    fde = utils.AverageMeter(\"FDE\", \":.6f\")\n",
        "    progress = utils.ProgressMeter(len(val_loader), [ade, fde], prefix=\"Test: \")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(val_loader):\n",
        "            batch = [tensor.cuda() for tensor in batch]\n",
        "            (\n",
        "                obs_traj,\n",
        "                pred_traj_gt,\n",
        "                obs_traj_rel,\n",
        "                pred_traj_gt_rel,\n",
        "                non_linear_ped,\n",
        "                loss_mask,\n",
        "                seq_start_end,\n",
        "            ) = batch\n",
        "            loss_mask = loss_mask[:, args.obs_len :]\n",
        "            pred_traj_fake_rel = model(obs_traj_rel, obs_traj, seq_start_end)\n",
        "\n",
        "            pred_traj_fake_rel_predpart = pred_traj_fake_rel[-args.pred_len :]\n",
        "            pred_traj_fake = relative_to_abs(pred_traj_fake_rel_predpart, obs_traj[-1])\n",
        "            ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n",
        "            ade_ = ade_ / (obs_traj.shape[1] * args.pred_len)\n",
        "\n",
        "            fde_ = fde_ / (obs_traj.shape[1])\n",
        "            ade.update(ade_, obs_traj.shape[1])\n",
        "            fde.update(fde_, obs_traj.shape[1])\n",
        "\n",
        "            if i % args.print_every == 0:\n",
        "                progress.display(i)\n",
        "\n",
        "        logging.info(\n",
        "            \" * ADE  {ade.avg:.3f} FDE  {fde.avg:.3f}\".format(ade=ade, fde=fde)\n",
        "        )\n",
        "        writer.add_scalar(\"val_ade\", ade.avg, epoch)\n",
        "    return ade.avg\n",
        "\n",
        "\n",
        "def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n",
        "    ade = displacement_error(pred_traj_fake, pred_traj_gt)\n",
        "    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1])\n",
        "    return ade, fde\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n",
        "    if is_best:\n",
        "        torch.save(state, filename)\n",
        "        logging.info(\"-------------- lower ade ----------------\")\n",
        "        shutil.copyfile(filename, \"model_best.pth.tar\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #args = parser.parse_args()\n",
        "    utils.set_logger(os.path.join(args.log_dir, \"train.log\"))\n",
        "    checkpoint_dir = \"./checkpoint\"\n",
        "    if os.path.exists(checkpoint_dir) is False:\n",
        "        os.mkdir(checkpoint_dir)\n",
        "    main(args)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4eba6bb9dafa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrajectoryGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m from utils.py import (\n",
            "\u001b[0;32m/content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/loader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrajectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrajectoryDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_collate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trajectories.py'; 'trajectories' is not a package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qZL-4Yl8HvdA"
      },
      "source": [
        "## Evaluate_model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ePhd-x4VHvdA",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import torch\n",
        "\n",
        "from data.loader import data_loader\n",
        "from models import TrajectoryGenerator\n",
        "from utils import (\n",
        "    displacement_error,\n",
        "    final_displacement_error,\n",
        "    l2_loss,\n",
        "    int_tuple,\n",
        "    relative_to_abs,\n",
        "    get_dset_path,\n",
        ")\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--log_dir\", default=\"./\", help=\"Directory containing logging file\")\n",
        "\n",
        "parser.add_argument(\"--dataset_name\", default=\"zara2\", type=str)\n",
        "parser.add_argument(\"--delim\", default=\"\\t\")\n",
        "parser.add_argument(\"--loader_num_workers\", default=4, type=int)\n",
        "parser.add_argument(\"--obs_len\", default=8, type=int)\n",
        "parser.add_argument(\"--pred_len\", default=8, type=int)\n",
        "parser.add_argument(\"--skip\", default=1, type=int)\n",
        "\n",
        "parser.add_argument(\"--seed\", type=int, default=72, help=\"Random seed.\")\n",
        "parser.add_argument(\"--batch_size\", default=64, type=int)\n",
        "\n",
        "parser.add_argument(\"--noise_dim\", default=(16,), type=int_tuple)\n",
        "parser.add_argument(\"--noise_type\", default=\"gaussian\")\n",
        "parser.add_argument(\"--noise_mix_type\", default=\"global\")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--traj_lstm_input_size\", type=int, default=2, help=\"traj_lstm_input_size\"\n",
        ")\n",
        "parser.add_argument(\"--traj_lstm_hidden_size\", default=32, type=int)\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--heads\", type=str, default=\"4,1\", help=\"Heads in each layer, splitted with comma\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--hidden-units\",\n",
        "    type=str,\n",
        "    default=\"16\",\n",
        "    help=\"Hidden units in each hidden layer, splitted with comma\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--graph_network_out_dims\",\n",
        "    type=int,\n",
        "    default=32,\n",
        "    help=\"dims of every node after through GAT module\",\n",
        ")\n",
        "parser.add_argument(\"--graph_lstm_hidden_size\", default=32, type=int)\n",
        "\n",
        "\n",
        "parser.add_argument(\"--num_samples\", default=20, type=int)\n",
        "\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--dropout\", type=float, default=0, help=\"Dropout rate (1 - keep probability).\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--alpha\", type=float, default=0.2, help=\"Alpha for the leaky_relu.\"\n",
        ")\n",
        "\n",
        "parser.add_argument(\"--dset_type\", default=\"test\", type=str)\n",
        "\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--resume\",\n",
        "    default=\"./model_best.pth.tar\",\n",
        "    type=str,\n",
        "    metavar=\"PATH\",\n",
        "    help=\"path to latest checkpoint (default: none)\",\n",
        ")\n",
        "\n",
        "\n",
        "def evaluate_helper(error, seq_start_end):\n",
        "    sum_ = 0\n",
        "    error = torch.stack(error, dim=1)\n",
        "    for (start, end) in seq_start_end:\n",
        "        start = start.item()\n",
        "        end = end.item()\n",
        "        _error = error[start:end]\n",
        "        _error = torch.sum(_error, dim=0)\n",
        "        _error = torch.min(_error)\n",
        "        sum_ += _error\n",
        "    return sum_\n",
        "\n",
        "\n",
        "def get_generator(checkpoint):\n",
        "    n_units = (\n",
        "        [args.traj_lstm_hidden_size]\n",
        "        + [int(x) for x in args.hidden_units.strip().split(\",\")]\n",
        "        + [args.graph_lstm_hidden_size]\n",
        "    )\n",
        "    n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n",
        "    model = TrajectoryGenerator(\n",
        "        obs_len=args.obs_len,\n",
        "        pred_len=args.pred_len,\n",
        "        traj_lstm_input_size=args.traj_lstm_input_size,\n",
        "        traj_lstm_hidden_size=args.traj_lstm_hidden_size,\n",
        "        n_units=n_units,\n",
        "        n_heads=n_heads,\n",
        "        graph_network_out_dims=args.graph_network_out_dims,\n",
        "        dropout=args.dropout,\n",
        "        alpha=args.alpha,\n",
        "        graph_lstm_hidden_size=args.graph_lstm_hidden_size,\n",
        "        noise_dim=args.noise_dim,\n",
        "        noise_type=args.noise_type,\n",
        "    )\n",
        "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
        "    model.cuda()\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n",
        "    ade = displacement_error(pred_traj_fake, pred_traj_gt, mode=\"raw\")\n",
        "    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1], mode=\"raw\")\n",
        "    return ade, fde\n",
        "\n",
        "\n",
        "def evaluate(args, loader, generator):\n",
        "    ade_outer, fde_outer = [], []\n",
        "    total_traj = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = [tensor.cuda() for tensor in batch]\n",
        "            (\n",
        "                obs_traj,\n",
        "                pred_traj_gt,\n",
        "                obs_traj_rel,\n",
        "                pred_traj_gt_rel,\n",
        "                non_linear_ped,\n",
        "                loss_mask,\n",
        "                seq_start_end,\n",
        "            ) = batch\n",
        "\n",
        "            ade, fde = [], []\n",
        "            total_traj += pred_traj_gt.size(1)\n",
        "\n",
        "            for _ in range(args.num_samples):\n",
        "                pred_traj_fake_rel = generator(\n",
        "                    obs_traj_rel, obs_traj, seq_start_end, 0, 3\n",
        "                )\n",
        "                pred_traj_fake_rel = pred_traj_fake_rel[-args.pred_len :]\n",
        "\n",
        "                pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
        "                ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n",
        "                ade.append(ade_)\n",
        "                fde.append(fde_)\n",
        "            ade_sum = evaluate_helper(ade, seq_start_end)\n",
        "            fde_sum = evaluate_helper(fde, seq_start_end)\n",
        "\n",
        "            ade_outer.append(ade_sum)\n",
        "            fde_outer.append(fde_sum)\n",
        "\n",
        "        ade = sum(ade_outer) / (total_traj * args.pred_len)\n",
        "        fde = sum(fde_outer) / (total_traj)\n",
        "        return ade, fde\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    checkpoint = torch.load(args.resume)\n",
        "    generator = get_generator(checkpoint)\n",
        "    path = get_dset_path(args.dataset_name, args.dset_type)\n",
        "\n",
        "    _, loader = data_loader(args, path)\n",
        "    ade, fde = evaluate(args, loader, generator)\n",
        "    print(\n",
        "        \"Dataset: {}, Pred Len: {}, ADE: {:.12f}, FDE: {:.12f}\".format(\n",
        "            args.dataset_name, args.pred_len, ade, fde\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parser.parse_args()\n",
        "    torch.manual_seed(72)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    main(args)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}