{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pytorch_Traj_Lin.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wm_JdO1Vu4nR","colab_type":"text"},"source":["## Colab & Drive環境設定"]},{"cell_type":"markdown","metadata":{"id":"9tGaekNkUp8_","colab_type":"text"},"source":["### Drive連結"]},{"cell_type":"code","metadata":{"id":"qnHuSwLjt8yG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1599317891898,"user_tz":-480,"elapsed":31415,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}},"outputId":"b2fe4ec0-3cd8-4747-ae63-91fb3cfc9c1f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eGynxt4w_yNB","colab_type":"text"},"source":["### 切換路徑\n","\n","\n","\n","```\n","#git clone https://github.com/chungyilin-gn/STGAT.git\n","#cd drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT  \n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"CcMT7shW8anR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599317895043,"user_tz":-480,"elapsed":3121,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}},"outputId":"f0f6a8a5-e4ae-4475-a95a-4a033d315f3f"},"source":["cd drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LrE4h5Aeynaz","colab_type":"text"},"source":["## 主程式"]},{"cell_type":"markdown","metadata":{"id":"Hv5ZIET60oFT","colab_type":"text"},"source":["### Library"]},{"cell_type":"code","metadata":{"id":"Z2xTXVrx0pV8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599318020067,"user_tz":-480,"elapsed":671,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}}},"source":["import argparse\n","import logging\n","import os\n","import random\n","import shutil\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# Model.py #\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import random\n","\n","# Main.py\n","import easydict\n","import time"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BpgkzVkB21ax","colab_type":"text"},"source":["### Utils"]},{"cell_type":"code","metadata":{"id":"_-exGF1V22Tg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599317998838,"user_tz":-480,"elapsed":613,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}}},"source":["import os\n","import logging\n","import torch\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","\n","    def __init__(self, name, fmt=\":f\"):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = \"{name} {val\" + self.fmt + \"} ({avg\" + self.fmt + \"})\"\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def display(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print(\"\\t\".join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = \"{:\" + str(num_digits) + \"d}\"\n","        return \"[\" + fmt + \"/\" + fmt.format(num_batches) + \"]\"\n","\n","\n","def set_logger(log_path):\n","    \"\"\"Set the logger to log info in terminal and file `log_path`.\n","    In general, it is useful to have a logger so that every output to the terminal is saved\n","    in a permanent file. Here we save it to `model_dir/train.log`.\n","    Example:\n","    ```\n","    logging.info(\"Starting training...\")\n","    ```\n","    Args:\n","        log_path: (string) where to log\n","    \"\"\"\n","    logger = logging.getLogger()\n","    logger.setLevel(logging.INFO)\n","\n","    if not logger.handlers:\n","        # Logging to a file\n","        file_handler = logging.FileHandler(log_path)\n","        file_handler.setFormatter(\n","            logging.Formatter(\"%(asctime)s:%(levelname)s: %(message)s\")\n","        )\n","        logger.addHandler(file_handler)\n","\n","        # Logging to console\n","        stream_handler = logging.StreamHandler()\n","        stream_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n","        logger.addHandler(stream_handler)\n","\n","\n","def relative_to_abs(rel_traj, start_pos):\n","    \"\"\"\n","    Inputs:\n","    - rel_traj: pytorch tensor of shape (seq_len, batch, 2)\n","    - start_pos: pytorch tensor of shape (batch, 2)\n","    Outputs:\n","    - abs_traj: pytorch tensor of shape (seq_len, batch, 2)\n","    \"\"\"\n","    # batch, seq_len, 2\n","    rel_traj = rel_traj.permute(1, 0, 2)\n","    displacement = torch.cumsum(rel_traj, dim=1)\n","    start_pos = torch.unsqueeze(start_pos, dim=1)\n","    abs_traj = displacement + start_pos\n","    return abs_traj.permute(1, 0, 2)\n","\n","\n","def get_dset_path(dset_name, dset_type):\n","    #_dir = os.path.dirname(__file__)\n","    # _dir = _dir.split(\"/\")[:-1]\n","    # _dir = \"/\".join(_dir)\n","    _dir = \"STGAT\"\n","\n","    print('<Utils/line:106>', 'datasets:',dset_name,dset_type)\n","\n","    return os.path.join(_dir, \"datasets\", dset_name, dset_type)\n","\n","\n","def int_tuple(s):\n","    return tuple(int(i) for i in s.split(\",\"))\n","\n","\n","def l2_loss(pred_traj, pred_traj_gt, loss_mask, random=0, mode=\"average\"):\n","\n","    \"\"\"\n","    Input:\n","    - pred_traj: Tensor of shape (seq_len, batch, 2). Predicted trajectory.\n","    - pred_traj_gt: Tensor of shape (seq_len, batch, 2). Groud truth\n","    predictions.\n","    - loss_mask: Tensor of shape (batch, seq_len)\n","    - mode: Can be one of sum, average, raw\n","    Output:\n","    - loss: l2 loss depending on mode\n","    \"\"\"\n","    seq_len, batch, _ = pred_traj.size()  #torch.Size([8, *164, 2])\n","    # equation below , the first part do noing, can be delete\n","\n","    # torch.Size([8, *164, 2]) -- (permute(1, 0, 2)) -> torch.Size([*164, 8, 2])\n","    loss = (pred_traj_gt.permute(1, 0, 2) - pred_traj.permute(1, 0, 2)) ** 2   \n","    \n","    if mode == \"sum\":\n","        return torch.sum(loss)\n","    elif mode == \"average\":\n","        return torch.sum(loss) / torch.numel(loss_mask.data)\n","    elif mode == \"raw\":\n","        return loss.sum(dim=2).sum(dim=1)  # 先dim=2加總(x,y軸誤差), 再將dim=1加總(各time-step誤差)\n","\n","def displacement_error(pred_traj, pred_traj_gt, consider_ped=None, mode=\"sum\"):\n","    \"\"\"\n","    Input:\n","    - pred_traj: Tensor of shape (seq_len, batch, 2). Predicted trajectory. [12, person_num, 2]\n","    - pred_traj_gt: Tensor of shape (seq_len, batch, 2). Ground truth\n","    predictions.\n","    - consider_ped: Tensor of shape (batch)\n","    - mode: Can be one of sum, raw\n","    Output:\n","    - loss: gives the eculidian displacement error\n","    \"\"\"\n","\n","    seq_len, _, _ = pred_traj.size()\n","    loss = pred_traj_gt.permute(1, 0, 2) - pred_traj.permute(1, 0, 2)\n","\n","    loss = loss ** 2\n","    if consider_ped is not None:\n","        loss = torch.sqrt(loss.sum(dim=2)).sum(dim=1) * consider_ped\n","    else:\n","        loss = torch.sqrt(loss.sum(dim=2)).sum(dim=1)\n","    if mode == \"sum\":\n","        return torch.sum(loss)\n","    elif mode == \"mean\":\n","        return torch.mean(loss)\n","    elif mode == \"raw\":\n","        return loss\n","\n","\n","def final_displacement_error(pred_pos, pred_pos_gt, consider_ped=None, mode=\"sum\"):\n","    \"\"\"\n","    Input:\n","    - pred_pos: Tensor of shape (batch, 2). Predicted last pos.\n","    - pred_pos_gt: Tensor of shape (seq_len, batch, 2). Groud truth\n","    last pos\n","    - consider_ped: Tensor of shape (batch)\n","    Output:\n","    - loss: gives the eculidian displacement error\n","    \"\"\"\n","\n","    loss = pred_pos_gt - pred_pos\n","    loss = loss ** 2\n","    if consider_ped is not None:\n","        loss = torch.sqrt(loss.sum(dim=1)) * consider_ped\n","    else:\n","        loss = torch.sqrt(loss.sum(dim=1))\n","    if mode == \"raw\":\n","        return loss\n","    else:\n","        return torch.sum(loss)"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VVcEBkHezU5U","colab_type":"text"},"source":["### Dataset\n","\n","\n","\n","```\n","初始化時動作(init()):\n","for each file:\n","\t\t檔案格式轉換: \n","\t\t[\n","\t\t\t[<frame_id_1> <ped_id> <x> <y>], \n","\t\t\t[<frame_id_2> <ped_id> <x> <y>], \n","\t\t\t...\n","\t\t]\n","\t\t=> 依照frame id合併\n","\t\t[ \n","\t\t\tarray([[780.  ,   1.  ,   8.46,   3.59]]), \n","\t\t\tarray([[790.  ,   1.  ,   9.57,   3.79]]), \n","\t\t\tarray([[800.  ,   1.  ,  10.67,   3.99], [800.  ,   2.  ,  13.64,   5.8 ]]), \n","\t\t\tarray([[810.  ,   1.  ,  11.73,   4.32], [810.  ,   2.  ,  12.09,   5.75]])\n","\t\t\t...\n","\t\t]\n","\n","\t\tfor 每次取20(seq_len)個array並concatenate:\n","\t\t\t        curr_seq_data =   \n","\t\t\t\t\t[         \n","\t\t\t\t\t\t[ 7.800e+02  1.000e+00  8.460e+00  3.590e+00]\n","\t\t\t\t\t\t[ 7.900e+02  1.000e+00  9.570e+00  3.790e+00]\n","\t\t\t\t\t\t[ 8.000e+02  1.000e+00  1.067e+01  3.990e+00]\n","\t\t\t\t\t\t[ 8.000e+02  2.000e+00  1.364e+01  5.800e+00]\n","\t\t\t\t\t\t[ 8.100e+02  1.000e+00  1.173e+01  4.320e+00]\n","\t\t\t\t\t\t[ 8.100e+02  2.000e+00  1.209e+01  5.750e+00]\n","\t\t\t\t\t\t...\n","\t\t\t\t\t\t[ 9.700e+02  7.000e+00  6.860e+00  5.830e+00]\n","\t\t\t\t\t\t[ 9.700e+02  8.000e+00 -9.300e-01  9.600e-01]\n","\t\t\t\t\t]\n","\n","\t\t\t\t\tfor 唯一行人id的位置資料 in curr_seq_data:\n","\t\t\t\t\t\t\tcurr_ped_seq[]= \n","\t\t\t\t\t\t\t[\n","\t\t\t\t\t\t\t\t[780.     1.     8.46   3.59]\n","\t\t\t\t\t\t\t\t[790.     1.     9.57   3.79]\n","\t\t\t\t\t\t\t\t[800.     1.    10.67   3.99]\n","\t\t\t\t\t\t\t\t[810.     1.    11.73   4.32]\n","\t\t\t\t\t\t\t\t[820.     1.    12.81   4.61]\n","\t\t\t\t\t\t\t]\n","\t\t\t\t\t\t\t若id的軌跡長度不足seq_len:\n","\t\t\t\t\t\t\t\t\tcontinute;\n","\n","\t\t\t\t\t\t\t若長度大於seq_len:\n","\t\t\t\t\t\t\t\t\ttraj: transpose to :(2, 20);\n","\t\t\t\t\t\t\t\t\ttraj_rel: 計算relative position;\n","\t\t\t\t\t\t\t\t\tseq_list.append(traj) # (n_traj, 2, 20)\n","\t\t\t\t\t\t\t\t\tseq_list.append(traj_rel) # (n_traj, 2, 20)\n","\n","__getitem__():\n","out = [\n","\tself.obs_traj[start:end, :],      # (n,2,8)\n","\tself.pred_traj[start:end, :],     # (n,2,12)\n","\t...\n","]\n","\n","seq_collate():\n","[\n","\t[\n","\t\tself.obs_traj[start_1:end_1, :],      # (n_1,2,8)\n","\t\tself.pred_traj[start_1:end_2, :],     # (n_1,2,12)\n","\t\t...\n","\t],\n","\t[\n","\t\tself.obs_traj[start_2:end_2, :],      # (n_2,2,8)\n","\t\tself.pred_traj[start_2:end_2, :],     # (n_2,2,12)\n","\t\t...\n","\t]\n","\t...\n","\t#64\n","]\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"rXR7OCKwyoaO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599318001971,"user_tz":-480,"elapsed":911,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}}},"source":["import logging\n","import os\n","import math\n","from IPython import embed\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","def seq_collate(data):\n","    '''\n","    [\n","      [\n","          self.obs_traj[start_1:end_1, :],      # (n_1,2,8)\n","          self.pred_traj[start_1:end_2, :],     # (n_1,2,12)\n","          ...\n","      ],\n","      [\n","          self.obs_traj[start_2:end_2, :],      # (n_2,2,8)\n","          self.pred_traj[start_2:end_2, :],     # (n_2,2,12)\n","          ...\n","      ]\n","      ...#64\n","    ]\n","    =>\n","    zip(*data):\n","    (\n","      [\n","          self.obs_traj[start_1:end_1, :],      # (n_1,2,8)\n","          self.obs_traj[start_2:end_2, :],      # (n_2,2,8)\n","          \n","          ...\n","      ],\n","      [\n","          self.pred_traj[start_1:end_2, :],     # (n_1,2,12)\n","          self.pred_traj[start_2:end_2, :],     # (n_2,2,12)\n","          ...\n","      ]\n","      ...#64\n","    )\n","    '''\n","    (\n","        obs_seq_list,           #64 items, each item:(n_?, 2, 8)\n","        pred_seq_list,          #64 items, each item:(n_?, 2, 12)\n","        obs_seq_rel_list, \n","        pred_seq_rel_list,\n","        non_linear_ped_list,\n","        loss_mask_list,\n","    ) = zip(*data)\n","\n","    _len = [len(seq) for seq in obs_seq_list]\n","    cum_start_idx = [0] + np.cumsum(_len).tolist()\n","    seq_start_end = [\n","        [start, end] for start, end in zip(cum_start_idx, cum_start_idx[1:])\n","    ]\n","\n","    # Data format: batch, input_size, seq_len\n","    # LSTM input format: seq_len, batch, input_size\n","    obs_traj = torch.cat(obs_seq_list, dim=0).permute(2, 0, 1)      # shape: torch.Size([*164, 2, 8])--permute--> torch.Size([8, 164, 2]): time, batch, feature\n","    pred_traj = torch.cat(pred_seq_list, dim=0).permute(2, 0, 1)    # shape: torch.Size([*164, 2, 12])--permute--> torch.Size([12, 164, 2])\n","    obs_traj_rel = torch.cat(obs_seq_rel_list, dim=0).permute(2, 0, 1)\n","    pred_traj_rel = torch.cat(pred_seq_rel_list, dim=0).permute(2, 0, 1)\n","    non_linear_ped = torch.cat(non_linear_ped_list)\n","    loss_mask = torch.cat(loss_mask_list, dim=0)\n","    seq_start_end = torch.LongTensor(seq_start_end)\n","    out = [\n","        obs_traj,\n","        pred_traj,\n","        obs_traj_rel,\n","        pred_traj_rel,\n","        non_linear_ped,\n","        loss_mask,\n","        seq_start_end,\n","    ]\n","\n","    return tuple(out)\n","\n","\n","def read_file(_path, delim=\"\\t\"):\n","    data = []\n","    if delim == \"tab\":\n","        delim = \"\\t\"\n","    elif delim == \"space\":\n","        delim = \" \"\n","    with open(_path, \"r\") as f:\n","        for line in f:\n","            line = line.strip().split(delim)\n","            line = [float(i) for i in line]\n","            data.append(line)\n","    return np.asarray(data)\n","\n","\n","def poly_fit(traj, traj_len, threshold):\n","    \"\"\"\n","    Input:\n","    - traj: Numpy array of shape (2, traj_len)\n","    - traj_len: Len of trajectory\n","    - threshold: Minimum error to be considered for non linear traj\n","    Output:\n","    - int: 1 -> Non Linear 0-> Linear\n","    \"\"\"\n","    t = np.linspace(0, traj_len - 1, traj_len)\n","    res_x = np.polyfit(t, traj[0, -traj_len:], 2, full=True)[1]\n","    res_y = np.polyfit(t, traj[1, -traj_len:], 2, full=True)[1]\n","    if res_x + res_y >= threshold:\n","        return 1.0\n","    else:\n","        return 0.0\n","\n","\n","class TrajectoryDataset(Dataset):     # 繼承torch.Dataset的屬性\n","    \"\"\"Dataloder for the Trajectory datasets\"\"\"\n","\n","    def __init__(\n","        self,\n","        data_dir,\n","        obs_len=8,\n","        pred_len=12,\n","        skip=1,\n","        threshold=0.002,\n","        min_ped=1,\n","        delim=\"\\t\",\n","    ):\n","        \"\"\"\n","        Args:\n","        - data_dir: Directory containing dataset files in the format\n","        <frame_id> <ped_id> <x> <y>\n","        - obs_len: Number of time-steps in input trajectories\n","        - pred_len: Number of time-steps in output trajectories\n","        - skip: Number of frames to skip while making the dataset\n","        - threshold: Minimum error to be considered for non linear traj\n","        when using a linear predictor\n","        - min_ped: Minimum number of pedestrians that should be in a seqeunce\n","        - delim: Delimiter in the dataset files\n","        \"\"\"\n","        super(TrajectoryDataset, self).__init__()\n","\n","        self.data_dir = data_dir\n","        self.obs_len = obs_len\n","        self.pred_len = pred_len\n","        self.skip = skip\n","        self.seq_len = self.obs_len + self.pred_len\n","        self.delim = delim\n","\n","        all_files = os.listdir(self.data_dir)\n","        all_files = [os.path.join(self.data_dir, _path) for _path in all_files]\n","        num_peds_in_seq = []    #儲存每個time-frame(idx)有效的軌跡數量\n","        seq_list = []\n","        seq_list_rel = []\n","        loss_mask_list = []\n","        non_linear_ped = []\n","        for path in all_files:\n","\n","            print('<Dataset/line:162>', 'file:',path.split('/')[-1])\n","\n","            '''\n","            - Step 1: 讀取原始檔案 <frame_id> <ped_id> <x> <y>\n","              - ex: zara2/train/biwi_hotel_train.txt\n","                data= [\n","                        [7.800e+02 1.000e+00 8.460e+00 3.590e+00]\n","                        [7.900e+02 1.000e+00 9.570e+00 3.790e+00]\n","                        [8.000e+02 1.000e+00 1.067e+01 3.990e+00]\n","                        ...\n","                        [1.023e+04 2.540e+02 1.810e+00 5.190e+00]\n","                        [1.023e+04 2.550e+02 1.200e+01 6.670e+00]\n","                        [1.023e+04 2.560e+02 1.151e+01 7.530e+00]\n","                      ]\n","            \"\"\"\n","            '''\n","            data = read_file(path, delim)\n","\n","            '''\n","            - Step 2: 建立frame number(unique) index\n","              - ex: np.unique(data[:, 0])=> 找出frame_number未重複的\n","                => frames: [780, 790, 800...]\n","            - np.unique: 排除數組中的重複數字，並進行排序後輸出\n","            '''\n","            frames = np.unique(data[:, 0]).tolist()\n","\n","            '''\n","            - Step 3: 相同time-frame的item合併\n","              - ex:\n","                data[]:\n","                  [\n","                    [780.     1.     8.46   3.59]\n","                    [790.     1.     9.57   3.79]\n","                    [800.     1.    10.67   3.99]\n","                    [800.     2.    13.64   5.8 ]\n","                    [810.     1.    11.73   4.32] \n","                    ...\n","                  ]\n","                =>\n","                frame_data[]: \n","                  [ \n","                    array([[780.  ,   1.  ,   8.46,   3.59]]), \n","                    array([[790.  ,   1.  ,   9.57,   3.79]]), \n","                    array([[800.  ,   1.  ,  10.67,   3.99], [800.  ,   2.  ,  13.64,   5.8 ]]), \n","                    array([[810.  ,   1.  ,  11.73,   4.32], [810.  ,   2.  ,  12.09,   5.75]])\n","                  ]\n","            '''\n","            frame_data = []\n","            for frame in frames:\n","                frame_data.append(data[frame == data[:, 0], :])\n","\n","            '''\n","            - Step 4: 預留seq_len長度\n","            '''\n","            num_sequences = int(math.ceil((len(frames) - self.seq_len + 1) / skip))\n","\n","            '''\n","            - Step 5: 遍歷每個time-frame,每次取seq_len個(obs_len+pred_len)\n","            '''\n","            for idx in range(0, num_sequences * self.skip + 1, skip):\n","                '''\n","                - Step 6: 找出此時段內所有位置資料:\n","                ex:\n","                  frame_data[idx : idx + seq_len] =\n","                  [\n","                    array([[780.  ,   1.  ,   8.46,   3.59]]), \n","                    array([[790.  ,   1.  ,   9.57,   3.79]]), \n","                    array([[800.  ,   1.  ,  10.67,   3.99], [800.  ,   2.  ,  13.64,   5.8 ]]),\n","                    ...\n","                    array([[9.700e+02,  2.000e+00,  2.010e+00,  8.000e+00],[ 9.700e+02,  3.000e+00,  3.190e+00,  6.890e+00],  [ 9.700e+02,  4.000e+00,  1.101e+01,  5.320e+00], [ 9.700e+02,  5.000e+00,  1.082e+01,  4.490e+00],  [ 9.700e+02,  6.000e+00,  2.130e+00,  6.290e+00],[ 9.700e+02,  7.000e+00,  6.860e+00,  5.830e+00],[ 9.700e+02,  8.000e+00, -9.300e-01,  9.600e-01]])\n","                  ]\n","\n","                  =>np.concatenate():\n","                    curr_seq_data =   \n","                    [         \n","                      [ 7.800e+02  1.000e+00  8.460e+00  3.590e+00]\n","                      [ 7.900e+02  1.000e+00  9.570e+00  3.790e+00]\n","                      [ 8.000e+02  1.000e+00  1.067e+01  3.990e+00]\n","                      [ 8.000e+02  2.000e+00  1.364e+01  5.800e+00]\n","                      [ 8.100e+02  1.000e+00  1.173e+01  4.320e+00]\n","                      [ 8.100e+02  2.000e+00  1.209e+01  5.750e+00]\n","                      ...\n","                      [ 9.700e+02  7.000e+00  6.860e+00  5.830e+00]\n","                      [ 9.700e+02  8.000e+00 -9.300e-01  9.600e-01]\n","                    ]  \n","                '''\n","                # curr_seq_data is a 20 length sequence\n","                curr_seq_data = np.concatenate(\n","                    frame_data[idx : idx + self.seq_len], axis=0\n","                )\n","\n","                '''\n","                 Step 7: 從idx~(idx+seq_len)內出不重複的pedestrain  \n","                  - ex:\n","                    peds_in_curr_seq: [1. 2. 3. 4. 5. 6. 7. 8.]\n","                '''\n","                peds_in_curr_seq = np.unique(curr_seq_data[:, 1])\n","\n","                curr_seq_rel = np.zeros((len(peds_in_curr_seq), 2, self.seq_len)) #宣告記錄行人數量之座標np.array\n","                curr_seq = np.zeros((len(peds_in_curr_seq), 2, self.seq_len))\n","                curr_loss_mask = np.zeros((len(peds_in_curr_seq), self.seq_len))\n","                num_peds_considered = 0\n","                _non_linear_ped = []\n","\n","                '''\n","                - Step 8: 遍歷每個ped, 找出idx~(idx+seq_len)內出現的位置item\n","                '''\n","                for _, ped_id in enumerate(peds_in_curr_seq):\n","\n","                    '''\n","                    - Step 9: 找出相同ped_id的item\n","                    ex: \n","                      curr_seq_data[] =   \n","                      [\n","                        [ 7.800e+02  1.000e+00  8.460e+00  3.590e+00]\n","                        [ 7.900e+02  1.000e+00  9.570e+00  3.790e+00]\n","                        [ 8.000e+02  1.000e+00  1.067e+01  3.990e+00]\n","                        [ 8.000e+02  2.000e+00  1.364e+01  5.800e+00]\n","                        [ 8.100e+02  1.000e+00  1.173e+01  4.320e+00]\n","                        [ 8.100e+02  2.000e+00  1.209e+01  5.750e+00]\n","                        ...\n","                        [ 9.700e+02  7.000e+00  6.860e+00  5.830e+00]\n","                        [ 9.700e+02  8.000e+00 -9.300e-01  9.600e-01]\n","                      ]\n","                      =>\n","                      目標ped_id: 1.0 \n","                      =>\n","                      curr_ped_seq[]= \n","                      [\n","                        [780.     1.     8.46   3.59]\n","                        [790.     1.     9.57   3.79]\n","                        [800.     1.    10.67   3.99]\n","                        [810.     1.    11.73   4.32]\n","                        [820.     1.    12.81   4.61]\n","                      ]\n","                    '''\n","                    curr_ped_seq = curr_seq_data[curr_seq_data[:, 1] == ped_id, :]\n","                    curr_ped_seq = np.around(curr_ped_seq, decimals=4)\n","                    \n","                    '''\n","                    - Step 10: 從frame id list(frames)找出此行人出現起始/結束之frame id的index\n","                    '''\n","                    pad_front = frames.index(curr_ped_seq[0, 0]) - idx\n","                    pad_end = frames.index(curr_ped_seq[-1, 0]) - idx + 1\n","\n","                    '''\n","                    如果出現的長度未超過seq_len(obs_len+pred_len)=>結束此行人處理\n","                    '''\n","                    if pad_end - pad_front != self.seq_len:\n","                        continue\n","\n","                    '''\n","                    - Step 11: transpose軌跡資料\n","                    '''\n","                    curr_ped_seq = np.transpose(curr_ped_seq[:, 2:]) #(20, 4)=>(20, 2)=>(2, 20)\n","                    curr_ped_seq = curr_ped_seq\n","                    # Make coordinates relative\n","                    rel_curr_ped_seq = np.zeros(curr_ped_seq.shape)\n","                    rel_curr_ped_seq[:, 1:] = curr_ped_seq[:, 1:] - curr_ped_seq[:, :-1]\n","                    _idx = num_peds_considered\n","\n","                    curr_seq[_idx, :, pad_front:pad_end] = curr_ped_seq  # 將curr_ped_seq寫入curr_seq的範圍\n","                    curr_seq_rel[_idx, :, pad_front:pad_end] = rel_curr_ped_seq\n","\n","                    # Linear vs Non-Linear Trajectory\n","                    #_non_linear_ped.append(poly_fit(curr_ped_seq, pred_len, threshold))\n","                    curr_loss_mask[_idx, pad_front:pad_end] = 1  # (nums_ped, seq_len )\n","                    num_peds_considered += 1\n","\n","                '''\n","                ex:\n","                  idx=5 \n","                    符合的行人軌跡數量=2:\n","                    array([\n","                          [\n","                            [10.31,  9.57,  8.73,  7.94,  7.17,  6.47,  5.86,  5.24,  4.87, 4.51,  4.2 ,  3.95,  3.47,  2.82,  2.01,  1.28,  0.54, -0.18,   -0.83, -1.52],\n","                            [ 5.97,  6.24,  6.34,  6.5 ,  6.62,  6.68,  6.82,  6.98,  7.16,  7.58,  7.3 ,  7.71,  7.86,  8.  ,  8.  ,  7.82,  7.4 ,  7.06,  6.43,  6.05]\n","                          ],\n","                          [\n","                            [12.49, 11.94, 11.03, 10.21,  9.36,  8.59,  7.78,  6.96,  6.29,  5.62,  5.06,  4.69,  4.35,  3.76,  3.19,  2.62,  1.78,  1.01,  0.07, -0.72],\n","                            [ 6.6 ,  6.77,  6.84,  6.81,  6.85,  6.85,  6.84,  6.84,  7.  ,  7.1 ,  7.04,  7.  ,  7.01,  6.99,  6.89,  7.13,  7.15,  6.96,  6.91,  6.66]\n","                          ]\n","                          ]),\n","                '''\n","                if num_peds_considered > min_ped:\n","                    #non_linear_ped += _non_linear_ped\n","                    \n","                    '''\n","                    ex:\n","                      num_peds_in_seq = [2, 2, 3,  3,  3,  3,  3, ...       2,     2,     2] => 儲存每個time-frame有效的軌跡數量\n","                      cum_start_idx =[0, 2, 4, 7, 10, 13, 16, 19, ... , 25503, 25505, 25507]\n","                    '''\n","                    num_peds_in_seq.append(num_peds_considered)      # 記錄本此行人數量\n","                    loss_mask_list.append(curr_loss_mask[:num_peds_considered])\n","                    seq_list.append(curr_seq[:num_peds_considered])  # Append array陣列\n","                    seq_list_rel.append(curr_seq_rel[:num_peds_considered])\n","\n","            print(\"<Dataset/line:359>\",\"time-step數量:\",len(seq_list),\"(len(seq_list))\", \", 所有軌跡數量:\",np.concatenate(seq_list_rel, axis=0).shape,\" (n_traj, 2, 20)\")\n","            \n","        self.num_seq = len(seq_list)\n","\n","        '''\n","        - ex: \n","            seq_list=\n","              [                                                               _\n","                array([[[10.31,  9.57,  8.73,  7.94,  7.17,  ...],  #x座標      |\n","                        [ 5.97,  6.24,  6.34,  6.5 ,  6.62,  ...]], #y座標      | => 某個frame idx~(idx+seq_len)內的行人軌跡\n","                      [[12.49, 11.94, 11.03, 10.21,  9.36,  ...],              |\n","                        [ 6.6 ,  6.77,  6.84,  6.81,  6.85,  ...]]]),         _|\n","                array([[[ 1.251e+01,  1.154e+01,  1.096e+01,  1.029e+01,  9.880e+00, ...],\n","                        [ 6.190e+00,  6.030e+00,  5.970e+00,  6.120e+00,  6.210e+00, ...]],\n","                      [[ 1.209e+01,  1.140e+01,  1.070e+01,  1.007e+01,  9.450e+00, ...],\n","                        [ 6.950e+00,  6.930e+00,  6.870e+00,  6.730e+00,  6.510e+00, ...]]]),\n","                ...\n","              ]\n","              =>(40,)\n","            seq_list = np.concatenate(seq_list, axis=0) = \n","              [\n","                  [ [ 1.031e+01  9.570e+00  8.730e+00  7.940e+00  7.170e+00  ...]\n","                    [ 5.970e+00  6.240e+00  6.340e+00  6.500e+00  6.620e+00  ...]]\n","                  [ [ 1.249e+01  1.194e+01  1.103e+01  1.021e+01  9.360e+00  ...]\n","                    [ 6.600e+00  6.770e+00  6.840e+00  6.810e+00  6.850e+00  ...]]\n","                  [ [ 1.251e+01  1.154e+01  1.096e+01  1.029e+01  9.880e+00  ...]\n","                    [ 6.190e+00  6.030e+00  5.970e+00  6.120e+00  6.210e+00  ...]]\n","                  [ [ 1.209e+01  1.140e+01  1.070e+01  1.007e+01  9.450e+00  ...]\n","                    [ 6.950e+00  6.930e+00  6.870e+00  6.730e+00  6.510e+00  ...]\n","                  ...\n","              ] \n","              =>(101,2,20)\n","        '''\n","        seq_list = np.concatenate(seq_list, axis=0)  # 將array of list 展開, ex:(40,)->(101,2,20)\n","        seq_list_rel = np.concatenate(seq_list_rel, axis=0)\n","        loss_mask_list = np.concatenate(loss_mask_list, axis=0)\n","        non_linear_ped = np.asarray(non_linear_ped)\n","\n","        # Convert numpy -> Torch Tensor\n","        self.obs_traj = torch.from_numpy(seq_list[:, :, : self.obs_len]).type(\n","            torch.float\n","        )\n","        self.pred_traj = torch.from_numpy(seq_list[:, :, self.obs_len :]).type(\n","            torch.float\n","        )\n","        self.obs_traj_rel = torch.from_numpy(seq_list_rel[:, :, : self.obs_len]).type(\n","            torch.float\n","        )\n","        self.pred_traj_rel = torch.from_numpy(seq_list_rel[:, :, self.obs_len :]).type(\n","            torch.float\n","        )\n","        self.loss_mask = torch.from_numpy(loss_mask_list).type(torch.float)\n","        self.non_linear_ped = torch.from_numpy(non_linear_ped).type(torch.float)\n","        \n","        \"\"\"\n","        - 每個間隔代表該frame內的行人軌跡item的index\n","        - ex: \n","          num_peds_in_seq = [2, 2, 3,  3,  3,  3,  3, ...       2,     2,     2] => 儲存每個time-frame有效的軌跡數量\n","          =>np.cumsum():\n","          cum_start_idx = [0, 2, 4, 7, 10,...]\n","          =>zip():\n","          seq_start_end = [(0, 2), (2, 4), (4, 7), (7, 10)...]  => 每個time-frame有效的軌跡數量= (start_index-end_index)\n","        \"\"\"\n","        cum_start_idx = [0] + np.cumsum(num_peds_in_seq).tolist()\n","        self.seq_start_end = [\n","            (start, end) for start, end in zip(cum_start_idx, cum_start_idx[1:])\n","        ] \n","\n","        print(\"<Dataset/line:427>\", '記錄各time-step內軌跡的index數量:', len(self.seq_start_end), '(len(seq_start_end))')\n","\n","    def __len__(self):\n","        return self.num_seq\n","\n","    def __getitem__(self, index):\n","        start, end = self.seq_start_end[index] #(start, end): 遍歷frame取的區間資料內，行人的數量\n","        out = [\n","            self.obs_traj[start:end, :],      # (n,2,8)\n","            self.pred_traj[start:end, :],     # (n,2,12)\n","            self.obs_traj_rel[start:end, :],  # (n,2,8)\n","            self.pred_traj_rel[start:end, :], # (n,2,12)\n","            self.non_linear_ped[start:end],\n","            self.loss_mask[start:end, :],\n","        ]\n","        return out"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XBrzI25szYwC","colab_type":"text"},"source":["### DataLoader"]},{"cell_type":"code","metadata":{"id":"bpovs7ymzYPc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599318003065,"user_tz":-480,"elapsed":578,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}}},"source":["from torch.utils.data import DataLoader\n","#from data.trajectories import TrajectoryDataset, seq_collate\n","\n","def data_loader(args, path):\n","\n","    print('<DataLoader/line:7>', 'path:',path)\n","\n","    dset = TrajectoryDataset(\n","        path,\n","        obs_len=args.obs_len,\n","        pred_len=args.pred_len,\n","        skip=args.skip,\n","        delim=args.delim)\n","\n","    loader = DataLoader(\n","        dset,\n","        batch_size=args.batch_size,\n","        shuffle=False,\n","        num_workers=args.loader_num_workers,\n","        collate_fn=seq_collate,\n","        pin_memory=True)\n","    return dset, loader"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZNQGdcpizHT","colab_type":"text"},"source":["### Model"]},{"cell_type":"code","metadata":{"id":"e9ZSAlCni0BX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599318005586,"user_tz":-480,"elapsed":1442,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}}},"source":["def get_noise(shape, noise_type):\n","    if noise_type == \"gaussian\":\n","        return torch.randn(*shape).cuda()\n","    elif noise_type == \"uniform\":\n","        return torch.rand(*shape).sub_(0.5).mul_(2.0).cuda()\n","    raise ValueError('Unrecognized noise type \"%s\"' % noise_type)\n","\n","\n","# this efficient implementation comes from https://github.com/xptree/DeepInf/\n","class BatchMultiHeadGraphAttention(nn.Module):\n","    def __init__(self, n_head, f_in, f_out, attn_dropout, bias=True):\n","        super(BatchMultiHeadGraphAttention, self).__init__()\n","        self.n_head = n_head\n","        self.f_in = f_in\n","        self.f_out = f_out\n","        self.w = nn.Parameter(torch.Tensor(n_head, f_in, f_out)) \n","        self.a_src = nn.Parameter(torch.Tensor(n_head, f_out, 1))   #將一個不可訓練的類型Tensor,轉換成可以訓練的類型parameter,並將這個parameter綁定到這個module裡面\n","        self.a_dst = nn.Parameter(torch.Tensor(n_head, f_out, 1))\n","\n","        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.dropout = nn.Dropout(attn_dropout)\n","        if bias:\n","            self.bias = nn.Parameter(torch.Tensor(f_out))\n","            nn.init.constant_(self.bias, 0)\n","        else:\n","            self.register_parameter(\"bias\", None)\n","\n","        nn.init.xavier_uniform_(self.w, gain=1.414)\n","        nn.init.xavier_uniform_(self.a_src, gain=1.414)\n","        nn.init.xavier_uniform_(self.a_dst, gain=1.414)\n","\n","    def forward(self, h):\n","\n","        \n","        bs, n = h.size()[:2]  # h is of size bs x n x f_in\n","\n","        # h.size(): (bs, n, _)(ex:(8, 2, 32)), h.unsqueeze(1):torch.Size([8, 1, 2, 32])\n","        # w.size(): (n_head, f_in, f_out)(ex:(4, 32, 16)) => h_prime.size(): torch.Size([8, 4, 2, 16])\n","        h_prime = torch.matmul(h.unsqueeze(1), self.w)  # (bs, n, f_in)\n","\n","        #print(\"<Model/line:35> h.unsqueeze(1):\",h.unsqueeze(1).size(),\", w.size():\",self.w.size(),\"=> h_prime.size():\",h_prime.size())\n","\n","        # self.a_src: (n_head, f_out, 1)\n","        \n","        # Attention 矩陣運算:\n","        # e_xy = [Whx || Why] * a^T, a^T =R^2F'=[a_scr || a_dst], a_scr=R^F' a_dst==R^F'\n","        # => e_xy = [Whx || Why] * [a_scr || a_dst]^T = Whx*a_scr + Why*a_dst\n","        # attention 矩陣(ex:n=3):\n","        #  [ e_11  e_12  e_13\n","        #    e_21  e_22  e_23\n","        #    e_31  e_32  e_33 ]\n","        # =>\n","        #  [(Wh1*a_scr+Wh1*a_dst) (Wh1*a_scr+Wh2*a_dst) (Wh1*a_scr+Wh3*a_dst)\n","        #   (Wh2*a_scr+Wh1*a_dst) (Wh2*a_scr+Wh2*a_dst) (Wh2*a_scr+Wh3*a_dst)\n","        #   (Wh3*a_scr+Wh1*a_dst) (Wh3*a_scr+Wh2*a_dst) (Wh3*a_scr+Wh3*a_dst)]\n","        # =>\n","        #  [(Wh1*a_scr) (Wh1*a_scr) (Wh1*a_scr)       [ (Wh1*a_dst) (Wh2*a_dst) (Wh3*a_dst)\n","        #   (Wh2*a_scr) (Wh2*a_scr) (Wh2*a_scr)   +     (Wh1*a_dst) (Wh2*a_dst) (Wh3*a_dst)\n","        #   (Wh3*a_scr) (Wh3*a_scr) (Wh3*a_scr)]        (Wh1*a_dst) (Wh2*a_dst) (Wh3*a_dst)]\n","        # =>\n","        #  [(Wh1*a_scr)                   [(Wh1*a_dst)\n","        # ( (Wh2*a_scr) ).expand(-1,n) + ( (Wh2*a_dst) ).expand(-1,n).permute(1,0)\n","        #   (Wh3*a_scr)]                   (Wh3*a_dst)]\n","        # =>\n","        # (torch.matmul(h_prime, self.a_src)).expand(-1,n)+ torch.matmul(h_prime, self.a_dst).expand(-1,n).permute(1,0)\n","        attn_src = torch.matmul(h_prime, self.a_src)    # bs x n_head x n x 1\n","        attn_dst = torch.matmul(h_prime, self.a_dst)    # bs x n_head x n x 1\n","        attn = attn_src.expand(-1, -1, -1, n) + attn_dst.expand(-1, -1, -1, n).permute(\n","            0, 1, 3, 2\n","        ) # bs x n_head x n x n\n","\n","        attn = self.leaky_relu(attn)\n","        attn = self.softmax(attn)\n","        attn = self.dropout(attn)\n","        output = torch.matmul(attn, h_prime)\n","        if self.bias is not None:\n","            return output + self.bias, attn\n","        else:\n","            return output, attn\n","\n","    def __repr__(self):\n","        return (\n","            self.__class__.__name__\n","            + \" (head:\"\n","            + str(self.n_head)\n","            + \" Units:\"\n","            + str(self.f_in)\n","            + \" -> \"\n","            + str(self.f_out)\n","            + \")\"\n","        )\n","\n","\n","class GAT(nn.Module):\n","    def __init__(self, n_units, n_heads, dropout=0.2, alpha=0.2):\n","        super(GAT, self).__init__()\n","        self.n_layer = len(n_units) - 1\n","        self.dropout = dropout\n","        self.layer_stack = nn.ModuleList()\n","\n","        for i in range(self.n_layer):\n","            f_in = n_units[i] * n_heads[i - 1] if i else n_units[i]\n","            self.layer_stack.append(\n","                BatchMultiHeadGraphAttention(\n","                    n_heads[i], f_in=f_in, f_out=n_units[i + 1], attn_dropout=dropout\n","                )\n","            )\n","\n","        self.norm_list = [\n","            torch.nn.InstanceNorm1d(32).cuda(),\n","            torch.nn.InstanceNorm1d(64).cuda(),\n","        ]\n","\n","    def forward(self, x):\n","\n","        bs, n = x.size()[:2]   # bs: 8 ; n=ped_nums ((start, end)內的軌跡數量, ex:2)\n","\n","        for i, gat_layer in enumerate(self.layer_stack):\n","            # 將encoding traj 正規化\n","            x = self.norm_list[i](x.permute(0, 2, 1)).permute(0, 2, 1)  #  先轉成torch.Size([8, 32, *2])正歸化->再轉回來 torch.Size([8, *2, 32])\n","\n","            # ex: n=2\n","            # layer1: output x.size(): torch.Size([8, 4, 2, 16]) , attn.size(): torch.Size([8, 4, 2, 2])\n","            # layer2: output x.size(): torch.Size([8, 1, 2, 32]) , attn.size(): torch.Size([8, 1, 2, 2])\n","            x, attn = gat_layer(x)   \n","\n","            if i + 1 == self.n_layer:\n","                x = x.squeeze(dim=1)   \n","            else:\n","                x = F.elu(x.transpose(1, 2).contiguous().view(bs, n, -1)) #Paper's equation 7\n","                x = F.dropout(x, self.dropout, training=self.training)\n","        else:\n","            return x\n","\n","class GATEncoder(nn.Module):\n","    def __init__(self, n_units, n_heads, dropout, alpha):\n","        super(GATEncoder, self).__init__()\n","        self.gat_net = GAT(n_units, n_heads, dropout, alpha)\n","\n","    def forward(self, obs_traj_embedding, seq_start_end):\n","        graph_embeded_data = []\n","\n","        # 不同time-step的軌跡分別處理 \n","        # seq_start_end => 記錄此batch內的屬於不同time-step的軌跡index\n","        # input: (8, *2, 32) -> (gat encoder) -> (8, *2, 32)\n","\n","           \n","        for start, end in seq_start_end.data: \n","            curr_seq_embedding_traj = obs_traj_embedding[:, start:end, :]   # curr_seq_embedding_traj: (8, *2, 32)\n","            \n","            curr_seq_graph_embedding = self.gat_net(curr_seq_embedding_traj)\n","            graph_embeded_data.append(curr_seq_graph_embedding)\n","\n","            #print(\"<Model/line:149> graph_embeded_data.stack()\", torch.cat(graph_embeded_data, dim=1).size())\n","\n","        graph_embeded_data = torch.cat(graph_embeded_data, dim=1)\n","        \n","        return graph_embeded_data\n","\n","class TrajectoryGenerator(nn.Module):\n","    def __init__(\n","        self,\n","        obs_len,\n","        pred_len,\n","        traj_lstm_input_size,   # 2\n","        traj_lstm_hidden_size,  # 32\n","        n_units,                #(32,16,32)\n","        n_heads,\n","        graph_network_out_dims, # 32\n","        dropout,\n","        alpha,\n","        graph_lstm_hidden_size, # 32\n","        noise_dim=(8,),\n","        noise_type=\"gaussian\",\n","    ):\n","        super(TrajectoryGenerator, self).__init__()\n","\n","        # 因easydict.EasyDict內的tuple會被強制轉成list, 所以再使用時需轉換回tuple\n","        noise_dim =tuple(noise_dim)\n","\n","        self.obs_len = obs_len\n","        self.pred_len = pred_len\n","\n","        \n","        self.gatencoder = GATEncoder(\n","            n_units=n_units, n_heads=n_heads, dropout=dropout, alpha=alpha\n","        )\n","\n","\n","        self.graph_lstm_hidden_size = graph_lstm_hidden_size\n","        self.traj_lstm_hidden_size = traj_lstm_hidden_size\n","        self.traj_lstm_input_size = traj_lstm_input_size\n","\n","        self.pred_lstm_hidden_size = (\n","            self.traj_lstm_hidden_size + self.graph_lstm_hidden_size + noise_dim[0]\n","        )\n","\n","        self.traj_lstm_model = nn.LSTMCell(traj_lstm_input_size, traj_lstm_hidden_size)\n","        self.graph_lstm_model = nn.LSTMCell(\n","            graph_network_out_dims, graph_lstm_hidden_size\n","        )\n","        self.traj_hidden2pos = nn.Linear(self.traj_lstm_hidden_size, 2)\n","        self.traj_gat_hidden2pos = nn.Linear(\n","            self.traj_lstm_hidden_size + self.graph_lstm_hidden_size, 2\n","        )\n","        self.pred_hidden2pos = nn.Linear(self.pred_lstm_hidden_size, 2)\n","\n","        self.noise_dim = noise_dim\n","        self.noise_type = noise_type\n","\n","        self.pred_lstm_model = nn.LSTMCell(\n","            traj_lstm_input_size, self.pred_lstm_hidden_size\n","        )\n","\n","    def init_hidden_traj_lstm(self, batch):\n","        return (\n","            torch.randn(batch, self.traj_lstm_hidden_size).cuda(),\n","            torch.randn(batch, self.traj_lstm_hidden_size).cuda(),\n","        )\n","\n","    def init_hidden_graph_lstm(self, batch):\n","        return (\n","            torch.randn(batch, self.graph_lstm_hidden_size).cuda(),\n","            torch.randn(batch, self.graph_lstm_hidden_size).cuda(),\n","        )\n","\n","    def add_noise(self, _input, seq_start_end):\n","        \n","        noise_shape = (seq_start_end.size(0),) + self.noise_dim\n","\n","        z_decoder = get_noise(noise_shape, self.noise_type)\n","\n","        _list = []\n","        for idx, (start, end) in enumerate(seq_start_end):\n","            start = start.item()\n","            end = end.item()\n","            _vec = z_decoder[idx].view(1, -1)\n","            _to_cat = _vec.repeat(end - start, 1)\n","            _list.append(torch.cat([_input[start:end], _to_cat], dim=1))\n","        decoder_h = torch.cat(_list, dim=0)\n","        return decoder_h\n","\n","    def forward(\n","        self,\n","        obs_traj_rel,\n","        obs_traj_pos,\n","        seq_start_end,\n","        teacher_forcing_ratio=0.5,\n","        training_step=3,\n","    ):\n","        batch = obs_traj_rel.shape[1]\n","        traj_lstm_h_t, traj_lstm_c_t = self.init_hidden_traj_lstm(batch)\n","        graph_lstm_h_t, graph_lstm_c_t = self.init_hidden_graph_lstm(batch)\n","        pred_traj_rel = []\n","        traj_lstm_hidden_states = []\n","        graph_lstm_hidden_states = []\n","        \n","        # 更新m-lstm, 共更新obs_len次 --START #\n","        for i, input_t in enumerate(   # input_t: torch.Size([1, *164, 2]) \n","            obs_traj_rel[: self.obs_len].chunk(\n","                obs_traj_rel[: self.obs_len].size(0), dim=0\n","            )\n","        ):\n","            \n","            '''\n","            # input_t: torch.Size([1, *164, 2]) \n","            # input_t.squeeze(0): torch.Size([*164, 2]) \n","            # traj_lstm_h_t: torch.Size([*164, 32]) \n","            # traj_lstm_c_t: torch.Size([*164, 32]) \n","            # output: torch.Size([*164, 2])\n","            '''\n","            traj_lstm_h_t, traj_lstm_c_t = self.traj_lstm_model(\n","                input_t.squeeze(0),  # torch.Size([1, 164, 2]) -> torch.Size([164, 2]) \n","                (traj_lstm_h_t, traj_lstm_c_t) # torch.Size([164, 32]) \n","            )\n","\n","            if training_step == 1:    \n","                output = self.traj_hidden2pos(traj_lstm_h_t) #torch.Size([164, 32]) ->2pos-> output: torch.Size([164, 2])\n","                pred_traj_rel += [output]\n","            else:\n","                traj_lstm_hidden_states += [traj_lstm_h_t]\n","        # 更新m-lstm, 共更新obs_len次 --END #\n","\n","        # m-lstm輸出 -> GAT -> g-lstm --START #\n","        if training_step == 2:\n","\n","            #(8, *164, 32) -- (gat encoder) -> (8, *164, 32)\n","            graph_lstm_input = self.gatencoder(\n","                torch.stack(traj_lstm_hidden_states),    \n","                seq_start_end\n","            )\n","            \n","            # 將GAT輸出, 依時間序當成g-lstm input --START #\n","            for i in range(self.obs_len):\n","                graph_lstm_h_t, graph_lstm_c_t = self.graph_lstm_model(    #graph_lstm_input.size: torch.Size([164, 32])\n","                    graph_lstm_input[i], (graph_lstm_h_t, graph_lstm_c_t)\n","                )\n","\n","                # 也就是paper中encoder的\"c\" \n","                # 因為還不是training_step==3, 故取\"每個\"時間序concat,並當成traj_gat_hidden2pos之input\n","                # (*164,32)||(*164,32) in dim1 => (*164,64) \n","                encoded_before_noise_hidden = torch.cat(\n","                    (traj_lstm_hidden_states[i], graph_lstm_h_t), dim=1   \n","                )\n","\n","                output = self.traj_gat_hidden2pos(encoded_before_noise_hidden)  #  (*164,64)->(*164, 2))\n","                pred_traj_rel += [output]  \n","            # 將GAT輸出, 依時間序當成g-lstm input --END #\n","\n","        # m-lstm輸出 -> GAT -> g-lstm --END #\n","\n","        if training_step == 3:\n","\n","            #(8, *164, 32) -- (gat encoder) -> (8, *164, 32)\n","            graph_lstm_input = self.gatencoder( \n","                torch.stack(traj_lstm_hidden_states), \n","                seq_start_end\n","            )\n","            \n","            # 將GAT輸出, 依時間序當成g-lstm input --START #\n","            for i, input_t in enumerate(                    #input_t: torch.Size([1, 164, 32])\n","                graph_lstm_input[: self.obs_len].chunk(\n","                    graph_lstm_input[: self.obs_len].size(0), dim=0\n","                )\n","            ):\n","\n","                graph_lstm_h_t, graph_lstm_c_t = self.graph_lstm_model(  #graph_lstm_h_t: torch.Size([164, 32])\n","                    input_t.squeeze(0), (graph_lstm_h_t, graph_lstm_c_t)\n","                )\n","\n","                graph_lstm_hidden_states += [graph_lstm_h_t] # graph_lstm_hidden_states: n x [164, 32]\n","            # 將GAT輸出, 依時間序當成g-lstm input --END #\n","\n","        # training_step == 1 or training_step == 2=> 逼近observed的軌跡數據\n","        if training_step == 1 or training_step == 2:\n","            return torch.stack(pred_traj_rel)\n","        else:\n","\n","            # 也就是paper中encoder的\"c\" \n","            # 因為training_step==3, 故取\"最後一個\"時間序concat,並當成traj_gat_hidden2pos之input\n","            # (*164,32)||(*164,32) in dim1 => (*164,64) \n","            encoded_before_noise_hidden = torch.cat(\n","                (traj_lstm_hidden_states[-1], graph_lstm_hidden_states[-1]), dim=1\n","            )\n","\n","            # 也就是paper中的State\n","            # torch.Size([164, 64]) -- (add_noise) -> torch.Size([164, 80])\n","            pred_lstm_hidden = self.add_noise(\n","                encoded_before_noise_hidden, seq_start_end\n","            )\n","\n","            pred_lstm_c_t = torch.zeros_like(pred_lstm_hidden).cuda()\n","\n","            # obs_traj_rel: torch.Size([20, 164, 2])\n","            output = obs_traj_rel[self.obs_len-1]  # 取倒數最後一個obs_traj_rel=> torch.Size([164, 2])\n","\n","            if self.training:\n","\n","                # obs_traj_rel: [20, 164, 2] => 取[-pre_len:]依次處理預測\n","                for i, input_t in enumerate(\n","                    obs_traj_rel[-self.pred_len :].chunk(\n","                        obs_traj_rel[-self.pred_len :].size(0), dim=0\n","                    )\n","                ):\n","                    teacher_force = random.random() < teacher_forcing_ratio\n","                    input_t = input_t if teacher_force else output.unsqueeze(0)\n","                    pred_lstm_hidden, pred_lstm_c_t = self.pred_lstm_model(\n","                        input_t.squeeze(0), (pred_lstm_hidden, pred_lstm_c_t)\n","                    )\n","                    output = self.pred_hidden2pos(pred_lstm_hidden)\n","                    pred_traj_rel += [output]\n","                outputs = torch.stack(pred_traj_rel)\n","            else:\n","                for i in range(self.pred_len):\n","                    pred_lstm_hidden, pred_lstm_c_t = self.pred_lstm_model(\n","                        output, (pred_lstm_hidden, pred_lstm_c_t)\n","                    )\n","                    output = self.pred_hidden2pos(pred_lstm_hidden)\n","                    pred_traj_rel += [output]\n","                outputs = torch.stack(pred_traj_rel)\n","            return outputs"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x30XNKFx0tjW","colab_type":"text"},"source":["### Main Run"]},{"cell_type":"code","metadata":{"id":"2uSdUF5w0ukL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599292709526,"user_tz":-480,"elapsed":2848904,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}},"outputId":"522902f8-c4ae-48ee-8cb5-614649ae224b"},"source":["\n","args = easydict.EasyDict({\n","        \"log_dir\": \"./\",\n","        \"dataset_name\": \"zara2\",\n","        \"delim\": \"\\t\",\n","        \"loader_num_workers\": 1,  #原:4\n","        \"obs_len\": 8,\n","        \"pred_len\": 12,\n","        \"skip\": 1,\n","        \"seed\": 72,\n","        \"batch_size\":64,\n","        \n","        \"noise_dim\":(16,),\n","        \"noise_type\":\"gaussian\",\n","        \"traj_lstm_input_size\":2,\n","        \"traj_lstm_hidden_size\":32,\n","        \"heads\":\"4,1\",\n","        \"hidden_units\":\"16\",\n","        \"graph_network_out_dims\":32,\n","        \"graph_lstm_hidden_size\":32,\n","        \"dropout\":0,\n","        \"alpha\": 0.2,\n","        \"lr\":1e-3,\n","        \"start_epoch\":0,\n","        \n","        \n","        \"use_gpu\":1,\n","        \"gpu_num\":\"0\",\n","        \"print_every\":5,\n","\n","        \"resume\":\"checkpoint/xxx.tar\",\n","\n","        \"best_k\": 1,\n","        \"epoch_step1\":150,\n","        \"epoch_step2\":250,\n","        \"num_epochs\":400,\n","})\n","\n","best_ade = 100\n","\n","def main(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_num\n","    train_path = get_dset_path(args.dataset_name, \"train\")\n","    val_path = get_dset_path(args.dataset_name, \"test\")\n","\n","    print('<Main/line:48>', 'Initializing train dataset')\n","    \n","    train_dset, train_loader = data_loader(args, train_path)\n","\n","    print('<Main/line:51>', \"len of train_dset:\",len(train_dset), \", len of train_loader:\",len(train_loader))\n","\n","    for batch_idx, batch in enumerate(train_loader):\n","        batch = [tensor.cuda() for tensor in batch]\n","        (\n","            obs_traj,         \n","            pred_traj_gt,\n","            obs_traj_rel,     # (obs_len, nums of item in a batch, 8)\n","            pred_traj_gt_rel, # (obs_len, nums of item in a batch, 12)\n","            non_linear_ped,\n","            loss_mask,\n","            seq_start_end,\n","        ) = batch   # 拆開資料\n","\n","        if batch_idx == 0:\n","          print('<Main/line:67>', 'obs_traj_rel.size():',obs_traj_rel.size())\n","          print('<Main/line:68>', 'pred_traj_gt_rel.size:',pred_traj_gt_rel.size())\n","\n","    _, val_loader = data_loader(args, val_path)\n","\n","    writer = SummaryWriter()\n","\n","\n","    n_units = (  #(32,16,32)\n","        [args.traj_lstm_hidden_size]                              # 32\n","        + [int(x) for x in args.hidden_units.strip().split(\",\")]  # 16\n","        + [args.graph_lstm_hidden_size]                           # 32               \n","    )\n","    n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n","\n","    model = TrajectoryGenerator(\n","        obs_len=args.obs_len,\n","        pred_len=args.pred_len,\n","        traj_lstm_input_size=args.traj_lstm_input_size,\n","        traj_lstm_hidden_size=args.traj_lstm_hidden_size,\n","        n_units=n_units,\n","        n_heads=n_heads,\n","        graph_network_out_dims=args.graph_network_out_dims,\n","        dropout=args.dropout,\n","        alpha=args.alpha,\n","        graph_lstm_hidden_size=args.graph_lstm_hidden_size,\n","        noise_dim=args.noise_dim,\n","        noise_type=args.noise_type,\n","    )\n","    print('args.noise_dim',args.noise_dim)\n","    model.cuda()\n","    print(\"<Main/line:97>\", \"Model.summary:\\n\",model)\n","\n","    optimizer = optim.Adam(\n","        [\n","            {\"params\": model.traj_lstm_model.parameters(), \"lr\": 1e-2},\n","            {\"params\": model.traj_hidden2pos.parameters()},\n","            {\"params\": model.gatencoder.parameters(), \"lr\": 3e-2},\n","            {\"params\": model.graph_lstm_model.parameters(), \"lr\": 1e-2},\n","            {\"params\": model.traj_gat_hidden2pos.parameters()},\n","            {\"params\": model.pred_lstm_model.parameters()},\n","            {\"params\": model.pred_hidden2pos.parameters()},\n","        ],\n","        lr=args.lr,\n","    )\n","    global best_ade\n","    if args.resume:\n","        if os.path.isfile(args.resume):\n","            print(\"Restoring from checkpoint {}\".format(args.resume))\n","            checkpoint = torch.load(args.resume)\n","            args.start_epoch = checkpoint[\"epoch\"]\n","            model.load_state_dict(checkpoint[\"state_dict\"])\n","            print(\n","                \"=> loaded checkpoint '{}' (epoch {})\".format(\n","                    args.resume, checkpoint[\"epoch\"]\n","                )\n","            )\n","        else:\n","            print(\"=> no checkpoint found at '{}'\".format(args.resume))\n","    \n","    training_step = 1\n","    execute_time = 0\n","\n","    for epoch in range(args.start_epoch, args.num_epochs + 1):\n","\n","        start_time = time.time()\n","\n","        if epoch < args.epoch_step1:\n","            training_step = 1\n","        elif epoch < args.epoch_step2:\n","            training_step = 2\n","        else:\n","            \n","            if epoch == args.epoch_step2:\n","                for param_group in optimizer.param_groups:\n","                    param_group[\"lr\"] = 5e-3\n","            training_step = 3    \n","\n","        print(\"<Main/line:128>\", \"/* Train EPOCH:\", epoch, \"(training_step:\", training_step,')')\n","        train(args, model, train_loader, optimizer, epoch, training_step, writer)\n","        \n","        if training_step == 3:\n","            \n","            ade = validate(args, model, val_loader, epoch, writer)\n","            is_best = ade < best_ade\n","            best_ade = min(ade, best_ade)\n","\n","            print('<Main/line:158> Validate(), ADE:',ade)\n","            print('ade:',ade)\n","            save_checkpoint(\n","                {\n","                    \"epoch\": epoch + 1,\n","                    \"state_dict\": model.state_dict(),\n","                    \"best_ade\": best_ade,\n","                    \"optimizer\": optimizer.state_dict(),\n","                },\n","                is_best,\n","                f\"./checkpoint/bestK{args.best_k}_checkpoint{epoch}.pth.tar\",\n","            )\n","\n","        execute_time += (time.time() - start_time)    \n","        print(\"<Main/line:167>\", \"*/ EPOCH execute:\",(time.time() - start_time),\", Total execute:\" , execute_time)\n","\n","    writer.close()\n","\n","import sys\n","def train(args, model, train_loader, optimizer, epoch, training_step, writer):\n","    losses = AverageMeter(\"Loss\", \":.6f\")\n","    progress = ProgressMeter(\n","        len(train_loader), [losses], prefix=\"Epoch: [{}]\".format(epoch)\n","    )\n","    model.train()\n","\n","    batch_start_time = time.time()\n","    for batch_idx, batch in enumerate(train_loader):\n","\n","        batch = [tensor.cuda() for tensor in batch] # 將資料移轉到CUDA\n","\n","        (\n","            obs_traj,\n","            pred_traj_gt,\n","            obs_traj_rel,\n","            pred_traj_gt_rel,\n","            non_linear_ped,\n","            loss_mask,\n","            seq_start_end,\n","        ) = batch\n","\n","        optimizer.zero_grad()  #SOP-1\n","\n","        loss = torch.zeros(1).to(pred_traj_gt)\n","        l2_loss_rel = []\n","        loss_mask = loss_mask[:, args.obs_len :]\n","\n","        batch_tmp_time = time.time()\n","        # 使預測值逼近model_input (obseved data)\n","        if training_step == 1 or training_step == 2:\n","            model_input = obs_traj_rel   # torch.Size([8, *164, 2])\n","\n","            pred_traj_fake_rel = model(  # torch.Size([8, *164, 2])\n","                model_input, obs_traj, seq_start_end, 1, training_step\n","            )\n","\n","            #print('<Main/line:217> Model Process Prediction of Batch:', (time.time()-batch_tmp_time), (time.time()-batch_start_time))\n","\n","            l2_loss_rel.append(\n","                # mode=\"raw\": 回傳每個傳入值的誤差 (已加總x,y&各time-step誤差)\n","                # ex: torch.Size([8, *164, 2]) -- (l2_loss) -> torch.Size([*164])\n","                l2_loss(pred_traj_fake_rel, model_input, loss_mask, mode=\"raw\")  #torch.Size([*164])\n","            )\n","            \n","        else:\n","            \n","            # [8, 164, 2]|| [12, 164, 2] => torch.Size([20, 164, 2])\n","            model_input = torch.cat((obs_traj_rel, pred_traj_gt_rel), dim=0)\n","\n","            start_time = time.time()\n","            for _ in range(args.best_k):\n","\n","                # in training_step==3 => 實際預測prediction(len=12)\n","                # pred_traj_fake_rel: torch.Size([12, 164, 2])\n","                pred_traj_fake_rel = model(model_input, obs_traj, seq_start_end, 0)\n","\n","                #print('args.best_k', args.best_k, ', index:',_, '\\npred_traj_fake_rel.size():',pred_traj_fake_rel.size())\n","                l2_loss_rel.append(\n","                    l2_loss( \n","                        pred_traj_fake_rel,\n","                        model_input[-args.pred_len :],\n","                        loss_mask,\n","                        mode=\"raw\",\n","                    ) # torch.Size([164])\n","                )\n","\n","        # best_k x (torch.Size([164])) -- (stack) ->  torch.Size([*164, best_k]): 每個軌跡best_k次誤差\n","        l2_loss_rel = torch.stack(l2_loss_rel, dim=1)   \n","\n","        l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n","\n","        # 統計每個time-step的軌跡誤差\n","        for start, end in seq_start_end.data:\n","\n","            _l2_loss_rel = torch.narrow(l2_loss_rel, 0, start, end - start) # 取出_l2_loss_rel範圍:(start, end)\n","            \n","            # 將取出的範圍(start, end)資料, 將best_k各次加總, ex: torch.Size([2, 15]) -> torch.Size([15])\n","            # tensor([[-0.6817,  0.6566, -0.6587, -0.0778,  0.6876],\n","            #         [-1.1618, -0.4350,  0.2843,  0.6821,  0.9042]]) torch.Size([2, 5])\n","            # -> torch.sum( , dim=0):\n","            # tensor( [-1.8435,  0.2215, -0.3743,  0.6042,  1.5917])  torch.Size([5])\n","            _l2_loss_rel = torch.sum(_l2_loss_rel, dim=0)  \n","            \n","            # torch.min(_l2_loss_rel): 找出best_k次加總後, 最小的誤差\n","            # 正規化誤差\n","            _l2_loss_rel = torch.min(_l2_loss_rel) / (\n","                (pred_traj_fake_rel.shape[0]) * (end - start)\n","            )\n","\n","            l2_loss_sum_rel += _l2_loss_rel\n","        \n","        loss += l2_loss_sum_rel\n","\n","        losses.update(loss.item(), obs_traj.shape[1])\n","        \n","        loss.backward()       #SOP-2\n","        optimizer.step()      #SOP-3 \n","\n","        '''\n","        if batch_idx % args.print_every == 0:\n","            progress.display(batch_idx)\n","        '''\n","        if batch_idx == len(train_loader)-1:\n","            print('<Main/line:277> Batch update over(best_K:',args.best_k, '), Loss:', loss)\n","    \n","    writer.add_scalar(\"train_loss\", losses.avg, epoch)\n","\n","\n","def validate(args, model, val_loader, epoch, writer):\n","    #ade = utils.AverageMeter(\"ADE\", \":.6f\")\n","    #fde = utils.AverageMeter(\"FDE\", \":.6f\")\n","    #progress = utils.ProgressMeter(len(val_loader), [ade, fde], prefix=\"Test: \")\n","\n","    ade = AverageMeter(\"ADE\", \":.6f\")\n","    fde = AverageMeter(\"FDE\", \":.6f\")\n","    progress = ProgressMeter(len(val_loader), [ade, fde], prefix=\"Test: \")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for i, batch in enumerate(val_loader):\n","            batch = [tensor.cuda() for tensor in batch]\n","            (\n","                obs_traj,\n","                pred_traj_gt,\n","                obs_traj_rel,\n","                pred_traj_gt_rel,\n","                non_linear_ped,\n","                loss_mask,\n","                seq_start_end,\n","            ) = batch\n","            loss_mask = loss_mask[:, args.obs_len :]\n","            pred_traj_fake_rel = model(obs_traj_rel, obs_traj, seq_start_end)\n","\n","            pred_traj_fake_rel_predpart = pred_traj_fake_rel[-args.pred_len :]\n","            pred_traj_fake = relative_to_abs(pred_traj_fake_rel_predpart, obs_traj[-1])\n","            ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n","            ade_ = ade_ / (obs_traj.shape[1] * args.pred_len)\n","\n","            fde_ = fde_ / (obs_traj.shape[1])\n","            ade.update(ade_, obs_traj.shape[1])\n","            fde.update(fde_, obs_traj.shape[1])\n","\n","            if i % args.print_every == 0:\n","                progress.display(i)\n","\n","        print(\n","            \" * ADE  {ade.avg:.3f} FDE  {fde.avg:.3f}\".format(ade=ade, fde=fde)\n","        )\n","        writer.add_scalar(\"val_ade\", ade.avg, epoch)\n","    return ade.avg\n","\n","\n","def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n","    ade = displacement_error(pred_traj_fake, pred_traj_gt)\n","    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1])\n","    return ade, fde\n","\n","\n","def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n","    if is_best:\n","        torch.save(state, filename)\n","        print(\"-------------- lower ade ----------------\")\n","        shutil.copyfile(filename, \"model_best.pth.tar\")\n","\n","\n","if __name__ == \"__main__\":\n","    #args = parser.parse_args()\n","    #utils.set_logger(os.path.join(args.log_dir, \"train.log\"))\n","    checkpoint_dir = \"./checkpoint\"\n","    if os.path.exists(checkpoint_dir) is False:\n","        os.mkdir(checkpoint_dir)\n","    main(args)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["<Utils/line:106> datasets: zara2 train\n","<Utils/line:106> datasets: zara2 test\n","<Main/line:48> Initializing train dataset\n","<DataLoader/line:7> path: STGAT/datasets/zara2/train\n","<Dataset/line:162> file: biwi_eth_train.txt\n","<Dataset/line:359> time-step數量: 40 (len(seq_list)) , 所有軌跡數量: (101, 2, 20)  (n_traj, 2, 20)\n","<Dataset/line:162> file: biwi_hotel_train.txt\n","<Dataset/line:359> time-step數量: 271 (len(seq_list)) , 所有軌跡數量: (859, 2, 20)  (n_traj, 2, 20)\n","<Dataset/line:162> file: crowds_zara01_train.txt\n","<Dataset/line:359> time-step數量: 774 (len(seq_list)) , 所有軌跡數量: (2759, 2, 20)  (n_traj, 2, 20)\n","<Dataset/line:162> file: crowds_zara03_train.txt\n","<Dataset/line:359> time-step數量: 1204 (len(seq_list)) , 所有軌跡數量: (4405, 2, 20)  (n_traj, 2, 20)\n","<Dataset/line:162> file: students001_train.txt\n","<Dataset/line:359> time-step數量: 1540 (len(seq_list)) , 所有軌跡數量: (16096, 2, 20)  (n_traj, 2, 20)\n","<Dataset/line:162> file: students003_train.txt\n","<Dataset/line:359> time-step數量: 1953 (len(seq_list)) , 所有軌跡數量: (25084, 2, 20)  (n_traj, 2, 20)\n","<Dataset/line:162> file: uni_examples_train.txt\n","<Dataset/line:359> time-step數量: 2112 (len(seq_list)) , 所有軌跡數量: (25507, 2, 20)  (n_traj, 2, 20)\n","<Dataset/line:427> 記錄各time-step內軌跡的index數量: 2112 (len(seq_start_end))\n","<Main/line:51> len of train_dset: 2112 , len of train_loader: 33\n","<Main/line:67> obs_traj_rel.size(): torch.Size([8, 164, 2])\n","<Main/line:68> pred_traj_gt_rel.size: torch.Size([12, 164, 2])\n","<DataLoader/line:7> path: STGAT/datasets/zara2/test\n","<Dataset/line:162> file: crowds_zara02.txt\n","<Dataset/line:359> time-step數量: 921 (len(seq_list)) , 所有軌跡數量: (5833, 2, 20)  (n_traj, 2, 20)\n","<Dataset/line:427> 記錄各time-step內軌跡的index數量: 921 (len(seq_start_end))\n","args.noise_dim [16]\n","<Main/line:97> Model.summary:\n"," TrajectoryGenerator(\n","  (gatencoder): GATEncoder(\n","    (gat_net): GAT(\n","      (layer_stack): ModuleList(\n","        (0): BatchMultiHeadGraphAttention (head:4 Units:32 -> 16)\n","        (1): BatchMultiHeadGraphAttention (head:1 Units:64 -> 32)\n","      )\n","    )\n","  )\n","  (traj_lstm_model): LSTMCell(2, 32)\n","  (graph_lstm_model): LSTMCell(32, 32)\n","  (traj_hidden2pos): Linear(in_features=32, out_features=2, bias=True)\n","  (traj_gat_hidden2pos): Linear(in_features=64, out_features=2, bias=True)\n","  (pred_hidden2pos): Linear(in_features=80, out_features=2, bias=True)\n","  (pred_lstm_model): LSTMCell(2, 80)\n",")\n","=> no checkpoint found at 'checkpoint/xxx.tar'\n","<Main/line:128> /* Train EPOCH: 0 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.7879], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6918864250183105 , Total execute: 1.6918840408325195\n","<Main/line:128> /* Train EPOCH: 1 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([1.3310], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6755850315093994 , Total execute: 3.3674674034118652\n","<Main/line:128> /* Train EPOCH: 2 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.5907], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7032780647277832 , Total execute: 5.070732831954956\n","<Main/line:128> /* Train EPOCH: 3 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.3373], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6757252216339111 , Total execute: 6.746456146240234\n","<Main/line:128> /* Train EPOCH: 4 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.2254], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6969170570373535 , Total execute: 8.443370580673218\n","<Main/line:128> /* Train EPOCH: 5 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1724], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6979095935821533 , Total execute: 10.141278266906738\n","<Main/line:128> /* Train EPOCH: 6 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1388], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6915996074676514 , Total execute: 11.832875728607178\n","<Main/line:128> /* Train EPOCH: 7 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1020], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.667344093322754 , Total execute: 13.500218391418457\n","<Main/line:128> /* Train EPOCH: 8 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1103], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6686081886291504 , Total execute: 15.168824911117554\n","<Main/line:128> /* Train EPOCH: 9 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0888], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6825110912322998 , Total execute: 16.85133409500122\n","<Main/line:128> /* Train EPOCH: 10 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0758], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6816859245300293 , Total execute: 18.53301739692688\n","<Main/line:128> /* Train EPOCH: 11 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0630], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.678420066833496 , Total execute: 20.211435317993164\n","<Main/line:128> /* Train EPOCH: 12 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0630], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6541109085083008 , Total execute: 21.86554455757141\n","<Main/line:128> /* Train EPOCH: 13 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0544], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7209315299987793 , Total execute: 23.586474418640137\n","<Main/line:128> /* Train EPOCH: 14 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0509], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.715550422668457 , Total execute: 25.302022218704224\n","<Main/line:128> /* Train EPOCH: 15 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0440], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6569769382476807 , Total execute: 26.958997011184692\n","<Main/line:128> /* Train EPOCH: 16 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0463], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6939468383789062 , Total execute: 28.652942180633545\n","<Main/line:128> /* Train EPOCH: 17 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0378], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.695068597793579 , Total execute: 30.348008632659912\n","<Main/line:128> /* Train EPOCH: 18 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0351], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6685142517089844 , Total execute: 32.016520977020264\n","<Main/line:128> /* Train EPOCH: 19 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0336], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6788032054901123 , Total execute: 33.695322036743164\n","<Main/line:128> /* Train EPOCH: 20 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0292], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6704111099243164 , Total execute: 35.36573100090027\n","<Main/line:128> /* Train EPOCH: 21 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0320], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.666227102279663 , Total execute: 37.0319561958313\n","<Main/line:128> /* Train EPOCH: 22 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0252], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6942439079284668 , Total execute: 38.726197957992554\n","<Main/line:128> /* Train EPOCH: 23 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0279], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6626007556915283 , Total execute: 40.38879656791687\n","<Main/line:128> /* Train EPOCH: 24 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0227], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6787195205688477 , Total execute: 42.067514419555664\n","<Main/line:128> /* Train EPOCH: 25 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0208], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6814708709716797 , Total execute: 43.74898362159729\n","<Main/line:128> /* Train EPOCH: 26 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0219], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6742665767669678 , Total execute: 45.42324876785278\n","<Main/line:128> /* Train EPOCH: 27 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0203], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7031688690185547 , Total execute: 47.126415967941284\n","<Main/line:128> /* Train EPOCH: 28 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0186], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6970109939575195 , Total execute: 48.82342505455017\n","<Main/line:128> /* Train EPOCH: 29 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0173], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6456341743469238 , Total execute: 50.46905732154846\n","<Main/line:128> /* Train EPOCH: 30 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0184], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6587414741516113 , Total execute: 52.12779664993286\n","<Main/line:128> /* Train EPOCH: 31 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0175], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6747241020202637 , Total execute: 53.80246615409851\n","<Main/line:128> /* Train EPOCH: 32 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0160], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.722656011581421 , Total execute: 55.52512049674988\n","<Main/line:128> /* Train EPOCH: 33 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0150], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6944231986999512 , Total execute: 57.219541788101196\n","<Main/line:128> /* Train EPOCH: 34 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0143], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.682906150817871 , Total execute: 58.902445554733276\n","<Main/line:128> /* Train EPOCH: 35 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0141], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.672898530960083 , Total execute: 60.575342416763306\n","<Main/line:128> /* Train EPOCH: 36 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0141], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6926124095916748 , Total execute: 62.26795268058777\n","<Main/line:128> /* Train EPOCH: 37 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0142], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7015902996063232 , Total execute: 63.96954131126404\n","<Main/line:128> /* Train EPOCH: 38 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0124], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.657832145690918 , Total execute: 65.6273717880249\n","<Main/line:128> /* Train EPOCH: 39 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0139], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7067232131958008 , Total execute: 67.33409309387207\n","<Main/line:128> /* Train EPOCH: 40 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0128], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6882641315460205 , Total execute: 69.02235555648804\n","<Main/line:128> /* Train EPOCH: 41 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0124], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6613719463348389 , Total execute: 70.68372535705566\n","<Main/line:128> /* Train EPOCH: 42 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0125], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.685499906539917 , Total execute: 72.36922311782837\n","<Main/line:128> /* Train EPOCH: 43 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0127], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6559767723083496 , Total execute: 74.02519750595093\n","<Main/line:128> /* Train EPOCH: 44 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0111], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6617231369018555 , Total execute: 75.68691921234131\n","<Main/line:128> /* Train EPOCH: 45 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0111], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6560091972351074 , Total execute: 77.34292650222778\n","<Main/line:128> /* Train EPOCH: 46 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0114], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.661557912826538 , Total execute: 79.00448250770569\n","<Main/line:128> /* Train EPOCH: 47 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0092], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6750593185424805 , Total execute: 80.67954015731812\n","<Main/line:128> /* Train EPOCH: 48 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0090], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6676521301269531 , Total execute: 82.34719038009644\n","<Main/line:128> /* Train EPOCH: 49 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0099], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6621973514556885 , Total execute: 84.00938630104065\n","<Main/line:128> /* Train EPOCH: 50 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0085], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6821045875549316 , Total execute: 85.69148874282837\n","<Main/line:128> /* Train EPOCH: 51 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0092], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.676671028137207 , Total execute: 87.36815786361694\n","<Main/line:128> /* Train EPOCH: 52 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0091], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6762118339538574 , Total execute: 89.04436779022217\n","<Main/line:128> /* Train EPOCH: 53 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0100], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6774787902832031 , Total execute: 90.72184467315674\n","<Main/line:128> /* Train EPOCH: 54 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0095], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7135274410247803 , Total execute: 92.43537044525146\n","<Main/line:128> /* Train EPOCH: 55 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0095], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6440455913543701 , Total execute: 94.07941341400146\n","<Main/line:128> /* Train EPOCH: 56 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0100], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.706380844116211 , Total execute: 95.78579258918762\n","<Main/line:128> /* Train EPOCH: 57 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0087], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6907234191894531 , Total execute: 97.47651410102844\n","<Main/line:128> /* Train EPOCH: 58 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0077], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.665815830230713 , Total execute: 99.14232778549194\n","<Main/line:128> /* Train EPOCH: 59 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0095], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.682018756866455 , Total execute: 100.82434463500977\n","<Main/line:128> /* Train EPOCH: 60 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0075], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6583678722381592 , Total execute: 102.48271012306213\n","<Main/line:128> /* Train EPOCH: 61 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0074], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.662278652191162 , Total execute: 104.14498734474182\n","<Main/line:128> /* Train EPOCH: 62 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0069], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6475481986999512 , Total execute: 105.79253339767456\n","<Main/line:128> /* Train EPOCH: 63 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0072], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6815118789672852 , Total execute: 107.47404336929321\n","<Main/line:128> /* Train EPOCH: 64 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0070], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6483674049377441 , Total execute: 109.12240052223206\n","<Main/line:128> /* Train EPOCH: 65 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0073], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6776814460754395 , Total execute: 110.80008029937744\n","<Main/line:128> /* Train EPOCH: 66 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0066], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6605570316314697 , Total execute: 112.46063542366028\n","<Main/line:128> /* Train EPOCH: 67 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0061], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6628994941711426 , Total execute: 114.12353301048279\n","<Main/line:128> /* Train EPOCH: 68 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0062], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.690659761428833 , Total execute: 115.81419110298157\n","<Main/line:128> /* Train EPOCH: 69 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0054], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.647979497909546 , Total execute: 117.46216821670532\n","<Main/line:128> /* Train EPOCH: 70 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0058], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6911702156066895 , Total execute: 119.15333652496338\n","<Main/line:128> /* Train EPOCH: 71 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0054], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7038507461547852 , Total execute: 120.85718536376953\n","<Main/line:128> /* Train EPOCH: 72 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0058], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7013792991638184 , Total execute: 122.55856227874756\n","<Main/line:128> /* Train EPOCH: 73 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0047], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6929214000701904 , Total execute: 124.25148177146912\n","<Main/line:128> /* Train EPOCH: 74 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0050], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6680850982666016 , Total execute: 125.91956496238708\n","<Main/line:128> /* Train EPOCH: 75 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0050], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6738462448120117 , Total execute: 127.59340906143188\n","<Main/line:128> /* Train EPOCH: 76 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0045], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7140426635742188 , Total execute: 129.3074495792389\n","<Main/line:128> /* Train EPOCH: 77 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0050], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7076051235198975 , Total execute: 131.01505303382874\n","<Main/line:128> /* Train EPOCH: 78 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0048], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.673504114151001 , Total execute: 132.6885552406311\n","<Main/line:128> /* Train EPOCH: 79 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0042], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6799864768981934 , Total execute: 134.36854004859924\n","<Main/line:128> /* Train EPOCH: 80 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0039], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.701240062713623 , Total execute: 136.0697784423828\n","<Main/line:128> /* Train EPOCH: 81 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0032], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6587789058685303 , Total execute: 137.7285554409027\n","<Main/line:128> /* Train EPOCH: 82 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0034], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.67244291305542 , Total execute: 139.4009964466095\n","<Main/line:128> /* Train EPOCH: 83 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0038], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.663679838180542 , Total execute: 141.06467413902283\n","<Main/line:128> /* Train EPOCH: 84 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0037], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6614539623260498 , Total execute: 142.72612619400024\n","<Main/line:128> /* Train EPOCH: 85 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0033], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.694838285446167 , Total execute: 144.42096257209778\n","<Main/line:128> /* Train EPOCH: 86 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0038], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.679966926574707 , Total execute: 146.10092759132385\n","<Main/line:128> /* Train EPOCH: 87 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0034], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.680718183517456 , Total execute: 147.78164386749268\n","<Main/line:128> /* Train EPOCH: 88 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0039], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.68276047706604 , Total execute: 149.46440243721008\n","<Main/line:128> /* Train EPOCH: 89 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0034], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.657273530960083 , Total execute: 151.1216742992401\n","<Main/line:128> /* Train EPOCH: 90 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0028], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6782691478729248 , Total execute: 152.79994130134583\n","<Main/line:128> /* Train EPOCH: 91 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0035], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.698545217514038 , Total execute: 154.49848437309265\n","<Main/line:128> /* Train EPOCH: 92 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0027], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.670149564743042 , Total execute: 156.16863226890564\n","<Main/line:128> /* Train EPOCH: 93 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0025], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.667435884475708 , Total execute: 157.83606600761414\n","<Main/line:128> /* Train EPOCH: 94 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0029], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6890842914581299 , Total execute: 159.52514839172363\n","<Main/line:128> /* Train EPOCH: 95 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0036], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6620457172393799 , Total execute: 161.18719267845154\n","<Main/line:128> /* Train EPOCH: 96 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0024], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6537981033325195 , Total execute: 162.84098887443542\n","<Main/line:128> /* Train EPOCH: 97 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0025], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.622896671295166 , Total execute: 164.46388339996338\n","<Main/line:128> /* Train EPOCH: 98 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0030], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6626348495483398 , Total execute: 166.1265161037445\n","<Main/line:128> /* Train EPOCH: 99 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0026], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7041420936584473 , Total execute: 167.83065629005432\n","<Main/line:128> /* Train EPOCH: 100 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0021], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6315464973449707 , Total execute: 169.46220088005066\n","<Main/line:128> /* Train EPOCH: 101 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0027], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.664635181427002 , Total execute: 171.1268343925476\n","<Main/line:128> /* Train EPOCH: 102 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0031], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6582045555114746 , Total execute: 172.7850365638733\n","<Main/line:128> /* Train EPOCH: 103 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0023], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6516528129577637 , Total execute: 174.43668723106384\n","<Main/line:128> /* Train EPOCH: 104 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0018], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6981968879699707 , Total execute: 176.1348819732666\n","<Main/line:128> /* Train EPOCH: 105 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0035], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6516978740692139 , Total execute: 177.78657793998718\n","<Main/line:128> /* Train EPOCH: 106 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0020], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6566038131713867 , Total execute: 179.44318008422852\n","<Main/line:128> /* Train EPOCH: 107 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0019], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6673967838287354 , Total execute: 181.11057543754578\n","<Main/line:128> /* Train EPOCH: 108 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0054], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6708457469940186 , Total execute: 182.78141951560974\n","<Main/line:128> /* Train EPOCH: 109 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0020], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6642735004425049 , Total execute: 184.4456913471222\n","<Main/line:128> /* Train EPOCH: 110 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0020], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6723074913024902 , Total execute: 186.11799693107605\n","<Main/line:128> /* Train EPOCH: 111 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0026], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.652637243270874 , Total execute: 187.7706320285797\n","<Main/line:128> /* Train EPOCH: 112 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0024], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6513230800628662 , Total execute: 189.42193984985352\n","<Main/line:128> /* Train EPOCH: 113 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0016], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6536121368408203 , Total execute: 191.07555079460144\n","<Main/line:128> /* Train EPOCH: 114 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0021], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7065129280090332 , Total execute: 192.78206157684326\n","<Main/line:128> /* Train EPOCH: 115 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0021], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6589076519012451 , Total execute: 194.44096732139587\n","<Main/line:128> /* Train EPOCH: 116 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0018], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6657965183258057 , Total execute: 196.10676217079163\n","<Main/line:128> /* Train EPOCH: 117 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0018], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6644482612609863 , Total execute: 197.77120876312256\n","<Main/line:128> /* Train EPOCH: 118 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0028], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6758887767791748 , Total execute: 199.44709610939026\n","<Main/line:128> /* Train EPOCH: 119 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0014], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6350998878479004 , Total execute: 201.08219385147095\n","<Main/line:128> /* Train EPOCH: 120 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0016], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6778368949890137 , Total execute: 202.76002836227417\n","<Main/line:128> /* Train EPOCH: 121 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0028], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6577067375183105 , Total execute: 204.41773343086243\n","<Main/line:128> /* Train EPOCH: 122 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0017], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.671818494796753 , Total execute: 206.08955001831055\n","<Main/line:128> /* Train EPOCH: 123 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0016], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.677077293395996 , Total execute: 207.7666256427765\n","<Main/line:128> /* Train EPOCH: 124 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0032], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.675621509552002 , Total execute: 209.44224524497986\n","<Main/line:128> /* Train EPOCH: 125 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0015], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6714701652526855 , Total execute: 211.1137137413025\n","<Main/line:128> /* Train EPOCH: 126 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0013], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.718968391418457 , Total execute: 212.8326804637909\n","<Main/line:128> /* Train EPOCH: 127 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0024], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6981539726257324 , Total execute: 214.53083276748657\n","<Main/line:128> /* Train EPOCH: 128 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0018], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6682872772216797 , Total execute: 216.19911789894104\n","<Main/line:128> /* Train EPOCH: 129 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0011], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6740095615386963 , Total execute: 217.87312602996826\n","<Main/line:128> /* Train EPOCH: 130 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0025], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6718237400054932 , Total execute: 219.54494738578796\n","<Main/line:128> /* Train EPOCH: 131 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0022], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6840176582336426 , Total execute: 221.22896313667297\n","<Main/line:128> /* Train EPOCH: 132 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0013], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.7107372283935547 , Total execute: 222.93969821929932\n","<Main/line:128> /* Train EPOCH: 133 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0040], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6677014827728271 , Total execute: 224.6073980331421\n","<Main/line:128> /* Train EPOCH: 134 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0013], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.675652265548706 , Total execute: 226.28304815292358\n","<Main/line:128> /* Train EPOCH: 135 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0011], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.666841983795166 , Total execute: 227.94988870620728\n","<Main/line:128> /* Train EPOCH: 136 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0015], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6599478721618652 , Total execute: 229.6098346710205\n","<Main/line:128> /* Train EPOCH: 137 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0015], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.664896011352539 , Total execute: 231.274729013443\n","<Main/line:128> /* Train EPOCH: 138 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0019], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6575984954833984 , Total execute: 232.93232560157776\n","<Main/line:128> /* Train EPOCH: 139 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0020], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.663133144378662 , Total execute: 234.59545707702637\n","<Main/line:128> /* Train EPOCH: 140 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0016], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6789700984954834 , Total execute: 236.27442526817322\n","<Main/line:128> /* Train EPOCH: 141 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0015], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6607463359832764 , Total execute: 237.93516969680786\n","<Main/line:128> /* Train EPOCH: 142 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0014], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6617753505706787 , Total execute: 239.5969421863556\n","<Main/line:128> /* Train EPOCH: 143 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0018], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6938540935516357 , Total execute: 241.2907943725586\n","<Main/line:128> /* Train EPOCH: 144 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0014], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.66949462890625 , Total execute: 242.9602870941162\n","<Main/line:128> /* Train EPOCH: 145 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0015], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6793737411499023 , Total execute: 244.63965892791748\n","<Main/line:128> /* Train EPOCH: 146 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0017], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.667957067489624 , Total execute: 246.30761432647705\n","<Main/line:128> /* Train EPOCH: 147 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0016], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.682347059249878 , Total execute: 247.9899594783783\n","<Main/line:128> /* Train EPOCH: 148 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0013], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.686126947402954 , Total execute: 249.67608451843262\n","<Main/line:128> /* Train EPOCH: 149 (training_step: 1 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0020], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 1.6747829914093018 , Total execute: 251.35086512565613\n","<Main/line:128> /* Train EPOCH: 150 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.7905], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.924831867218018 , Total execute: 260.27569460868835\n","<Main/line:128> /* Train EPOCH: 151 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([1.4896], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 9.078837394714355 , Total execute: 269.3545296192169\n","<Main/line:128> /* Train EPOCH: 152 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.7383], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 9.040193319320679 , Total execute: 278.3947205543518\n","<Main/line:128> /* Train EPOCH: 153 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.4535], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.978900909423828 , Total execute: 287.37361907958984\n","<Main/line:128> /* Train EPOCH: 154 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.2868], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.897018194198608 , Total execute: 296.27063488960266\n","<Main/line:128> /* Train EPOCH: 155 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.2666], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.876636981964111 , Total execute: 305.14726853370667\n","<Main/line:128> /* Train EPOCH: 156 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.2178], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.903151988983154 , Total execute: 314.0504183769226\n","<Main/line:128> /* Train EPOCH: 157 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.2144], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.87969708442688 , Total execute: 322.9301133155823\n","<Main/line:128> /* Train EPOCH: 158 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1804], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.856502771377563 , Total execute: 331.7866141796112\n","<Main/line:128> /* Train EPOCH: 159 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1593], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.896185398101807 , Total execute: 340.6827974319458\n","<Main/line:128> /* Train EPOCH: 160 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1443], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.902148723602295 , Total execute: 349.58494424819946\n","<Main/line:128> /* Train EPOCH: 161 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1273], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.898605823516846 , Total execute: 358.4835476875305\n","<Main/line:128> /* Train EPOCH: 162 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1122], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.976256370544434 , Total execute: 367.45980167388916\n","<Main/line:128> /* Train EPOCH: 163 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1231], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.953419208526611 , Total execute: 376.41321849823\n","<Main/line:128> /* Train EPOCH: 164 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1178], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.946736335754395 , Total execute: 385.35995268821716\n","<Main/line:128> /* Train EPOCH: 165 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.1061], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.89674973487854 , Total execute: 394.2567002773285\n","<Main/line:128> /* Train EPOCH: 166 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0949], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.93976902961731 , Total execute: 403.1964671611786\n","<Main/line:128> /* Train EPOCH: 167 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0911], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.925128698348999 , Total execute: 412.1215937137604\n","<Main/line:128> /* Train EPOCH: 168 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0809], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.944282293319702 , Total execute: 421.06587409973145\n","<Main/line:128> /* Train EPOCH: 169 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0776], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.86602258682251 , Total execute: 429.9318947792053\n","<Main/line:128> /* Train EPOCH: 170 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0683], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.991226434707642 , Total execute: 438.92311906814575\n","<Main/line:128> /* Train EPOCH: 171 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0695], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.893855333328247 , Total execute: 447.81697249412537\n","<Main/line:128> /* Train EPOCH: 172 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0648], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.918927192687988 , Total execute: 456.7358977794647\n","<Main/line:128> /* Train EPOCH: 173 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0729], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.961000204086304 , Total execute: 465.69689559936523\n","<Main/line:128> /* Train EPOCH: 174 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0549], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.891357421875 , Total execute: 474.588250875473\n","<Main/line:128> /* Train EPOCH: 175 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0528], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.910284519195557 , Total execute: 483.4985337257385\n","<Main/line:128> /* Train EPOCH: 176 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0543], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.922966241836548 , Total execute: 492.4214975833893\n","<Main/line:128> /* Train EPOCH: 177 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0482], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.9367835521698 , Total execute: 501.35827898979187\n","<Main/line:128> /* Train EPOCH: 178 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0524], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.946885824203491 , Total execute: 510.3051631450653\n","<Main/line:128> /* Train EPOCH: 179 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0487], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.889646768569946 , Total execute: 519.1948075294495\n","<Main/line:128> /* Train EPOCH: 180 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0436], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.877760410308838 , Total execute: 528.0725662708282\n","<Main/line:128> /* Train EPOCH: 181 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0426], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.833442687988281 , Total execute: 536.9060068130493\n","<Main/line:128> /* Train EPOCH: 182 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0464], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.926771879196167 , Total execute: 545.8327767848969\n","<Main/line:128> /* Train EPOCH: 183 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0414], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.962238311767578 , Total execute: 554.7950129508972\n","<Main/line:128> /* Train EPOCH: 184 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0478], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.858908891677856 , Total execute: 563.6539196968079\n","<Main/line:128> /* Train EPOCH: 185 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0416], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.98144793510437 , Total execute: 572.6353652477264\n","<Main/line:128> /* Train EPOCH: 186 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0402], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 9.016718864440918 , Total execute: 581.6520817279816\n","<Main/line:128> /* Train EPOCH: 187 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0367], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.89062786102295 , Total execute: 590.5427072048187\n","<Main/line:128> /* Train EPOCH: 188 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0349], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.964405059814453 , Total execute: 599.5071103572845\n","<Main/line:128> /* Train EPOCH: 189 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0305], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.949187517166138 , Total execute: 608.4562957286835\n","<Main/line:128> /* Train EPOCH: 190 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0318], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.878357648849487 , Total execute: 617.3346512317657\n","<Main/line:128> /* Train EPOCH: 191 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0287], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.88257908821106 , Total execute: 626.2172284126282\n","<Main/line:128> /* Train EPOCH: 192 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0271], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.932563304901123 , Total execute: 635.1497898101807\n","<Main/line:128> /* Train EPOCH: 193 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0275], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.894806623458862 , Total execute: 644.0445942878723\n","<Main/line:128> /* Train EPOCH: 194 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0258], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.880990982055664 , Total execute: 652.9255828857422\n","<Main/line:128> /* Train EPOCH: 195 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0265], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.991181373596191 , Total execute: 661.916761636734\n","<Main/line:128> /* Train EPOCH: 196 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0248], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.89801812171936 , Total execute: 670.8147776126862\n","<Main/line:128> /* Train EPOCH: 197 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0218], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.860431671142578 , Total execute: 679.6752071380615\n","<Main/line:128> /* Train EPOCH: 198 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0227], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.821592092514038 , Total execute: 688.4967970848083\n","<Main/line:128> /* Train EPOCH: 199 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0202], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.877640724182129 , Total execute: 697.3744356632233\n","<Main/line:128> /* Train EPOCH: 200 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0205], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.83978009223938 , Total execute: 706.2142133712769\n","<Main/line:128> /* Train EPOCH: 201 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0200], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.841853857040405 , Total execute: 715.0560653209686\n","<Main/line:128> /* Train EPOCH: 202 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0198], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.88151741027832 , Total execute: 723.9375808238983\n","<Main/line:128> /* Train EPOCH: 203 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0187], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.916252613067627 , Total execute: 732.8538315296173\n","<Main/line:128> /* Train EPOCH: 204 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0200], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.926661252975464 , Total execute: 741.7804908752441\n","<Main/line:128> /* Train EPOCH: 205 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0242], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.825554847717285 , Total execute: 750.6060433387756\n","<Main/line:128> /* Train EPOCH: 206 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0219], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.875205755233765 , Total execute: 759.4812476634979\n","<Main/line:128> /* Train EPOCH: 207 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0189], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.836072444915771 , Total execute: 768.3173177242279\n","<Main/line:128> /* Train EPOCH: 208 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0185], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.761609315872192 , Total execute: 777.0789248943329\n","<Main/line:128> /* Train EPOCH: 209 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0162], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.789339542388916 , Total execute: 785.8682622909546\n","<Main/line:128> /* Train EPOCH: 210 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0146], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.724001407623291 , Total execute: 794.5922620296478\n","<Main/line:128> /* Train EPOCH: 211 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0166], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.811940908432007 , Total execute: 803.404200553894\n","<Main/line:128> /* Train EPOCH: 212 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0264], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.86887812614441 , Total execute: 812.2730770111084\n","<Main/line:128> /* Train EPOCH: 213 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0179], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.877380847930908 , Total execute: 821.1504557132721\n","<Main/line:128> /* Train EPOCH: 214 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0142], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.912893056869507 , Total execute: 830.063346862793\n","<Main/line:128> /* Train EPOCH: 215 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0148], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.818517684936523 , Total execute: 838.8818628787994\n","<Main/line:128> /* Train EPOCH: 216 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0145], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.838440895080566 , Total execute: 847.7203016281128\n","<Main/line:128> /* Train EPOCH: 217 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0131], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.917031049728394 , Total execute: 856.6373302936554\n","<Main/line:128> /* Train EPOCH: 218 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0113], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.878816843032837 , Total execute: 865.5161452293396\n","<Main/line:128> /* Train EPOCH: 219 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0125], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.890260219573975 , Total execute: 874.4064033031464\n","<Main/line:128> /* Train EPOCH: 220 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0115], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.978498697280884 , Total execute: 883.3849000930786\n","<Main/line:128> /* Train EPOCH: 221 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0102], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.944309949874878 , Total execute: 892.3292078971863\n","<Main/line:128> /* Train EPOCH: 222 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0103], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.832031726837158 , Total execute: 901.1612377166748\n","<Main/line:128> /* Train EPOCH: 223 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0099], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.843214750289917 , Total execute: 910.0044505596161\n","<Main/line:128> /* Train EPOCH: 224 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0089], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.801015138626099 , Total execute: 918.8054637908936\n","<Main/line:128> /* Train EPOCH: 225 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0100], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.877137660980225 , Total execute: 927.6825995445251\n","<Main/line:128> /* Train EPOCH: 226 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0088], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.811300039291382 , Total execute: 936.4938976764679\n","<Main/line:128> /* Train EPOCH: 227 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0090], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.878317832946777 , Total execute: 945.3722133636475\n","<Main/line:128> /* Train EPOCH: 228 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0086], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.864624738693237 , Total execute: 954.2368359565735\n","<Main/line:128> /* Train EPOCH: 229 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0091], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.8302743434906 , Total execute: 963.0671081542969\n","<Main/line:128> /* Train EPOCH: 230 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0088], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.760844707489014 , Total execute: 971.8279507160187\n","<Main/line:128> /* Train EPOCH: 231 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0085], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.792070150375366 , Total execute: 980.6200189590454\n","<Main/line:128> /* Train EPOCH: 232 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0080], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.818482160568237 , Total execute: 989.438499212265\n","<Main/line:128> /* Train EPOCH: 233 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0070], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.83490514755249 , Total execute: 998.2734010219574\n","<Main/line:128> /* Train EPOCH: 234 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0070], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.833549499511719 , Total execute: 1007.1069483757019\n","<Main/line:128> /* Train EPOCH: 235 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0065], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.874561548233032 , Total execute: 1015.9815077781677\n","<Main/line:128> /* Train EPOCH: 236 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0065], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.786857843399048 , Total execute: 1024.7683637142181\n","<Main/line:128> /* Train EPOCH: 237 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0065], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.814435005187988 , Total execute: 1033.5827968120575\n","<Main/line:128> /* Train EPOCH: 238 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0058], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.909245252609253 , Total execute: 1042.4920394420624\n","<Main/line:128> /* Train EPOCH: 239 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0053], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.924875736236572 , Total execute: 1051.4169130325317\n","<Main/line:128> /* Train EPOCH: 240 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0052], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.890910148620605 , Total execute: 1060.3078207969666\n","<Main/line:128> /* Train EPOCH: 241 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0053], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.838555097579956 , Total execute: 1069.1463737487793\n","<Main/line:128> /* Train EPOCH: 242 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0048], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.780879259109497 , Total execute: 1077.9272503852844\n","<Main/line:128> /* Train EPOCH: 243 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0044], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.857640743255615 , Total execute: 1086.7848892211914\n","<Main/line:128> /* Train EPOCH: 244 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0051], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.875357151031494 , Total execute: 1095.6602442264557\n","<Main/line:128> /* Train EPOCH: 245 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0049], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.814708709716797 , Total execute: 1104.4749510288239\n","<Main/line:128> /* Train EPOCH: 246 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0045], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.848354578018188 , Total execute: 1113.3233034610748\n","<Main/line:128> /* Train EPOCH: 247 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0045], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.918243169784546 , Total execute: 1122.2415447235107\n","<Main/line:128> /* Train EPOCH: 248 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0035], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.81807279586792 , Total execute: 1131.0596158504486\n","<Main/line:128> /* Train EPOCH: 249 (training_step: 2 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([0.0045], device='cuda:0', grad_fn=<AddBackward0>)\n","<Main/line:167> */ EPOCH execute: 8.807897329330444 , Total execute: 1139.8675112724304\n","<Main/line:128> /* Train EPOCH: 250 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([9.4972], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.819639 (0.819639)\tFDE 1.685976 (1.685976)\n","Test: [ 5/15]\tADE 0.538052 (0.667469)\tFDE 1.014247 (1.348608)\n","Test: [10/15]\tADE 0.518835 (0.579170)\tFDE 0.966413 (1.134396)\n"," * ADE  0.576 FDE  1.124\n","<Main/line:158> Validate(), ADE: tensor(0.5756, device='cuda:0')\n","ade: tensor(0.5756, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.92453646659851 , Total execute: 1151.7920444011688\n","<Main/line:128> /* Train EPOCH: 251 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([6.7249], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.877334 (0.877334)\tFDE 1.737971 (1.737971)\n","Test: [ 5/15]\tADE 0.476406 (0.646046)\tFDE 0.945156 (1.289575)\n","Test: [10/15]\tADE 0.478440 (0.521918)\tFDE 0.907649 (1.036547)\n"," * ADE  0.518 FDE  1.034\n","<Main/line:158> Validate(), ADE: tensor(0.5177, device='cuda:0')\n","ade: tensor(0.5177, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.257898092269897 , Total execute: 1163.0499408245087\n","<Main/line:128> /* Train EPOCH: 252 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([5.0725], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.648286 (0.648286)\tFDE 1.253892 (1.253892)\n","Test: [ 5/15]\tADE 0.466129 (0.537573)\tFDE 0.942884 (1.098635)\n","Test: [10/15]\tADE 0.466975 (0.462145)\tFDE 0.931426 (0.957237)\n"," * ADE  0.463 FDE  0.965\n","<Main/line:158> Validate(), ADE: tensor(0.4633, device='cuda:0')\n","ade: tensor(0.4633, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.365922212600708 , Total execute: 1174.415861606598\n","<Main/line:128> /* Train EPOCH: 253 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.1377], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.632553 (0.632553)\tFDE 1.293748 (1.293748)\n","Test: [ 5/15]\tADE 0.425586 (0.510845)\tFDE 0.858006 (1.056147)\n","Test: [10/15]\tADE 0.426537 (0.435343)\tFDE 0.828022 (0.886189)\n"," * ADE  0.432 FDE  0.881\n","<Main/line:158> Validate(), ADE: tensor(0.4318, device='cuda:0')\n","ade: tensor(0.4318, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.297461032867432 , Total execute: 1185.7133209705353\n","<Main/line:128> /* Train EPOCH: 254 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([5.3913], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.512251 (0.512251)\tFDE 1.004685 (1.004685)\n","Test: [ 5/15]\tADE 0.422360 (0.473081)\tFDE 0.861629 (0.978818)\n","Test: [10/15]\tADE 0.417736 (0.412107)\tFDE 0.843878 (0.855199)\n"," * ADE  0.418 FDE  0.866\n","<Main/line:158> Validate(), ADE: tensor(0.4176, device='cuda:0')\n","ade: tensor(0.4176, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.484367609024048 , Total execute: 1197.1976866722107\n","<Main/line:128> /* Train EPOCH: 255 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([6.9387], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.674697 (0.674697)\tFDE 1.500091 (1.500091)\n","Test: [ 5/15]\tADE 0.391403 (0.535516)\tFDE 0.820010 (1.164148)\n","Test: [10/15]\tADE 0.414700 (0.443632)\tFDE 0.837034 (0.947531)\n"," * ADE  0.442 FDE  0.942\n","<Main/line:158> Validate(), ADE: tensor(0.4417, device='cuda:0')\n","ade: tensor(0.4417, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.330917119979858 , Total execute: 1208.5286028385162\n","<Main/line:128> /* Train EPOCH: 256 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.8011], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.534784 (0.534784)\tFDE 1.132007 (1.132007)\n","Test: [ 5/15]\tADE 0.393747 (0.467964)\tFDE 0.807786 (0.995360)\n","Test: [10/15]\tADE 0.394924 (0.404845)\tFDE 0.784075 (0.842927)\n"," * ADE  0.406 FDE  0.846\n","<Main/line:158> Validate(), ADE: tensor(0.4060, device='cuda:0')\n","ade: tensor(0.4060, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.270774602890015 , Total execute: 1219.7993757724762\n","<Main/line:128> /* Train EPOCH: 257 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.9822], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.505117 (0.505117)\tFDE 1.075054 (1.075054)\n","Test: [ 5/15]\tADE 0.471440 (0.506275)\tFDE 1.021658 (1.101516)\n","Test: [10/15]\tADE 0.490121 (0.476174)\tFDE 1.036073 (1.035875)\n"," * ADE  0.480 FDE  1.042\n","<Main/line:158> Validate(), ADE: tensor(0.4800, device='cuda:0')\n","ade: tensor(0.4800, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.360825777053833 , Total execute: 1231.1602005958557\n","<Main/line:128> /* Train EPOCH: 258 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.6661], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.487513 (0.487513)\tFDE 1.032001 (1.032001)\n","Test: [ 5/15]\tADE 0.417056 (0.464801)\tFDE 0.861443 (0.991083)\n","Test: [10/15]\tADE 0.435812 (0.418944)\tFDE 0.877695 (0.882240)\n"," * ADE  0.422 FDE  0.885\n","<Main/line:158> Validate(), ADE: tensor(0.4215, device='cuda:0')\n","ade: tensor(0.4215, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.32630467414856 , Total execute: 1242.48650431633\n","<Main/line:128> /* Train EPOCH: 259 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.2311], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.515842 (0.515842)\tFDE 1.123579 (1.123579)\n","Test: [ 5/15]\tADE 0.357414 (0.436854)\tFDE 0.726883 (0.941402)\n","Test: [10/15]\tADE 0.380871 (0.370367)\tFDE 0.761162 (0.781718)\n"," * ADE  0.367 FDE  0.775\n","<Main/line:158> Validate(), ADE: tensor(0.3675, device='cuda:0')\n","ade: tensor(0.3675, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.240105390548706 , Total execute: 1253.72660779953\n","<Main/line:128> /* Train EPOCH: 260 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.1607], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.502571 (0.502571)\tFDE 1.087710 (1.087710)\n","Test: [ 5/15]\tADE 0.337054 (0.421247)\tFDE 0.690186 (0.912201)\n","Test: [10/15]\tADE 0.379138 (0.360112)\tFDE 0.773126 (0.769097)\n"," * ADE  0.357 FDE  0.761\n","<Main/line:158> Validate(), ADE: tensor(0.3567, device='cuda:0')\n","ade: tensor(0.3567, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.441374063491821 , Total execute: 1265.1679804325104\n","<Main/line:128> /* Train EPOCH: 261 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.8458], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.464313 (0.464313)\tFDE 0.986316 (0.986316)\n","Test: [ 5/15]\tADE 0.333921 (0.399355)\tFDE 0.671923 (0.853178)\n","Test: [10/15]\tADE 0.366140 (0.344022)\tFDE 0.738570 (0.723963)\n"," * ADE  0.343 FDE  0.721\n","<Main/line:158> Validate(), ADE: tensor(0.3427, device='cuda:0')\n","ade: tensor(0.3427, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.311925649642944 , Total execute: 1276.4799046516418\n","<Main/line:128> /* Train EPOCH: 262 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.8576], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.450565 (0.450565)\tFDE 0.952422 (0.952422)\n","Test: [ 5/15]\tADE 0.351468 (0.411708)\tFDE 0.723536 (0.881240)\n","Test: [10/15]\tADE 0.398593 (0.369578)\tFDE 0.815872 (0.783752)\n"," * ADE  0.370 FDE  0.786\n","<Main/line:158> Validate(), ADE: tensor(0.3704, device='cuda:0')\n","ade: tensor(0.3704, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.235191106796265 , Total execute: 1287.7150948047638\n","<Main/line:128> /* Train EPOCH: 263 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.8392], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.472213 (0.472213)\tFDE 0.986793 (0.986793)\n","Test: [ 5/15]\tADE 0.384957 (0.433505)\tFDE 0.804659 (0.926727)\n","Test: [10/15]\tADE 0.415276 (0.386008)\tFDE 0.858848 (0.822579)\n"," * ADE  0.387 FDE  0.825\n","<Main/line:158> Validate(), ADE: tensor(0.3869, device='cuda:0')\n","ade: tensor(0.3869, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.181442022323608 , Total execute: 1298.896535873413\n","<Main/line:128> /* Train EPOCH: 264 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.7794], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.462853 (0.462853)\tFDE 0.973418 (0.973418)\n","Test: [ 5/15]\tADE 0.374856 (0.425824)\tFDE 0.775325 (0.907226)\n","Test: [10/15]\tADE 0.400374 (0.373086)\tFDE 0.821431 (0.793024)\n"," * ADE  0.374 FDE  0.797\n","<Main/line:158> Validate(), ADE: tensor(0.3744, device='cuda:0')\n","ade: tensor(0.3744, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.28377103805542 , Total execute: 1310.1803061962128\n","<Main/line:128> /* Train EPOCH: 265 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.7270], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.459915 (0.459915)\tFDE 0.971823 (0.971823)\n","Test: [ 5/15]\tADE 0.333075 (0.400795)\tFDE 0.675692 (0.857202)\n","Test: [10/15]\tADE 0.376472 (0.346825)\tFDE 0.767994 (0.733176)\n"," * ADE  0.346 FDE  0.731\n","<Main/line:158> Validate(), ADE: tensor(0.3455, device='cuda:0')\n","ade: tensor(0.3455, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.189867973327637 , Total execute: 1321.3701734542847\n","<Main/line:128> /* Train EPOCH: 266 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.6851], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.460552 (0.460552)\tFDE 0.968178 (0.968178)\n","Test: [ 5/15]\tADE 0.346078 (0.401585)\tFDE 0.699199 (0.855281)\n","Test: [10/15]\tADE 0.375175 (0.345122)\tFDE 0.762986 (0.728097)\n"," * ADE  0.344 FDE  0.728\n","<Main/line:158> Validate(), ADE: tensor(0.3443, device='cuda:0')\n","ade: tensor(0.3443, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.222745656967163 , Total execute: 1332.5929181575775\n","<Main/line:128> /* Train EPOCH: 267 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.6521], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.449807 (0.449807)\tFDE 0.952664 (0.952664)\n","Test: [ 5/15]\tADE 0.348534 (0.402037)\tFDE 0.710804 (0.859949)\n","Test: [10/15]\tADE 0.389996 (0.352307)\tFDE 0.801733 (0.747611)\n"," * ADE  0.352 FDE  0.748\n","<Main/line:158> Validate(), ADE: tensor(0.3521, device='cuda:0')\n","ade: tensor(0.3521, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.20389699935913 , Total execute: 1343.796814441681\n","<Main/line:128> /* Train EPOCH: 268 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.6745], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.449409 (0.449409)\tFDE 0.951183 (0.951183)\n","Test: [ 5/15]\tADE 0.362561 (0.410561)\tFDE 0.739842 (0.876720)\n","Test: [10/15]\tADE 0.384897 (0.359125)\tFDE 0.794666 (0.762689)\n"," * ADE  0.359 FDE  0.764\n","<Main/line:158> Validate(), ADE: tensor(0.3594, device='cuda:0')\n","ade: tensor(0.3594, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.26858925819397 , Total execute: 1355.0654027462006\n","<Main/line:128> /* Train EPOCH: 269 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5920], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.459772 (0.459772)\tFDE 0.963056 (0.963056)\n","Test: [ 5/15]\tADE 0.354806 (0.405429)\tFDE 0.720322 (0.862612)\n","Test: [10/15]\tADE 0.377243 (0.352857)\tFDE 0.775187 (0.746872)\n"," * ADE  0.352 FDE  0.747\n","<Main/line:158> Validate(), ADE: tensor(0.3523, device='cuda:0')\n","ade: tensor(0.3523, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.178640365600586 , Total execute: 1366.2440421581268\n","<Main/line:128> /* Train EPOCH: 270 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5805], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.463218 (0.463217)\tFDE 0.984167 (0.984167)\n","Test: [ 5/15]\tADE 0.347388 (0.404824)\tFDE 0.704749 (0.862644)\n","Test: [10/15]\tADE 0.371660 (0.350100)\tFDE 0.759254 (0.739085)\n"," * ADE  0.350 FDE  0.740\n","<Main/line:158> Validate(), ADE: tensor(0.3502, device='cuda:0')\n","ade: tensor(0.3502, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.104618310928345 , Total execute: 1377.3486597537994\n","<Main/line:128> /* Train EPOCH: 271 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5679], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.458213 (0.458213)\tFDE 0.964618 (0.964618)\n","Test: [ 5/15]\tADE 0.334169 (0.395201)\tFDE 0.673345 (0.841444)\n","Test: [10/15]\tADE 0.370981 (0.339587)\tFDE 0.757891 (0.717653)\n"," * ADE  0.339 FDE  0.718\n","<Main/line:158> Validate(), ADE: tensor(0.3393, device='cuda:0')\n","ade: tensor(0.3393, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.78514313697815 , Total execute: 1389.1338000297546\n","<Main/line:128> /* Train EPOCH: 272 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5576], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.453902 (0.453902)\tFDE 0.959980 (0.959980)\n","Test: [ 5/15]\tADE 0.339858 (0.398154)\tFDE 0.688714 (0.847886)\n","Test: [10/15]\tADE 0.371453 (0.342855)\tFDE 0.760956 (0.724542)\n"," * ADE  0.342 FDE  0.725\n","<Main/line:158> Validate(), ADE: tensor(0.3425, device='cuda:0')\n","ade: tensor(0.3425, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.12084174156189 , Total execute: 1400.2546410560608\n","<Main/line:128> /* Train EPOCH: 273 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5145], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.458842 (0.458842)\tFDE 0.976765 (0.976765)\n","Test: [ 5/15]\tADE 0.327130 (0.394557)\tFDE 0.659597 (0.841276)\n","Test: [10/15]\tADE 0.371043 (0.338493)\tFDE 0.760793 (0.715883)\n"," * ADE  0.338 FDE  0.716\n","<Main/line:158> Validate(), ADE: tensor(0.3384, device='cuda:0')\n","ade: tensor(0.3384, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.145095109939575 , Total execute: 1411.399734735489\n","<Main/line:128> /* Train EPOCH: 274 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5004], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.459482 (0.459482)\tFDE 0.977263 (0.977263)\n","Test: [ 5/15]\tADE 0.325139 (0.390110)\tFDE 0.653827 (0.832529)\n","Test: [10/15]\tADE 0.363133 (0.333151)\tFDE 0.741653 (0.704277)\n"," * ADE  0.332 FDE  0.703\n","<Main/line:158> Validate(), ADE: tensor(0.3316, device='cuda:0')\n","ade: tensor(0.3316, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.27519965171814 , Total execute: 1422.6749329566956\n","<Main/line:128> /* Train EPOCH: 275 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5189], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.454663 (0.454663)\tFDE 0.967614 (0.967614)\n","Test: [ 5/15]\tADE 0.330575 (0.391862)\tFDE 0.667126 (0.836845)\n","Test: [10/15]\tADE 0.364319 (0.334305)\tFDE 0.749164 (0.707420)\n"," * ADE  0.334 FDE  0.707\n","<Main/line:158> Validate(), ADE: tensor(0.3336, device='cuda:0')\n","ade: tensor(0.3336, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.162732362747192 , Total execute: 1433.8376641273499\n","<Main/line:128> /* Train EPOCH: 276 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5029], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.458009 (0.458009)\tFDE 0.970733 (0.970733)\n","Test: [ 5/15]\tADE 0.322479 (0.388660)\tFDE 0.652636 (0.832567)\n","Test: [10/15]\tADE 0.364845 (0.332477)\tFDE 0.750391 (0.706359)\n"," * ADE  0.332 FDE  0.706\n","<Main/line:158> Validate(), ADE: tensor(0.3317, device='cuda:0')\n","ade: tensor(0.3317, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.296819686889648 , Total execute: 1445.1344828605652\n","<Main/line:128> /* Train EPOCH: 277 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5133], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.460094 (0.460094)\tFDE 0.976295 (0.976295)\n","Test: [ 5/15]\tADE 0.329429 (0.389934)\tFDE 0.666274 (0.836648)\n","Test: [10/15]\tADE 0.365173 (0.333453)\tFDE 0.752991 (0.710237)\n"," * ADE  0.332 FDE  0.708\n","<Main/line:158> Validate(), ADE: tensor(0.3319, device='cuda:0')\n","ade: tensor(0.3319, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.258198738098145 , Total execute: 1456.3926808834076\n","<Main/line:128> /* Train EPOCH: 278 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5394], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.462968 (0.462968)\tFDE 0.987969 (0.987969)\n","Test: [ 5/15]\tADE 0.338040 (0.395823)\tFDE 0.684345 (0.848667)\n","Test: [10/15]\tADE 0.378133 (0.339117)\tFDE 0.773572 (0.720123)\n"," * ADE  0.338 FDE  0.718\n","<Main/line:158> Validate(), ADE: tensor(0.3376, device='cuda:0')\n","ade: tensor(0.3376, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.146021604537964 , Total execute: 1467.5387012958527\n","<Main/line:128> /* Train EPOCH: 279 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.4926], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.457690 (0.457690)\tFDE 0.975253 (0.975253)\n","Test: [ 5/15]\tADE 0.332606 (0.391575)\tFDE 0.671536 (0.839325)\n","Test: [10/15]\tADE 0.359003 (0.332110)\tFDE 0.739774 (0.705701)\n"," * ADE  0.331 FDE  0.705\n","<Main/line:158> Validate(), ADE: tensor(0.3310, device='cuda:0')\n","ade: tensor(0.3310, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.285181283950806 , Total execute: 1478.8238804340363\n","<Main/line:128> /* Train EPOCH: 280 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.4069], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.457399 (0.457399)\tFDE 0.975197 (0.975197)\n","Test: [ 5/15]\tADE 0.339746 (0.395906)\tFDE 0.684404 (0.846405)\n","Test: [10/15]\tADE 0.367102 (0.339796)\tFDE 0.752662 (0.718838)\n"," * ADE  0.339 FDE  0.719\n","<Main/line:158> Validate(), ADE: tensor(0.3392, device='cuda:0')\n","ade: tensor(0.3392, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.282907485961914 , Total execute: 1490.1067872047424\n","<Main/line:128> /* Train EPOCH: 281 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.4126], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.465215 (0.465215)\tFDE 0.991641 (0.991641)\n","Test: [ 5/15]\tADE 0.342881 (0.399123)\tFDE 0.690259 (0.850744)\n","Test: [10/15]\tADE 0.370649 (0.339953)\tFDE 0.759895 (0.718679)\n"," * ADE  0.339 FDE  0.718\n","<Main/line:158> Validate(), ADE: tensor(0.3391, device='cuda:0')\n","ade: tensor(0.3391, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.226154565811157 , Total execute: 1501.3329405784607\n","<Main/line:128> /* Train EPOCH: 282 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3934], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.465276 (0.465276)\tFDE 0.994202 (0.994202)\n","Test: [ 5/15]\tADE 0.323539 (0.388333)\tFDE 0.660281 (0.834611)\n","Test: [10/15]\tADE 0.354518 (0.328657)\tFDE 0.734101 (0.701100)\n"," * ADE  0.327 FDE  0.700\n","<Main/line:158> Validate(), ADE: tensor(0.3275, device='cuda:0')\n","ade: tensor(0.3275, device='cuda:0')\n","-------------- lower ade ----------------\n","<Main/line:167> */ EPOCH execute: 11.453390836715698 , Total execute: 1512.786329984665\n","<Main/line:128> /* Train EPOCH: 283 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.4066], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.461096 (0.461096)\tFDE 0.982211 (0.982211)\n","Test: [ 5/15]\tADE 0.330695 (0.391925)\tFDE 0.675221 (0.841348)\n","Test: [10/15]\tADE 0.360544 (0.332807)\tFDE 0.748678 (0.710446)\n"," * ADE  0.331 FDE  0.710\n","<Main/line:158> Validate(), ADE: tensor(0.3313, device='cuda:0')\n","ade: tensor(0.3313, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.186082363128662 , Total execute: 1523.9724111557007\n","<Main/line:128> /* Train EPOCH: 284 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.4159], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.465883 (0.465883)\tFDE 0.992170 (0.992170)\n","Test: [ 5/15]\tADE 0.338684 (0.393431)\tFDE 0.687894 (0.842195)\n","Test: [10/15]\tADE 0.365198 (0.334554)\tFDE 0.752112 (0.710557)\n"," * ADE  0.334 FDE  0.710\n","<Main/line:158> Validate(), ADE: tensor(0.3338, device='cuda:0')\n","ade: tensor(0.3338, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.208660364151001 , Total execute: 1535.1810705661774\n","<Main/line:128> /* Train EPOCH: 285 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3826], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.466869 (0.466869)\tFDE 0.995095 (0.995095)\n","Test: [ 5/15]\tADE 0.339979 (0.398209)\tFDE 0.691788 (0.851816)\n","Test: [10/15]\tADE 0.370724 (0.339588)\tFDE 0.764058 (0.721100)\n"," * ADE  0.339 FDE  0.722\n","<Main/line:158> Validate(), ADE: tensor(0.3395, device='cuda:0')\n","ade: tensor(0.3395, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.189355850219727 , Total execute: 1546.3704252243042\n","<Main/line:128> /* Train EPOCH: 286 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3664], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.462895 (0.462895)\tFDE 0.998643 (0.998643)\n","Test: [ 5/15]\tADE 0.330547 (0.392678)\tFDE 0.675391 (0.844908)\n","Test: [10/15]\tADE 0.362175 (0.333949)\tFDE 0.752104 (0.714066)\n"," * ADE  0.333 FDE  0.714\n","<Main/line:158> Validate(), ADE: tensor(0.3332, device='cuda:0')\n","ade: tensor(0.3332, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.152812242507935 , Total execute: 1557.5232367515564\n","<Main/line:128> /* Train EPOCH: 287 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3689], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.467575 (0.467575)\tFDE 0.994169 (0.994169)\n","Test: [ 5/15]\tADE 0.341801 (0.400484)\tFDE 0.695758 (0.853679)\n","Test: [10/15]\tADE 0.365307 (0.338094)\tFDE 0.745455 (0.714697)\n"," * ADE  0.338 FDE  0.716\n","<Main/line:158> Validate(), ADE: tensor(0.3380, device='cuda:0')\n","ade: tensor(0.3380, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.13674259185791 , Total execute: 1568.6599786281586\n","<Main/line:128> /* Train EPOCH: 288 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3489], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.467649 (0.467649)\tFDE 1.004375 (1.004375)\n","Test: [ 5/15]\tADE 0.335036 (0.394919)\tFDE 0.685177 (0.849120)\n","Test: [10/15]\tADE 0.368138 (0.337144)\tFDE 0.764162 (0.719692)\n"," * ADE  0.336 FDE  0.718\n","<Main/line:158> Validate(), ADE: tensor(0.3356, device='cuda:0')\n","ade: tensor(0.3356, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.132175922393799 , Total execute: 1579.7921538352966\n","<Main/line:128> /* Train EPOCH: 289 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3505], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.462599 (0.462599)\tFDE 0.987886 (0.987886)\n","Test: [ 5/15]\tADE 0.328777 (0.390178)\tFDE 0.670175 (0.836497)\n","Test: [10/15]\tADE 0.358041 (0.329586)\tFDE 0.739726 (0.703013)\n"," * ADE  0.328 FDE  0.702\n","<Main/line:158> Validate(), ADE: tensor(0.3281, device='cuda:0')\n","ade: tensor(0.3281, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.27050232887268 , Total execute: 1591.062655210495\n","<Main/line:128> /* Train EPOCH: 290 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2621], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.464735 (0.464735)\tFDE 1.002331 (1.002331)\n","Test: [ 5/15]\tADE 0.333683 (0.392333)\tFDE 0.681723 (0.844502)\n","Test: [10/15]\tADE 0.373086 (0.336601)\tFDE 0.772421 (0.719799)\n"," * ADE  0.336 FDE  0.718\n","<Main/line:158> Validate(), ADE: tensor(0.3357, device='cuda:0')\n","ade: tensor(0.3357, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.23591160774231 , Total execute: 1602.2985661029816\n","<Main/line:128> /* Train EPOCH: 291 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3821], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.469132 (0.469132)\tFDE 1.009885 (1.009885)\n","Test: [ 5/15]\tADE 0.340127 (0.398517)\tFDE 0.683645 (0.850380)\n","Test: [10/15]\tADE 0.359965 (0.335852)\tFDE 0.736095 (0.709913)\n"," * ADE  0.335 FDE  0.711\n","<Main/line:158> Validate(), ADE: tensor(0.3354, device='cuda:0')\n","ade: tensor(0.3354, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.188524961471558 , Total execute: 1613.4870901107788\n","<Main/line:128> /* Train EPOCH: 292 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2617], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.471354 (0.471354)\tFDE 1.012736 (1.012736)\n","Test: [ 5/15]\tADE 0.340135 (0.396334)\tFDE 0.692733 (0.851075)\n","Test: [10/15]\tADE 0.372282 (0.339556)\tFDE 0.770488 (0.723020)\n"," * ADE  0.339 FDE  0.722\n","<Main/line:158> Validate(), ADE: tensor(0.3389, device='cuda:0')\n","ade: tensor(0.3389, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.142292976379395 , Total execute: 1624.6293823719025\n","<Main/line:128> /* Train EPOCH: 293 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3320], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.467182 (0.467182)\tFDE 1.002802 (1.002802)\n","Test: [ 5/15]\tADE 0.332515 (0.396514)\tFDE 0.680677 (0.849016)\n","Test: [10/15]\tADE 0.367299 (0.338095)\tFDE 0.756902 (0.718650)\n"," * ADE  0.337 FDE  0.720\n","<Main/line:158> Validate(), ADE: tensor(0.3374, device='cuda:0')\n","ade: tensor(0.3374, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.254010677337646 , Total execute: 1635.8833920955658\n","<Main/line:128> /* Train EPOCH: 294 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3128], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.471251 (0.471251)\tFDE 1.019502 (1.019502)\n","Test: [ 5/15]\tADE 0.340055 (0.401304)\tFDE 0.697539 (0.865197)\n","Test: [10/15]\tADE 0.374254 (0.344121)\tFDE 0.774818 (0.734208)\n"," * ADE  0.343 FDE  0.732\n","<Main/line:158> Validate(), ADE: tensor(0.3433, device='cuda:0')\n","ade: tensor(0.3433, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.204267501831055 , Total execute: 1647.087658882141\n","<Main/line:128> /* Train EPOCH: 295 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3500], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.467824 (0.467824)\tFDE 0.991365 (0.991365)\n","Test: [ 5/15]\tADE 0.343915 (0.402228)\tFDE 0.703901 (0.857592)\n","Test: [10/15]\tADE 0.371057 (0.341001)\tFDE 0.764958 (0.721795)\n"," * ADE  0.340 FDE  0.722\n","<Main/line:158> Validate(), ADE: tensor(0.3395, device='cuda:0')\n","ade: tensor(0.3395, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.347129583358765 , Total execute: 1658.4347877502441\n","<Main/line:128> /* Train EPOCH: 296 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2302], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.472165 (0.472165)\tFDE 1.015767 (1.015767)\n","Test: [ 5/15]\tADE 0.346112 (0.400901)\tFDE 0.709571 (0.862232)\n","Test: [10/15]\tADE 0.375523 (0.344047)\tFDE 0.779479 (0.734112)\n"," * ADE  0.343 FDE  0.732\n","<Main/line:158> Validate(), ADE: tensor(0.3429, device='cuda:0')\n","ade: tensor(0.3429, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.353203058242798 , Total execute: 1669.787989616394\n","<Main/line:128> /* Train EPOCH: 297 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3210], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.470590 (0.470590)\tFDE 1.008021 (1.008021)\n","Test: [ 5/15]\tADE 0.340642 (0.403939)\tFDE 0.695745 (0.861947)\n","Test: [10/15]\tADE 0.368577 (0.342121)\tFDE 0.758281 (0.725476)\n"," * ADE  0.340 FDE  0.724\n","<Main/line:158> Validate(), ADE: tensor(0.3404, device='cuda:0')\n","ade: tensor(0.3404, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.327841758728027 , Total execute: 1681.1158301830292\n","<Main/line:128> /* Train EPOCH: 298 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2711], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.475025 (0.475025)\tFDE 1.026793 (1.026793)\n","Test: [ 5/15]\tADE 0.340505 (0.400395)\tFDE 0.695292 (0.859199)\n","Test: [10/15]\tADE 0.379979 (0.343917)\tFDE 0.786221 (0.731781)\n"," * ADE  0.342 FDE  0.729\n","<Main/line:158> Validate(), ADE: tensor(0.3424, device='cuda:0')\n","ade: tensor(0.3424, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.348044395446777 , Total execute: 1692.4638736248016\n","<Main/line:128> /* Train EPOCH: 299 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2875], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.470179 (0.470179)\tFDE 0.998785 (0.998785)\n","Test: [ 5/15]\tADE 0.345224 (0.403738)\tFDE 0.704117 (0.861550)\n","Test: [10/15]\tADE 0.368835 (0.342809)\tFDE 0.764438 (0.728972)\n"," * ADE  0.342 FDE  0.729\n","<Main/line:158> Validate(), ADE: tensor(0.3417, device='cuda:0')\n","ade: tensor(0.3417, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.12607192993164 , Total execute: 1703.5899443626404\n","<Main/line:128> /* Train EPOCH: 300 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2329], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.465399 (0.465399)\tFDE 1.006087 (1.006087)\n","Test: [ 5/15]\tADE 0.344425 (0.400659)\tFDE 0.706408 (0.862572)\n","Test: [10/15]\tADE 0.374395 (0.342443)\tFDE 0.776899 (0.730963)\n"," * ADE  0.341 FDE  0.729\n","<Main/line:158> Validate(), ADE: tensor(0.3413, device='cuda:0')\n","ade: tensor(0.3413, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.132485151290894 , Total execute: 1714.7224287986755\n","<Main/line:128> /* Train EPOCH: 301 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2737], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.471087 (0.471087)\tFDE 1.008602 (1.008602)\n","Test: [ 5/15]\tADE 0.352964 (0.406148)\tFDE 0.721179 (0.866442)\n","Test: [10/15]\tADE 0.372930 (0.344059)\tFDE 0.772725 (0.731056)\n"," * ADE  0.344 FDE  0.732\n","<Main/line:158> Validate(), ADE: tensor(0.3435, device='cuda:0')\n","ade: tensor(0.3435, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.252584218978882 , Total execute: 1725.9750123023987\n","<Main/line:128> /* Train EPOCH: 302 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2471], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.480793 (0.480793)\tFDE 1.034565 (1.034565)\n","Test: [ 5/15]\tADE 0.350457 (0.408178)\tFDE 0.714450 (0.872212)\n","Test: [10/15]\tADE 0.378461 (0.348274)\tFDE 0.781913 (0.738277)\n"," * ADE  0.347 FDE  0.736\n","<Main/line:158> Validate(), ADE: tensor(0.3470, device='cuda:0')\n","ade: tensor(0.3470, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.165610551834106 , Total execute: 1737.140622138977\n","<Main/line:128> /* Train EPOCH: 303 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2980], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.479649 (0.479649)\tFDE 1.021454 (1.021454)\n","Test: [ 5/15]\tADE 0.336034 (0.402095)\tFDE 0.687092 (0.855804)\n","Test: [10/15]\tADE 0.370777 (0.339620)\tFDE 0.764029 (0.718504)\n"," * ADE  0.339 FDE  0.719\n","<Main/line:158> Validate(), ADE: tensor(0.3385, device='cuda:0')\n","ade: tensor(0.3385, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.264001369476318 , Total execute: 1748.404622554779\n","<Main/line:128> /* Train EPOCH: 304 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2601], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.477454 (0.477454)\tFDE 1.025778 (1.025778)\n","Test: [ 5/15]\tADE 0.341881 (0.405909)\tFDE 0.703212 (0.870834)\n","Test: [10/15]\tADE 0.380446 (0.348865)\tFDE 0.791661 (0.743176)\n"," * ADE  0.347 FDE  0.740\n","<Main/line:158> Validate(), ADE: tensor(0.3469, device='cuda:0')\n","ade: tensor(0.3469, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.20729374885559 , Total execute: 1759.611915588379\n","<Main/line:128> /* Train EPOCH: 305 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2215], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.466748 (0.466748)\tFDE 1.000039 (1.000039)\n","Test: [ 5/15]\tADE 0.338495 (0.399965)\tFDE 0.694020 (0.854560)\n","Test: [10/15]\tADE 0.377031 (0.342704)\tFDE 0.779673 (0.727914)\n"," * ADE  0.343 FDE  0.729\n","<Main/line:158> Validate(), ADE: tensor(0.3426, device='cuda:0')\n","ade: tensor(0.3426, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.2296781539917 , Total execute: 1770.8415925502777\n","<Main/line:128> /* Train EPOCH: 306 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2355], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.491219 (0.491219)\tFDE 1.058925 (1.058925)\n","Test: [ 5/15]\tADE 0.340266 (0.407971)\tFDE 0.693969 (0.872254)\n","Test: [10/15]\tADE 0.371548 (0.342353)\tFDE 0.768401 (0.726736)\n"," * ADE  0.340 FDE  0.722\n","<Main/line:158> Validate(), ADE: tensor(0.3397, device='cuda:0')\n","ade: tensor(0.3397, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.235989093780518 , Total execute: 1782.0775809288025\n","<Main/line:128> /* Train EPOCH: 307 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1680], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.473648 (0.473648)\tFDE 1.021109 (1.021109)\n","Test: [ 5/15]\tADE 0.339158 (0.401394)\tFDE 0.692495 (0.860636)\n","Test: [10/15]\tADE 0.371179 (0.342285)\tFDE 0.769608 (0.729470)\n"," * ADE  0.341 FDE  0.728\n","<Main/line:158> Validate(), ADE: tensor(0.3411, device='cuda:0')\n","ade: tensor(0.3411, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.287007331848145 , Total execute: 1793.3645870685577\n","<Main/line:128> /* Train EPOCH: 308 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1828], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.493143 (0.493143)\tFDE 1.070983 (1.070983)\n","Test: [ 5/15]\tADE 0.337712 (0.404150)\tFDE 0.698626 (0.871267)\n","Test: [10/15]\tADE 0.375709 (0.345628)\tFDE 0.781880 (0.738660)\n"," * ADE  0.343 FDE  0.734\n","<Main/line:158> Validate(), ADE: tensor(0.3429, device='cuda:0')\n","ade: tensor(0.3429, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.147460222244263 , Total execute: 1804.5120463371277\n","<Main/line:128> /* Train EPOCH: 309 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1767], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.473703 (0.473703)\tFDE 1.028136 (1.028136)\n","Test: [ 5/15]\tADE 0.340316 (0.400473)\tFDE 0.697579 (0.859897)\n","Test: [10/15]\tADE 0.374817 (0.340343)\tFDE 0.777890 (0.725625)\n"," * ADE  0.339 FDE  0.724\n","<Main/line:158> Validate(), ADE: tensor(0.3387, device='cuda:0')\n","ade: tensor(0.3387, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.350477695465088 , Total execute: 1815.8625228404999\n","<Main/line:128> /* Train EPOCH: 310 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2108], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.485391 (0.485391)\tFDE 1.039452 (1.039452)\n","Test: [ 5/15]\tADE 0.345607 (0.406535)\tFDE 0.705725 (0.870978)\n","Test: [10/15]\tADE 0.376080 (0.348203)\tFDE 0.780165 (0.739087)\n"," * ADE  0.346 FDE  0.735\n","<Main/line:158> Validate(), ADE: tensor(0.3459, device='cuda:0')\n","ade: tensor(0.3459, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.326819658279419 , Total execute: 1827.1893417835236\n","<Main/line:128> /* Train EPOCH: 311 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1625], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.472436 (0.472436)\tFDE 1.032289 (1.032289)\n","Test: [ 5/15]\tADE 0.337305 (0.400808)\tFDE 0.692364 (0.863289)\n","Test: [10/15]\tADE 0.375071 (0.340431)\tFDE 0.781608 (0.728794)\n"," * ADE  0.338 FDE  0.725\n","<Main/line:158> Validate(), ADE: tensor(0.3383, device='cuda:0')\n","ade: tensor(0.3383, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.227839231491089 , Total execute: 1838.417180299759\n","<Main/line:128> /* Train EPOCH: 312 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2575], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.488984 (0.488984)\tFDE 1.051333 (1.051333)\n","Test: [ 5/15]\tADE 0.329835 (0.400067)\tFDE 0.671579 (0.859473)\n","Test: [10/15]\tADE 0.364572 (0.334328)\tFDE 0.754626 (0.712021)\n"," * ADE  0.332 FDE  0.708\n","<Main/line:158> Validate(), ADE: tensor(0.3317, device='cuda:0')\n","ade: tensor(0.3317, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.23087739944458 , Total execute: 1849.6480569839478\n","<Main/line:128> /* Train EPOCH: 313 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1274], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.469510 (0.469510)\tFDE 1.014717 (1.014717)\n","Test: [ 5/15]\tADE 0.351061 (0.405684)\tFDE 0.717645 (0.868240)\n","Test: [10/15]\tADE 0.371940 (0.346255)\tFDE 0.774687 (0.737402)\n"," * ADE  0.345 FDE  0.735\n","<Main/line:158> Validate(), ADE: tensor(0.3447, device='cuda:0')\n","ade: tensor(0.3447, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.211260795593262 , Total execute: 1860.8593168258667\n","<Main/line:128> /* Train EPOCH: 314 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1590], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.484340 (0.484340)\tFDE 1.043331 (1.043331)\n","Test: [ 5/15]\tADE 0.350961 (0.412072)\tFDE 0.709051 (0.878231)\n","Test: [10/15]\tADE 0.375290 (0.349522)\tFDE 0.774524 (0.736902)\n"," * ADE  0.348 FDE  0.734\n","<Main/line:158> Validate(), ADE: tensor(0.3479, device='cuda:0')\n","ade: tensor(0.3479, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.259122371673584 , Total execute: 1872.1184384822845\n","<Main/line:128> /* Train EPOCH: 315 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1581], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.467391 (0.467391)\tFDE 1.020098 (1.020098)\n","Test: [ 5/15]\tADE 0.340677 (0.403239)\tFDE 0.702188 (0.868083)\n","Test: [10/15]\tADE 0.373827 (0.346647)\tFDE 0.778964 (0.739665)\n"," * ADE  0.346 FDE  0.738\n","<Main/line:158> Validate(), ADE: tensor(0.3459, device='cuda:0')\n","ade: tensor(0.3459, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.18100380897522 , Total execute: 1883.299441576004\n","<Main/line:128> /* Train EPOCH: 316 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1409], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.479895 (0.479895)\tFDE 1.037065 (1.037065)\n","Test: [ 5/15]\tADE 0.347635 (0.409921)\tFDE 0.715272 (0.882835)\n","Test: [10/15]\tADE 0.381792 (0.350599)\tFDE 0.793047 (0.748484)\n"," * ADE  0.350 FDE  0.746\n","<Main/line:158> Validate(), ADE: tensor(0.3495, device='cuda:0')\n","ade: tensor(0.3495, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.068050861358643 , Total execute: 1894.367491722107\n","<Main/line:128> /* Train EPOCH: 317 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1138], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.474807 (0.474807)\tFDE 1.034237 (1.034237)\n","Test: [ 5/15]\tADE 0.342378 (0.400983)\tFDE 0.699189 (0.863437)\n","Test: [10/15]\tADE 0.375907 (0.342206)\tFDE 0.780433 (0.730461)\n"," * ADE  0.341 FDE  0.729\n","<Main/line:158> Validate(), ADE: tensor(0.3410, device='cuda:0')\n","ade: tensor(0.3410, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.269880533218384 , Total execute: 1905.6373715400696\n","<Main/line:128> /* Train EPOCH: 318 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0920], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.488881 (0.488881)\tFDE 1.048398 (1.048398)\n","Test: [ 5/15]\tADE 0.356345 (0.416911)\tFDE 0.730483 (0.893063)\n","Test: [10/15]\tADE 0.382722 (0.359000)\tFDE 0.794394 (0.762198)\n"," * ADE  0.357 FDE  0.758\n","<Main/line:158> Validate(), ADE: tensor(0.3568, device='cuda:0')\n","ade: tensor(0.3568, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.20912504196167 , Total execute: 1916.846495628357\n","<Main/line:128> /* Train EPOCH: 319 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0884], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.473920 (0.473920)\tFDE 1.025467 (1.025467)\n","Test: [ 5/15]\tADE 0.343157 (0.400753)\tFDE 0.701141 (0.862248)\n","Test: [10/15]\tADE 0.365727 (0.339939)\tFDE 0.758628 (0.725108)\n"," * ADE  0.338 FDE  0.723\n","<Main/line:158> Validate(), ADE: tensor(0.3382, device='cuda:0')\n","ade: tensor(0.3382, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.319363832473755 , Total execute: 1928.1658585071564\n","<Main/line:128> /* Train EPOCH: 320 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0714], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.486629 (0.486629)\tFDE 1.050261 (1.050261)\n","Test: [ 5/15]\tADE 0.350836 (0.414292)\tFDE 0.725612 (0.891628)\n","Test: [10/15]\tADE 0.387128 (0.359794)\tFDE 0.805993 (0.766526)\n"," * ADE  0.356 FDE  0.759\n","<Main/line:158> Validate(), ADE: tensor(0.3562, device='cuda:0')\n","ade: tensor(0.3562, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.232352018356323 , Total execute: 1939.3982095718384\n","<Main/line:128> /* Train EPOCH: 321 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1197], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.487210 (0.487210)\tFDE 1.053281 (1.053281)\n","Test: [ 5/15]\tADE 0.344483 (0.404938)\tFDE 0.701088 (0.869147)\n","Test: [10/15]\tADE 0.361450 (0.338621)\tFDE 0.746257 (0.720022)\n"," * ADE  0.336 FDE  0.717\n","<Main/line:158> Validate(), ADE: tensor(0.3362, device='cuda:0')\n","ade: tensor(0.3362, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.140140771865845 , Total execute: 1950.5383496284485\n","<Main/line:128> /* Train EPOCH: 322 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1021], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.491859 (0.491859)\tFDE 1.056115 (1.056115)\n","Test: [ 5/15]\tADE 0.349988 (0.412937)\tFDE 0.714899 (0.884773)\n","Test: [10/15]\tADE 0.377855 (0.353561)\tFDE 0.783385 (0.749830)\n"," * ADE  0.351 FDE  0.744\n","<Main/line:158> Validate(), ADE: tensor(0.3508, device='cuda:0')\n","ade: tensor(0.3508, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.267216682434082 , Total execute: 1961.8055653572083\n","<Main/line:128> /* Train EPOCH: 323 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0866], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.473881 (0.473881)\tFDE 1.028968 (1.028968)\n","Test: [ 5/15]\tADE 0.346175 (0.405027)\tFDE 0.710158 (0.871182)\n","Test: [10/15]\tADE 0.362857 (0.344086)\tFDE 0.759613 (0.735501)\n"," * ADE  0.341 FDE  0.731\n","<Main/line:158> Validate(), ADE: tensor(0.3414, device='cuda:0')\n","ade: tensor(0.3414, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.190830945968628 , Total execute: 1972.9963953495026\n","<Main/line:128> /* Train EPOCH: 324 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1211], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.489677 (0.489677)\tFDE 1.052135 (1.052135)\n","Test: [ 5/15]\tADE 0.342998 (0.410832)\tFDE 0.700226 (0.878673)\n","Test: [10/15]\tADE 0.369412 (0.346953)\tFDE 0.763819 (0.735693)\n"," * ADE  0.344 FDE  0.729\n","<Main/line:158> Validate(), ADE: tensor(0.3438, device='cuda:0')\n","ade: tensor(0.3438, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.187252759933472 , Total execute: 1984.1836473941803\n","<Main/line:128> /* Train EPOCH: 325 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0742], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.484212 (0.484212)\tFDE 1.056851 (1.056851)\n","Test: [ 5/15]\tADE 0.344203 (0.406522)\tFDE 0.710290 (0.881813)\n","Test: [10/15]\tADE 0.371124 (0.348313)\tFDE 0.776307 (0.747238)\n"," * ADE  0.344 FDE  0.739\n","<Main/line:158> Validate(), ADE: tensor(0.3437, device='cuda:0')\n","ade: tensor(0.3437, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.317050695419312 , Total execute: 1995.5006971359253\n","<Main/line:128> /* Train EPOCH: 326 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1293], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.482222 (0.482222)\tFDE 1.042185 (1.042185)\n","Test: [ 5/15]\tADE 0.338433 (0.407810)\tFDE 0.690895 (0.876551)\n","Test: [10/15]\tADE 0.376387 (0.348164)\tFDE 0.776555 (0.738589)\n"," * ADE  0.346 FDE  0.734\n","<Main/line:158> Validate(), ADE: tensor(0.3462, device='cuda:0')\n","ade: tensor(0.3462, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.185420751571655 , Total execute: 2006.6861171722412\n","<Main/line:128> /* Train EPOCH: 327 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1196], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.493303 (0.493303)\tFDE 1.077570 (1.077570)\n","Test: [ 5/15]\tADE 0.367329 (0.428380)\tFDE 0.746883 (0.916628)\n","Test: [10/15]\tADE 0.397824 (0.374323)\tFDE 0.820403 (0.790503)\n"," * ADE  0.370 FDE  0.782\n","<Main/line:158> Validate(), ADE: tensor(0.3701, device='cuda:0')\n","ade: tensor(0.3701, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.232316732406616 , Total execute: 2017.918433189392\n","<Main/line:128> /* Train EPOCH: 328 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.5433], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.493059 (0.493059)\tFDE 1.060433 (1.060433)\n","Test: [ 5/15]\tADE 0.360005 (0.418222)\tFDE 0.720878 (0.890850)\n","Test: [10/15]\tADE 0.368069 (0.351799)\tFDE 0.751443 (0.739556)\n"," * ADE  0.351 FDE  0.739\n","<Main/line:158> Validate(), ADE: tensor(0.3509, device='cuda:0')\n","ade: tensor(0.3509, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.212807416915894 , Total execute: 2029.1312398910522\n","<Main/line:128> /* Train EPOCH: 329 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2996], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.493696 (0.493696)\tFDE 1.075271 (1.075271)\n","Test: [ 5/15]\tADE 0.369483 (0.428050)\tFDE 0.749494 (0.916421)\n","Test: [10/15]\tADE 0.394238 (0.369540)\tFDE 0.810155 (0.780464)\n"," * ADE  0.370 FDE  0.782\n","<Main/line:158> Validate(), ADE: tensor(0.3698, device='cuda:0')\n","ade: tensor(0.3698, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.168226480484009 , Total execute: 2040.2994656562805\n","<Main/line:128> /* Train EPOCH: 330 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2985], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.498334 (0.498334)\tFDE 1.064544 (1.064544)\n","Test: [ 5/15]\tADE 0.374445 (0.432721)\tFDE 0.758074 (0.917351)\n","Test: [10/15]\tADE 0.402242 (0.378512)\tFDE 0.825969 (0.794022)\n"," * ADE  0.377 FDE  0.791\n","<Main/line:158> Validate(), ADE: tensor(0.3773, device='cuda:0')\n","ade: tensor(0.3773, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.202048540115356 , Total execute: 2051.5015132427216\n","<Main/line:128> /* Train EPOCH: 331 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1927], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.475817 (0.475817)\tFDE 1.031870 (1.031870)\n","Test: [ 5/15]\tADE 0.368841 (0.420011)\tFDE 0.756120 (0.900354)\n","Test: [10/15]\tADE 0.396094 (0.364753)\tFDE 0.823104 (0.776282)\n"," * ADE  0.363 FDE  0.773\n","<Main/line:158> Validate(), ADE: tensor(0.3628, device='cuda:0')\n","ade: tensor(0.3628, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.197526693344116 , Total execute: 2062.6990389823914\n","<Main/line:128> /* Train EPOCH: 332 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1475], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.485099 (0.485099)\tFDE 1.055311 (1.055311)\n","Test: [ 5/15]\tADE 0.350259 (0.414427)\tFDE 0.708632 (0.886730)\n","Test: [10/15]\tADE 0.395712 (0.357356)\tFDE 0.810493 (0.756521)\n"," * ADE  0.353 FDE  0.748\n","<Main/line:158> Validate(), ADE: tensor(0.3529, device='cuda:0')\n","ade: tensor(0.3529, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.231017351150513 , Total execute: 2073.9300553798676\n","<Main/line:128> /* Train EPOCH: 333 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1614], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.486235 (0.486235)\tFDE 1.065016 (1.065016)\n","Test: [ 5/15]\tADE 0.340542 (0.406723)\tFDE 0.695919 (0.875996)\n","Test: [10/15]\tADE 0.383964 (0.350586)\tFDE 0.797754 (0.747563)\n"," * ADE  0.347 FDE  0.741\n","<Main/line:158> Validate(), ADE: tensor(0.3470, device='cuda:0')\n","ade: tensor(0.3470, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.248249530792236 , Total execute: 2085.178304195404\n","<Main/line:128> /* Train EPOCH: 334 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0837], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.483750 (0.483750)\tFDE 1.051786 (1.051786)\n","Test: [ 5/15]\tADE 0.345274 (0.409803)\tFDE 0.706687 (0.882906)\n","Test: [10/15]\tADE 0.386977 (0.356407)\tFDE 0.804558 (0.759470)\n"," * ADE  0.354 FDE  0.754\n","<Main/line:158> Validate(), ADE: tensor(0.3537, device='cuda:0')\n","ade: tensor(0.3537, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.163965702056885 , Total execute: 2096.3422689437866\n","<Main/line:128> /* Train EPOCH: 335 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0260], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.475522 (0.475522)\tFDE 1.041860 (1.041860)\n","Test: [ 5/15]\tADE 0.339867 (0.401252)\tFDE 0.697339 (0.868652)\n","Test: [10/15]\tADE 0.374127 (0.344499)\tFDE 0.781115 (0.738786)\n"," * ADE  0.341 FDE  0.733\n","<Main/line:158> Validate(), ADE: tensor(0.3412, device='cuda:0')\n","ade: tensor(0.3412, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.152199745178223 , Total execute: 2107.4944677352905\n","<Main/line:128> /* Train EPOCH: 336 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0455], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.491625 (0.491625)\tFDE 1.070436 (1.070436)\n","Test: [ 5/15]\tADE 0.346084 (0.410709)\tFDE 0.705987 (0.885837)\n","Test: [10/15]\tADE 0.384760 (0.354675)\tFDE 0.794327 (0.754993)\n"," * ADE  0.352 FDE  0.749\n","<Main/line:158> Validate(), ADE: tensor(0.3518, device='cuda:0')\n","ade: tensor(0.3518, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.18887996673584 , Total execute: 2118.683346748352\n","<Main/line:128> /* Train EPOCH: 337 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1575], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.480410 (0.480410)\tFDE 1.060737 (1.060737)\n","Test: [ 5/15]\tADE 0.330180 (0.403307)\tFDE 0.679618 (0.874801)\n","Test: [10/15]\tADE 0.369126 (0.344111)\tFDE 0.770936 (0.737419)\n"," * ADE  0.341 FDE  0.731\n","<Main/line:158> Validate(), ADE: tensor(0.3406, device='cuda:0')\n","ade: tensor(0.3406, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.340966701507568 , Total execute: 2130.0243124961853\n","<Main/line:128> /* Train EPOCH: 338 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0655], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.494670 (0.494670)\tFDE 1.068474 (1.068474)\n","Test: [ 5/15]\tADE 0.332808 (0.406991)\tFDE 0.675722 (0.874864)\n","Test: [10/15]\tADE 0.377806 (0.352072)\tFDE 0.783182 (0.747392)\n"," * ADE  0.348 FDE  0.740\n","<Main/line:158> Validate(), ADE: tensor(0.3480, device='cuda:0')\n","ade: tensor(0.3480, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.325006008148193 , Total execute: 2141.3493177890778\n","<Main/line:128> /* Train EPOCH: 339 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0980], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.491880 (0.491880)\tFDE 1.079596 (1.079596)\n","Test: [ 5/15]\tADE 0.338286 (0.406855)\tFDE 0.693659 (0.881701)\n","Test: [10/15]\tADE 0.367676 (0.346031)\tFDE 0.766786 (0.742464)\n"," * ADE  0.342 FDE  0.735\n","<Main/line:158> Validate(), ADE: tensor(0.3422, device='cuda:0')\n","ade: tensor(0.3422, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.193430185317993 , Total execute: 2152.54274725914\n","<Main/line:128> /* Train EPOCH: 340 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0747], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.499002 (0.499002)\tFDE 1.079054 (1.079054)\n","Test: [ 5/15]\tADE 0.346725 (0.416749)\tFDE 0.708804 (0.897625)\n","Test: [10/15]\tADE 0.380138 (0.361629)\tFDE 0.793448 (0.772033)\n"," * ADE  0.359 FDE  0.766\n","<Main/line:158> Validate(), ADE: tensor(0.3587, device='cuda:0')\n","ade: tensor(0.3587, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.135349988937378 , Total execute: 2163.6780965328217\n","<Main/line:128> /* Train EPOCH: 341 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0352], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.496559 (0.496559)\tFDE 1.082733 (1.082733)\n","Test: [ 5/15]\tADE 0.348624 (0.412915)\tFDE 0.713310 (0.894334)\n","Test: [10/15]\tADE 0.370395 (0.351703)\tFDE 0.770397 (0.752723)\n"," * ADE  0.349 FDE  0.747\n","<Main/line:158> Validate(), ADE: tensor(0.3487, device='cuda:0')\n","ade: tensor(0.3487, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.239580631256104 , Total execute: 2174.9176762104034\n","<Main/line:128> /* Train EPOCH: 342 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1076], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.503234 (0.503234)\tFDE 1.093080 (1.093080)\n","Test: [ 5/15]\tADE 0.338881 (0.411213)\tFDE 0.690941 (0.886763)\n","Test: [10/15]\tADE 0.369476 (0.350851)\tFDE 0.771329 (0.747310)\n"," * ADE  0.346 FDE  0.738\n","<Main/line:158> Validate(), ADE: tensor(0.3463, device='cuda:0')\n","ade: tensor(0.3463, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.202140808105469 , Total execute: 2186.119816303253\n","<Main/line:128> /* Train EPOCH: 343 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0347], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.496183 (0.496183)\tFDE 1.092138 (1.092138)\n","Test: [ 5/15]\tADE 0.342301 (0.414515)\tFDE 0.697985 (0.895786)\n","Test: [10/15]\tADE 0.372128 (0.351914)\tFDE 0.777094 (0.751419)\n"," * ADE  0.347 FDE  0.742\n","<Main/line:158> Validate(), ADE: tensor(0.3468, device='cuda:0')\n","ade: tensor(0.3468, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.086231708526611 , Total execute: 2197.2060470581055\n","<Main/line:128> /* Train EPOCH: 344 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0139], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.516346 (0.516346)\tFDE 1.119450 (1.119450)\n","Test: [ 5/15]\tADE 0.339052 (0.421129)\tFDE 0.691860 (0.906170)\n","Test: [10/15]\tADE 0.369923 (0.353548)\tFDE 0.769555 (0.752650)\n"," * ADE  0.349 FDE  0.743\n","<Main/line:158> Validate(), ADE: tensor(0.3486, device='cuda:0')\n","ade: tensor(0.3486, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.245970010757446 , Total execute: 2208.4520161151886\n","<Main/line:128> /* Train EPOCH: 345 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9483], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.514293 (0.514293)\tFDE 1.116420 (1.116420)\n","Test: [ 5/15]\tADE 0.343298 (0.417652)\tFDE 0.707715 (0.904880)\n","Test: [10/15]\tADE 0.381090 (0.357851)\tFDE 0.799986 (0.766516)\n"," * ADE  0.353 FDE  0.757\n","<Main/line:158> Validate(), ADE: tensor(0.3527, device='cuda:0')\n","ade: tensor(0.3527, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.18180227279663 , Total execute: 2219.6338176727295\n","<Main/line:128> /* Train EPOCH: 346 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3476], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.529284 (0.529284)\tFDE 1.145524 (1.145524)\n","Test: [ 5/15]\tADE 0.362168 (0.434774)\tFDE 0.741961 (0.935971)\n","Test: [10/15]\tADE 0.385904 (0.368855)\tFDE 0.806165 (0.786531)\n"," * ADE  0.365 FDE  0.779\n","<Main/line:158> Validate(), ADE: tensor(0.3651, device='cuda:0')\n","ade: tensor(0.3651, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.177218914031982 , Total execute: 2230.811035633087\n","<Main/line:128> /* Train EPOCH: 347 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1797], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.510582 (0.510582)\tFDE 1.093985 (1.093985)\n","Test: [ 5/15]\tADE 0.357927 (0.429625)\tFDE 0.734131 (0.918685)\n","Test: [10/15]\tADE 0.387008 (0.370527)\tFDE 0.799271 (0.782039)\n"," * ADE  0.366 FDE  0.774\n","<Main/line:158> Validate(), ADE: tensor(0.3658, device='cuda:0')\n","ade: tensor(0.3658, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.30202579498291 , Total execute: 2242.1130604743958\n","<Main/line:128> /* Train EPOCH: 348 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0795], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.525514 (0.525514)\tFDE 1.130507 (1.130507)\n","Test: [ 5/15]\tADE 0.332616 (0.420581)\tFDE 0.681457 (0.900419)\n","Test: [10/15]\tADE 0.388654 (0.361545)\tFDE 0.818400 (0.769345)\n"," * ADE  0.357 FDE  0.761\n","<Main/line:158> Validate(), ADE: tensor(0.3572, device='cuda:0')\n","ade: tensor(0.3572, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.199973106384277 , Total execute: 2253.3130328655243\n","<Main/line:128> /* Train EPOCH: 349 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1654], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.518307 (0.518307)\tFDE 1.127721 (1.127721)\n","Test: [ 5/15]\tADE 0.343815 (0.419535)\tFDE 0.700783 (0.903669)\n","Test: [10/15]\tADE 0.387699 (0.360057)\tFDE 0.810759 (0.766213)\n"," * ADE  0.356 FDE  0.758\n","<Main/line:158> Validate(), ADE: tensor(0.3555, device='cuda:0')\n","ade: tensor(0.3555, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.204997539520264 , Total execute: 2264.5180294513702\n","<Main/line:128> /* Train EPOCH: 350 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3697], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.529074 (0.529074)\tFDE 1.136129 (1.136129)\n","Test: [ 5/15]\tADE 0.349566 (0.428889)\tFDE 0.708369 (0.916369)\n","Test: [10/15]\tADE 0.390688 (0.369000)\tFDE 0.815473 (0.778717)\n"," * ADE  0.365 FDE  0.772\n","<Main/line:158> Validate(), ADE: tensor(0.3654, device='cuda:0')\n","ade: tensor(0.3654, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.1937735080719 , Total execute: 2275.7118022441864\n","<Main/line:128> /* Train EPOCH: 351 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1710], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.542950 (0.542950)\tFDE 1.154150 (1.154150)\n","Test: [ 5/15]\tADE 0.364113 (0.431464)\tFDE 0.730560 (0.916619)\n","Test: [10/15]\tADE 0.395542 (0.372400)\tFDE 0.810387 (0.777763)\n"," * ADE  0.369 FDE  0.770\n","<Main/line:158> Validate(), ADE: tensor(0.3688, device='cuda:0')\n","ade: tensor(0.3688, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.074975728988647 , Total execute: 2286.7867770195007\n","<Main/line:128> /* Train EPOCH: 352 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0148], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.527210 (0.527210)\tFDE 1.141670 (1.141670)\n","Test: [ 5/15]\tADE 0.348745 (0.432026)\tFDE 0.710729 (0.929463)\n","Test: [10/15]\tADE 0.395450 (0.371528)\tFDE 0.827604 (0.789112)\n"," * ADE  0.364 FDE  0.775\n","<Main/line:158> Validate(), ADE: tensor(0.3644, device='cuda:0')\n","ade: tensor(0.3644, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.17790412902832 , Total execute: 2297.9646801948547\n","<Main/line:128> /* Train EPOCH: 353 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0573], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.541487 (0.541487)\tFDE 1.154892 (1.154892)\n","Test: [ 5/15]\tADE 0.356892 (0.432587)\tFDE 0.733218 (0.929846)\n","Test: [10/15]\tADE 0.396154 (0.367383)\tFDE 0.823592 (0.781726)\n"," * ADE  0.363 FDE  0.773\n","<Main/line:158> Validate(), ADE: tensor(0.3629, device='cuda:0')\n","ade: tensor(0.3629, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.177674293518066 , Total execute: 2309.1423535346985\n","<Main/line:128> /* Train EPOCH: 354 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9642], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.525500 (0.525500)\tFDE 1.135403 (1.135403)\n","Test: [ 5/15]\tADE 0.354567 (0.436825)\tFDE 0.725289 (0.939968)\n","Test: [10/15]\tADE 0.400993 (0.372322)\tFDE 0.842200 (0.793258)\n"," * ADE  0.368 FDE  0.784\n","<Main/line:158> Validate(), ADE: tensor(0.3676, device='cuda:0')\n","ade: tensor(0.3676, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.247208833694458 , Total execute: 2320.389561653137\n","<Main/line:128> /* Train EPOCH: 355 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([5.0348], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.522869 (0.522869)\tFDE 1.142713 (1.142713)\n","Test: [ 5/15]\tADE 0.426223 (0.470658)\tFDE 0.811441 (0.974164)\n","Test: [10/15]\tADE 0.485877 (0.453723)\tFDE 0.960188 (0.905547)\n"," * ADE  0.456 FDE  0.907\n","<Main/line:158> Validate(), ADE: tensor(0.4558, device='cuda:0')\n","ade: tensor(0.4558, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.151782989501953 , Total execute: 2331.5413434505463\n","<Main/line:128> /* Train EPOCH: 356 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.3803], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.565877 (0.565877)\tFDE 1.203907 (1.203907)\n","Test: [ 5/15]\tADE 0.382154 (0.454230)\tFDE 0.752623 (0.955778)\n","Test: [10/15]\tADE 0.429603 (0.402769)\tFDE 0.881960 (0.833994)\n"," * ADE  0.402 FDE  0.831\n","<Main/line:158> Validate(), ADE: tensor(0.4016, device='cuda:0')\n","ade: tensor(0.4016, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.184611797332764 , Total execute: 2342.7259545326233\n","<Main/line:128> /* Train EPOCH: 357 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([4.1477], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.547628 (0.547627)\tFDE 1.159325 (1.159325)\n","Test: [ 5/15]\tADE 0.349313 (0.436403)\tFDE 0.709966 (0.931874)\n","Test: [10/15]\tADE 0.393489 (0.374622)\tFDE 0.814135 (0.791833)\n"," * ADE  0.372 FDE  0.786\n","<Main/line:158> Validate(), ADE: tensor(0.3722, device='cuda:0')\n","ade: tensor(0.3722, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.171821117401123 , Total execute: 2353.8977749347687\n","<Main/line:128> /* Train EPOCH: 358 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.8559], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.547496 (0.547496)\tFDE 1.188073 (1.188073)\n","Test: [ 5/15]\tADE 0.352208 (0.439233)\tFDE 0.706985 (0.939546)\n","Test: [10/15]\tADE 0.406430 (0.374887)\tFDE 0.831370 (0.789763)\n"," * ADE  0.370 FDE  0.779\n","<Main/line:158> Validate(), ADE: tensor(0.3701, device='cuda:0')\n","ade: tensor(0.3701, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.077953815460205 , Total execute: 2364.975727558136\n","<Main/line:128> /* Train EPOCH: 359 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.6957], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.546865 (0.546865)\tFDE 1.180481 (1.180481)\n","Test: [ 5/15]\tADE 0.355293 (0.442817)\tFDE 0.719535 (0.948664)\n","Test: [10/15]\tADE 0.396892 (0.375147)\tFDE 0.828687 (0.796791)\n"," * ADE  0.370 FDE  0.786\n","<Main/line:158> Validate(), ADE: tensor(0.3704, device='cuda:0')\n","ade: tensor(0.3704, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.154726505279541 , Total execute: 2376.130453109741\n","<Main/line:128> /* Train EPOCH: 360 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.4369], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.578346 (0.578346)\tFDE 1.246218 (1.246218)\n","Test: [ 5/15]\tADE 0.362737 (0.452948)\tFDE 0.729819 (0.967063)\n","Test: [10/15]\tADE 0.425789 (0.390161)\tFDE 0.891567 (0.823689)\n"," * ADE  0.383 FDE  0.808\n","<Main/line:158> Validate(), ADE: tensor(0.3832, device='cuda:0')\n","ade: tensor(0.3832, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.136870384216309 , Total execute: 2387.267322778702\n","<Main/line:128> /* Train EPOCH: 361 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3784], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.558904 (0.558904)\tFDE 1.196327 (1.196327)\n","Test: [ 5/15]\tADE 0.360435 (0.444961)\tFDE 0.727286 (0.948045)\n","Test: [10/15]\tADE 0.414071 (0.378985)\tFDE 0.862867 (0.798957)\n"," * ADE  0.373 FDE  0.788\n","<Main/line:158> Validate(), ADE: tensor(0.3734, device='cuda:0')\n","ade: tensor(0.3734, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.102807760238647 , Total execute: 2398.3701298236847\n","<Main/line:128> /* Train EPOCH: 362 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.4053], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.545314 (0.545314)\tFDE 1.179378 (1.179378)\n","Test: [ 5/15]\tADE 0.370651 (0.448670)\tFDE 0.744563 (0.956471)\n","Test: [10/15]\tADE 0.426997 (0.387272)\tFDE 0.880660 (0.811882)\n"," * ADE  0.383 FDE  0.804\n","<Main/line:158> Validate(), ADE: tensor(0.3834, device='cuda:0')\n","ade: tensor(0.3834, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.113274097442627 , Total execute: 2409.4834032058716\n","<Main/line:128> /* Train EPOCH: 363 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3053], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.558982 (0.558982)\tFDE 1.197178 (1.197178)\n","Test: [ 5/15]\tADE 0.345974 (0.437630)\tFDE 0.700772 (0.935656)\n","Test: [10/15]\tADE 0.398059 (0.368622)\tFDE 0.823942 (0.778774)\n"," * ADE  0.363 FDE  0.767\n","<Main/line:158> Validate(), ADE: tensor(0.3630, device='cuda:0')\n","ade: tensor(0.3630, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.120299816131592 , Total execute: 2420.6037023067474\n","<Main/line:128> /* Train EPOCH: 364 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2760], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.565539 (0.565539)\tFDE 1.212144 (1.212144)\n","Test: [ 5/15]\tADE 0.368210 (0.452874)\tFDE 0.737926 (0.961892)\n","Test: [10/15]\tADE 0.426711 (0.389466)\tFDE 0.883311 (0.816424)\n"," * ADE  0.382 FDE  0.802\n","<Main/line:158> Validate(), ADE: tensor(0.3823, device='cuda:0')\n","ade: tensor(0.3823, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.188783645629883 , Total execute: 2431.7924852371216\n","<Main/line:128> /* Train EPOCH: 365 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1932], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.559253 (0.559253)\tFDE 1.220890 (1.220890)\n","Test: [ 5/15]\tADE 0.344545 (0.434893)\tFDE 0.696076 (0.938981)\n","Test: [10/15]\tADE 0.409473 (0.371047)\tFDE 0.856561 (0.789840)\n"," * ADE  0.367 FDE  0.780\n","<Main/line:158> Validate(), ADE: tensor(0.3669, device='cuda:0')\n","ade: tensor(0.3669, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.366278171539307 , Total execute: 2443.1587624549866\n","<Main/line:128> /* Train EPOCH: 366 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2213], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.558252 (0.558252)\tFDE 1.194165 (1.194165)\n","Test: [ 5/15]\tADE 0.354710 (0.447112)\tFDE 0.715095 (0.953576)\n","Test: [10/15]\tADE 0.416194 (0.379606)\tFDE 0.871131 (0.802801)\n"," * ADE  0.373 FDE  0.790\n","<Main/line:158> Validate(), ADE: tensor(0.3732, device='cuda:0')\n","ade: tensor(0.3732, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.189467191696167 , Total execute: 2454.3482286930084\n","<Main/line:128> /* Train EPOCH: 367 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2984], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.566588 (0.566588)\tFDE 1.225312 (1.225312)\n","Test: [ 5/15]\tADE 0.351382 (0.441912)\tFDE 0.714817 (0.948934)\n","Test: [10/15]\tADE 0.407017 (0.376270)\tFDE 0.847661 (0.799424)\n"," * ADE  0.372 FDE  0.789\n","<Main/line:158> Validate(), ADE: tensor(0.3718, device='cuda:0')\n","ade: tensor(0.3718, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.058531522750854 , Total execute: 2465.4067590236664\n","<Main/line:128> /* Train EPOCH: 368 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2131], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.564141 (0.564141)\tFDE 1.215943 (1.215943)\n","Test: [ 5/15]\tADE 0.353140 (0.445022)\tFDE 0.708547 (0.950916)\n","Test: [10/15]\tADE 0.395707 (0.375570)\tFDE 0.823440 (0.792728)\n"," * ADE  0.369 FDE  0.778\n","<Main/line:158> Validate(), ADE: tensor(0.3688, device='cuda:0')\n","ade: tensor(0.3688, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.172995328903198 , Total execute: 2476.579753637314\n","<Main/line:128> /* Train EPOCH: 369 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2364], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.566730 (0.566730)\tFDE 1.244195 (1.244195)\n","Test: [ 5/15]\tADE 0.355615 (0.447389)\tFDE 0.728832 (0.966430)\n","Test: [10/15]\tADE 0.395053 (0.377462)\tFDE 0.823956 (0.803605)\n"," * ADE  0.370 FDE  0.787\n","<Main/line:158> Validate(), ADE: tensor(0.3704, device='cuda:0')\n","ade: tensor(0.3704, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.18936538696289 , Total execute: 2487.769117832184\n","<Main/line:128> /* Train EPOCH: 370 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3220], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.585033 (0.585033)\tFDE 1.264732 (1.264732)\n","Test: [ 5/15]\tADE 0.369476 (0.462059)\tFDE 0.753890 (0.989375)\n","Test: [10/15]\tADE 0.402288 (0.387864)\tFDE 0.841502 (0.824120)\n"," * ADE  0.382 FDE  0.810\n","<Main/line:158> Validate(), ADE: tensor(0.3815, device='cuda:0')\n","ade: tensor(0.3815, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.131672143936157 , Total execute: 2498.9007892608643\n","<Main/line:128> /* Train EPOCH: 371 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0973], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.615451 (0.615451)\tFDE 1.308482 (1.308482)\n","Test: [ 5/15]\tADE 0.380519 (0.487468)\tFDE 0.772445 (1.034035)\n","Test: [10/15]\tADE 0.424562 (0.407902)\tFDE 0.886547 (0.859711)\n"," * ADE  0.399 FDE  0.842\n","<Main/line:158> Validate(), ADE: tensor(0.3991, device='cuda:0')\n","ade: tensor(0.3991, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.112555503845215 , Total execute: 2510.0133440494537\n","<Main/line:128> /* Train EPOCH: 372 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0858], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.573179 (0.573179)\tFDE 1.222882 (1.222882)\n","Test: [ 5/15]\tADE 0.375226 (0.472507)\tFDE 0.764372 (1.004037)\n","Test: [10/15]\tADE 0.425636 (0.400824)\tFDE 0.884080 (0.844990)\n"," * ADE  0.394 FDE  0.830\n","<Main/line:158> Validate(), ADE: tensor(0.3935, device='cuda:0')\n","ade: tensor(0.3935, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.163348913192749 , Total execute: 2521.1766922473907\n","<Main/line:128> /* Train EPOCH: 373 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9974], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.595750 (0.595750)\tFDE 1.267362 (1.267362)\n","Test: [ 5/15]\tADE 0.380983 (0.478471)\tFDE 0.764838 (1.012193)\n","Test: [10/15]\tADE 0.424886 (0.409874)\tFDE 0.880327 (0.856140)\n"," * ADE  0.402 FDE  0.841\n","<Main/line:158> Validate(), ADE: tensor(0.4022, device='cuda:0')\n","ade: tensor(0.4022, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.197282075881958 , Total execute: 2532.373973608017\n","<Main/line:128> /* Train EPOCH: 374 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1159], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.559298 (0.559298)\tFDE 1.191363 (1.191363)\n","Test: [ 5/15]\tADE 0.363916 (0.456431)\tFDE 0.738553 (0.972690)\n","Test: [10/15]\tADE 0.413014 (0.391241)\tFDE 0.862581 (0.825989)\n"," * ADE  0.385 FDE  0.814\n","<Main/line:158> Validate(), ADE: tensor(0.3846, device='cuda:0')\n","ade: tensor(0.3846, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.262988328933716 , Total execute: 2543.6369609832764\n","<Main/line:128> /* Train EPOCH: 375 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9755], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.569792 (0.569792)\tFDE 1.225670 (1.225670)\n","Test: [ 5/15]\tADE 0.390064 (0.470992)\tFDE 0.789238 (1.003953)\n","Test: [10/15]\tADE 0.431187 (0.407337)\tFDE 0.892611 (0.856052)\n"," * ADE  0.401 FDE  0.843\n","<Main/line:158> Validate(), ADE: tensor(0.4005, device='cuda:0')\n","ade: tensor(0.4005, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.13461709022522 , Total execute: 2554.7715771198273\n","<Main/line:128> /* Train EPOCH: 376 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9514], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.561994 (0.561994)\tFDE 1.214307 (1.214307)\n","Test: [ 5/15]\tADE 0.399365 (0.468384)\tFDE 0.811571 (1.003401)\n","Test: [10/15]\tADE 0.419279 (0.402230)\tFDE 0.873431 (0.850935)\n"," * ADE  0.397 FDE  0.840\n","<Main/line:158> Validate(), ADE: tensor(0.3969, device='cuda:0')\n","ade: tensor(0.3969, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.134359121322632 , Total execute: 2565.9059352874756\n","<Main/line:128> /* Train EPOCH: 377 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9952], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.579609 (0.579609)\tFDE 1.256640 (1.256640)\n","Test: [ 5/15]\tADE 0.388334 (0.473003)\tFDE 0.783666 (1.008919)\n","Test: [10/15]\tADE 0.408978 (0.402291)\tFDE 0.855698 (0.848780)\n"," * ADE  0.396 FDE  0.837\n","<Main/line:158> Validate(), ADE: tensor(0.3963, device='cuda:0')\n","ade: tensor(0.3963, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.188149690628052 , Total execute: 2577.094084262848\n","<Main/line:128> /* Train EPOCH: 378 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0251], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.556108 (0.556108)\tFDE 1.200768 (1.200768)\n","Test: [ 5/15]\tADE 0.387157 (0.453718)\tFDE 0.771541 (0.966070)\n","Test: [10/15]\tADE 0.421482 (0.396712)\tFDE 0.871017 (0.830373)\n"," * ADE  0.392 FDE  0.820\n","<Main/line:158> Validate(), ADE: tensor(0.3919, device='cuda:0')\n","ade: tensor(0.3919, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.250296592712402 , Total execute: 2588.3443801403046\n","<Main/line:128> /* Train EPOCH: 379 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9757], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.591771 (0.591771)\tFDE 1.293823 (1.293823)\n","Test: [ 5/15]\tADE 0.373775 (0.468127)\tFDE 0.756390 (1.006724)\n","Test: [10/15]\tADE 0.416228 (0.401629)\tFDE 0.868556 (0.851034)\n"," * ADE  0.395 FDE  0.837\n","<Main/line:158> Validate(), ADE: tensor(0.3949, device='cuda:0')\n","ade: tensor(0.3949, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.11770224571228 , Total execute: 2599.462081670761\n","<Main/line:128> /* Train EPOCH: 380 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9510], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.596028 (0.596028)\tFDE 1.280057 (1.280057)\n","Test: [ 5/15]\tADE 0.372888 (0.465398)\tFDE 0.750593 (0.994569)\n","Test: [10/15]\tADE 0.410546 (0.396436)\tFDE 0.857185 (0.838532)\n"," * ADE  0.391 FDE  0.828\n","<Main/line:158> Validate(), ADE: tensor(0.3912, device='cuda:0')\n","ade: tensor(0.3912, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.095612287521362 , Total execute: 2610.557693004608\n","<Main/line:128> /* Train EPOCH: 381 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.8435], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.600380 (0.600380)\tFDE 1.290197 (1.290197)\n","Test: [ 5/15]\tADE 0.372217 (0.473676)\tFDE 0.751107 (1.007675)\n","Test: [10/15]\tADE 0.423409 (0.402434)\tFDE 0.879410 (0.846994)\n"," * ADE  0.398 FDE  0.837\n","<Main/line:158> Validate(), ADE: tensor(0.3975, device='cuda:0')\n","ade: tensor(0.3975, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.118738651275635 , Total execute: 2621.676430940628\n","<Main/line:128> /* Train EPOCH: 382 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0143], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.597074 (0.597074)\tFDE 1.271256 (1.271256)\n","Test: [ 5/15]\tADE 0.374741 (0.472099)\tFDE 0.766743 (1.008172)\n","Test: [10/15]\tADE 0.406142 (0.401830)\tFDE 0.849408 (0.852763)\n"," * ADE  0.397 FDE  0.844\n","<Main/line:158> Validate(), ADE: tensor(0.3972, device='cuda:0')\n","ade: tensor(0.3972, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.10935378074646 , Total execute: 2632.7857837677\n","<Main/line:128> /* Train EPOCH: 383 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9660], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.584809 (0.584809)\tFDE 1.255905 (1.255905)\n","Test: [ 5/15]\tADE 0.382703 (0.469736)\tFDE 0.758906 (0.995460)\n","Test: [10/15]\tADE 0.424625 (0.404702)\tFDE 0.877265 (0.847380)\n"," * ADE  0.397 FDE  0.831\n","<Main/line:158> Validate(), ADE: tensor(0.3970, device='cuda:0')\n","ade: tensor(0.3970, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.142060041427612 , Total execute: 2643.927842617035\n","<Main/line:128> /* Train EPOCH: 384 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9849], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.596067 (0.596067)\tFDE 1.282404 (1.282404)\n","Test: [ 5/15]\tADE 0.381256 (0.478880)\tFDE 0.776989 (1.021394)\n","Test: [10/15]\tADE 0.428487 (0.414652)\tFDE 0.891418 (0.875487)\n"," * ADE  0.409 FDE  0.865\n","<Main/line:158> Validate(), ADE: tensor(0.4088, device='cuda:0')\n","ade: tensor(0.4088, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.136362314224243 , Total execute: 2655.0642042160034\n","<Main/line:128> /* Train EPOCH: 385 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.3011], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.585361 (0.585361)\tFDE 1.257695 (1.257695)\n","Test: [ 5/15]\tADE 0.402941 (0.475019)\tFDE 0.817264 (1.010524)\n","Test: [10/15]\tADE 0.439374 (0.418792)\tFDE 0.911253 (0.883895)\n"," * ADE  0.412 FDE  0.870\n","<Main/line:158> Validate(), ADE: tensor(0.4124, device='cuda:0')\n","ade: tensor(0.4124, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.18140959739685 , Total execute: 2666.2456126213074\n","<Main/line:128> /* Train EPOCH: 386 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2672], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.624694 (0.624694)\tFDE 1.356728 (1.356728)\n","Test: [ 5/15]\tADE 0.384674 (0.479899)\tFDE 0.787451 (1.032248)\n","Test: [10/15]\tADE 0.410565 (0.405095)\tFDE 0.857042 (0.862701)\n"," * ADE  0.399 FDE  0.849\n","<Main/line:158> Validate(), ADE: tensor(0.3990, device='cuda:0')\n","ade: tensor(0.3990, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.19184160232544 , Total execute: 2677.437453508377\n","<Main/line:128> /* Train EPOCH: 387 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.1582], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.628365 (0.628365)\tFDE 1.332865 (1.332865)\n","Test: [ 5/15]\tADE 0.379641 (0.480155)\tFDE 0.773608 (1.019525)\n","Test: [10/15]\tADE 0.420396 (0.400731)\tFDE 0.876007 (0.846823)\n"," * ADE  0.393 FDE  0.832\n","<Main/line:158> Validate(), ADE: tensor(0.3927, device='cuda:0')\n","ade: tensor(0.3927, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.202060222625732 , Total execute: 2688.63951253891\n","<Main/line:128> /* Train EPOCH: 388 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.2258], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.625558 (0.625558)\tFDE 1.304246 (1.304246)\n","Test: [ 5/15]\tADE 0.373649 (0.488414)\tFDE 0.763330 (1.030512)\n","Test: [10/15]\tADE 0.431211 (0.410971)\tFDE 0.895966 (0.865379)\n"," * ADE  0.405 FDE  0.854\n","<Main/line:158> Validate(), ADE: tensor(0.4046, device='cuda:0')\n","ade: tensor(0.4046, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.079232931137085 , Total execute: 2699.7187445163727\n","<Main/line:128> /* Train EPOCH: 389 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9670], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.581430 (0.581430)\tFDE 1.243104 (1.243104)\n","Test: [ 5/15]\tADE 0.368113 (0.467170)\tFDE 0.744469 (0.991458)\n","Test: [10/15]\tADE 0.408444 (0.393888)\tFDE 0.848904 (0.830543)\n"," * ADE  0.388 FDE  0.817\n","<Main/line:158> Validate(), ADE: tensor(0.3876, device='cuda:0')\n","ade: tensor(0.3876, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.18839955329895 , Total execute: 2710.9071431159973\n","<Main/line:128> /* Train EPOCH: 390 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0502], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.564342 (0.564342)\tFDE 1.229643 (1.229643)\n","Test: [ 5/15]\tADE 0.352405 (0.454950)\tFDE 0.731015 (0.982784)\n","Test: [10/15]\tADE 0.427833 (0.388091)\tFDE 0.902185 (0.834337)\n"," * ADE  0.382 FDE  0.822\n","<Main/line:158> Validate(), ADE: tensor(0.3820, device='cuda:0')\n","ade: tensor(0.3820, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.129266023635864 , Total execute: 2722.036408185959\n","<Main/line:128> /* Train EPOCH: 391 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.8832], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.601462 (0.601462)\tFDE 1.297076 (1.297076)\n","Test: [ 5/15]\tADE 0.350609 (0.460993)\tFDE 0.726551 (0.992064)\n","Test: [10/15]\tADE 0.416262 (0.390080)\tFDE 0.879928 (0.837561)\n"," * ADE  0.381 FDE  0.820\n","<Main/line:158> Validate(), ADE: tensor(0.3815, device='cuda:0')\n","ade: tensor(0.3815, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.153021574020386 , Total execute: 2733.189428806305\n","<Main/line:128> /* Train EPOCH: 392 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9458], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.641548 (0.641548)\tFDE 1.375287 (1.375287)\n","Test: [ 5/15]\tADE 0.370474 (0.491239)\tFDE 0.766708 (1.050163)\n","Test: [10/15]\tADE 0.444645 (0.414219)\tFDE 0.930745 (0.883713)\n"," * ADE  0.404 FDE  0.864\n","<Main/line:158> Validate(), ADE: tensor(0.4038, device='cuda:0')\n","ade: tensor(0.4038, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.271857738494873 , Total execute: 2744.461285829544\n","<Main/line:128> /* Train EPOCH: 393 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9084], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.629035 (0.629034)\tFDE 1.351578 (1.351578)\n","Test: [ 5/15]\tADE 0.367431 (0.478905)\tFDE 0.754721 (1.022834)\n","Test: [10/15]\tADE 0.444473 (0.406607)\tFDE 0.928835 (0.862960)\n"," * ADE  0.398 FDE  0.846\n","<Main/line:158> Validate(), ADE: tensor(0.3979, device='cuda:0')\n","ade: tensor(0.3979, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.274927616119385 , Total execute: 2755.736212491989\n","<Main/line:128> /* Train EPOCH: 394 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0235], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.654821 (0.654821)\tFDE 1.398552 (1.398552)\n","Test: [ 5/15]\tADE 0.370456 (0.489815)\tFDE 0.763310 (1.046802)\n","Test: [10/15]\tADE 0.429037 (0.412444)\tFDE 0.900455 (0.878269)\n"," * ADE  0.403 FDE  0.860\n","<Main/line:158> Validate(), ADE: tensor(0.4026, device='cuda:0')\n","ade: tensor(0.4026, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.114392042160034 , Total execute: 2766.850603580475\n","<Main/line:128> /* Train EPOCH: 395 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9269], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.613201 (0.613201)\tFDE 1.320501 (1.320501)\n","Test: [ 5/15]\tADE 0.373265 (0.474892)\tFDE 0.764330 (1.016892)\n","Test: [10/15]\tADE 0.417538 (0.401592)\tFDE 0.876095 (0.853979)\n"," * ADE  0.393 FDE  0.837\n","<Main/line:158> Validate(), ADE: tensor(0.3926, device='cuda:0')\n","ade: tensor(0.3926, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.227055311203003 , Total execute: 2778.077657699585\n","<Main/line:128> /* Train EPOCH: 396 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9983], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.661735 (0.661735)\tFDE 1.401654 (1.401654)\n","Test: [ 5/15]\tADE 0.368148 (0.495314)\tFDE 0.752757 (1.052171)\n","Test: [10/15]\tADE 0.445116 (0.413282)\tFDE 0.936751 (0.877273)\n"," * ADE  0.402 FDE  0.855\n","<Main/line:158> Validate(), ADE: tensor(0.4024, device='cuda:0')\n","ade: tensor(0.4024, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.147668838500977 , Total execute: 2789.22532582283\n","<Main/line:128> /* Train EPOCH: 397 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0890], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.597671 (0.597671)\tFDE 1.267402 (1.267402)\n","Test: [ 5/15]\tADE 0.344489 (0.450001)\tFDE 0.703772 (0.960185)\n","Test: [10/15]\tADE 0.408028 (0.378203)\tFDE 0.854922 (0.804179)\n"," * ADE  0.369 FDE  0.787\n","<Main/line:158> Validate(), ADE: tensor(0.3691, device='cuda:0')\n","ade: tensor(0.3691, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.163302421569824 , Total execute: 2800.3886275291443\n","<Main/line:128> /* Train EPOCH: 398 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([3.0111], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.614382 (0.614382)\tFDE 1.317155 (1.317155)\n","Test: [ 5/15]\tADE 0.368151 (0.478386)\tFDE 0.747313 (1.015748)\n","Test: [10/15]\tADE 0.423265 (0.402621)\tFDE 0.878311 (0.847634)\n"," * ADE  0.393 FDE  0.827\n","<Main/line:158> Validate(), ADE: tensor(0.3930, device='cuda:0')\n","ade: tensor(0.3930, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.090543508529663 , Total execute: 2811.479170322418\n","<Main/line:128> /* Train EPOCH: 399 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.8768], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.601137 (0.601137)\tFDE 1.298746 (1.298746)\n","Test: [ 5/15]\tADE 0.357947 (0.465023)\tFDE 0.739258 (1.003260)\n","Test: [10/15]\tADE 0.416474 (0.392832)\tFDE 0.881748 (0.843848)\n"," * ADE  0.384 FDE  0.826\n","<Main/line:158> Validate(), ADE: tensor(0.3844, device='cuda:0')\n","ade: tensor(0.3844, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.11773943901062 , Total execute: 2822.596908569336\n","<Main/line:128> /* Train EPOCH: 400 (training_step: 3 )\n","<Main/line:277> Batch update over(best_K: 1 ), Loss: tensor([2.9142], device='cuda:0', grad_fn=<AddBackward0>)\n","Test: [ 0/15]\tADE 0.642386 (0.642386)\tFDE 1.365121 (1.365121)\n","Test: [ 5/15]\tADE 0.379451 (0.489663)\tFDE 0.773563 (1.041637)\n","Test: [10/15]\tADE 0.424240 (0.408864)\tFDE 0.883754 (0.862761)\n"," * ADE  0.399 FDE  0.843\n","<Main/line:158> Validate(), ADE: tensor(0.3987, device='cuda:0')\n","ade: tensor(0.3987, device='cuda:0')\n","<Main/line:167> */ EPOCH execute: 11.175570249557495 , Total execute: 2833.7724781036377\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y2qdKQ0-7TgZ","colab_type":"text"},"source":["### Evaluate\n","\n","```\n","\n","K: 1/Dataset: zara2/Dataset: zara2, Pred Len: 8, ADE: 0.198548972607, FDE: 0.409291565418\n","K: 5/Dataset: zara2, Pred Len: 8, ADE: 0.204093366861, FDE: 0.407672882080\n","K: 10/Dataset: zara2/Pred Len: 8/ADE: 0.192609801888, FDE: 0.391454011202\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"L9pLgtJq7Uto","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1599318213294,"user_tz":-480,"elapsed":21828,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}},"outputId":"6bf409c4-b0e7-47fc-fcff-cc4ff1584d86"},"source":["import argparse\n","import os\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","import torch\n","\n","args = easydict.EasyDict({\n","        \"log_dir\": \"./\",\n","        \"dataset_name\": \"zara2\",\n","        \"delim\": \"\\t\",\n","        \"loader_num_workers\": 1,  #原:4\n","        \"obs_len\": 8,\n","        \n","        \"skip\": 1,\n","        \"seed\": 72,\n","        \"batch_size\":64,\n","        \n","        \"noise_dim\":(16,),\n","        \"noise_type\":\"gaussian\",\n","        \"noise_mix_type\": \"global\",\n","\n","        \"traj_lstm_input_size\":2,\n","        \"traj_lstm_hidden_size\":32,\n","        \"heads\":\"4,1\",\n","        \"hidden_units\":\"16\",\n","        \"graph_network_out_dims\":32,\n","        \"graph_lstm_hidden_size\":32,\n","        \"dropout\":0,\n","        \"alpha\": 0.2,\n","        \"lr\":1e-3,\n","        \"start_epoch\":0,\n","        \n","        \n","        \"use_gpu\":1,\n","        \"gpu_num\":\"0\",\n","        \"print_every\":5,\n","\n","        \"resume\":\"checkpoint/bestK10_checkpoint295.pth.tar\",\n","\n","        \"pred_len\": 8,\n","        \"num_samples\": 20,\n","        \"epoch_step1\":150,\n","        \"epoch_step2\":250,\n","        \"num_epochs\":400,\n","\n","        \"dset_type\":\"test\"\n","})\n","\n","\n","\n","def evaluate_helper(error, seq_start_end):\n","    sum_ = 0\n","    error = torch.stack(error, dim=1)\n","    for (start, end) in seq_start_end:\n","        start = start.item()\n","        end = end.item()\n","        _error = error[start:end]\n","        _error = torch.sum(_error, dim=0)\n","        _error = torch.min(_error)\n","        sum_ += _error\n","    return sum_\n","\n","\n","def get_generator(checkpoint):\n","    n_units = (\n","        [args.traj_lstm_hidden_size]\n","        + [int(x) for x in args.hidden_units.strip().split(\",\")]\n","        + [args.graph_lstm_hidden_size]\n","    )\n","    n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n","    model = TrajectoryGenerator(\n","        obs_len=args.obs_len,\n","        pred_len=args.pred_len,\n","        traj_lstm_input_size=args.traj_lstm_input_size,\n","        traj_lstm_hidden_size=args.traj_lstm_hidden_size,\n","        n_units=n_units,\n","        n_heads=n_heads,\n","        graph_network_out_dims=args.graph_network_out_dims,\n","        dropout=args.dropout,\n","        alpha=args.alpha,\n","        graph_lstm_hidden_size=args.graph_lstm_hidden_size,\n","        noise_dim=args.noise_dim,\n","        noise_type=args.noise_type,\n","    )\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    model.cuda()\n","    model.eval()\n","    return model\n","\n","\n","def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n","    ade = displacement_error(pred_traj_fake, pred_traj_gt, mode=\"raw\")\n","    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1], mode=\"raw\")\n","    return ade, fde\n","\n","\n","def evaluate(args, loader, generator):\n","    ade_outer, fde_outer = [], []\n","    total_traj = 0\n","    with torch.no_grad():\n","        for batch in loader:\n","            batch = [tensor.cuda() for tensor in batch]\n","            (\n","                obs_traj,\n","                pred_traj_gt,\n","                obs_traj_rel,\n","                pred_traj_gt_rel,\n","                non_linear_ped,\n","                loss_mask,\n","                seq_start_end,\n","            ) = batch\n","\n","            ade, fde = [], []\n","            total_traj += pred_traj_gt.size(1)\n","\n","            for _ in range(args.num_samples):\n","                pred_traj_fake_rel = generator(\n","                    obs_traj_rel, obs_traj, seq_start_end, 0, 3\n","                )\n","                pred_traj_fake_rel = pred_traj_fake_rel[-args.pred_len :]\n","\n","                pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n","                ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n","                ade.append(ade_)\n","                fde.append(fde_)\n","            ade_sum = evaluate_helper(ade, seq_start_end)\n","            fde_sum = evaluate_helper(fde, seq_start_end)\n","\n","            ade_outer.append(ade_sum)\n","            fde_outer.append(fde_sum)\n","\n","        ade = sum(ade_outer) / (total_traj * args.pred_len)\n","        fde = sum(fde_outer) / (total_traj)\n","        return ade, fde\n","\n","\n","def main(args):\n","    checkpoint = torch.load(args.resume)\n","    generator = get_generator(checkpoint)\n","    path = get_dset_path(args.dataset_name, args.dset_type)\n","\n","    _, loader = data_loader(args, path)\n","    ade, fde = evaluate(args, loader, generator)\n","    print(\n","        \"Dataset: {}, Pred Len: {}, ADE: {:.12f}, FDE: {:.12f}\".format(\n","            args.dataset_name, args.pred_len, ade, fde\n","        )\n","    )\n","\n","if __name__ == \"__main__\":\n","    #args = parser.parse_args()\n","    torch.manual_seed(72)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    main(args)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["<Utils/line:106> datasets: zara2 test\n","<DataLoader/line:7> path: STGAT/datasets/zara2/test\n","<Dataset/line:162> file: crowds_zara02.txt\n","<Dataset/line:359> time-step數量: 956 (len(seq_list)) , 所有軌跡數量: (6622, 2, 16)  (n_traj, 2, 20)\n","<Dataset/line:427> 記錄各time-step內軌跡的index數量: 956 (len(seq_start_end))\n","Dataset: zara2, Pred Len: 8, ADE: 0.204093366861, FDE: 0.407672882080\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OcF-Qi1EAq6J","colab_type":"text"},"source":["### Draw"]},{"cell_type":"code","metadata":{"id":"evIhRUUMAqaD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1599318761200,"user_tz":-480,"elapsed":198194,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}},"outputId":"8804eb85-1ed4-4cf9-80ba-7ad53ee1a653"},"source":["\n","import matplotlib.pyplot as plt\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n","\n","plt.style.use(\"seaborn-dark\")\n","\n","args = easydict.EasyDict({\n","        \"log_dir\": \"./\",\n","        \"dataset_name\": \"zara2\",\n","        \"delim\": \"\\t\",\n","        \"loader_num_workers\": 1,  #原:4\n","        \"obs_len\": 8,\n","        \n","        \"skip\": 1,\n","        \"seed\": 72,\n","        \"batch_size\":64,\n","        \n","        \"noise_dim\":(16,),\n","        \"noise_type\":\"gaussian\",\n","        \"noise_mix_type\": \"global\",\n","\n","        \"traj_lstm_input_size\":2,\n","        \"traj_lstm_hidden_size\":32,\n","        \"heads\":\"4,1\",\n","        \"hidden_units\":\"16\",\n","        \"graph_network_out_dims\":32,\n","        \"graph_lstm_hidden_size\":32,\n","        \"dropout\":0,\n","        \"alpha\": 0.2,\n","        \"lr\":1e-3,\n","        \"start_epoch\":0,\n","        \n","        \n","        \"use_gpu\":1,\n","        \"gpu_num\":\"0\",\n","        \"print_every\":5,\n","\n","        \"resume\":\"checkpoint/bestK10_checkpoint295.pth.tar\",\n","\n","        \"pred_len\": 8,\n","        \"num_samples\": 20,\n","        \"epoch_step1\":150,\n","        \"epoch_step2\":250,\n","        \"num_epochs\":400,\n","\n","        \"dset_type\":\"test\"\n","})\n","\n","\n","def evaluate_helper(error, seq_start_end, model_output_traj, model_output_traj_best):\n","    error = torch.stack(error, dim=1)\n","    for (start, end) in seq_start_end:\n","        start = start.item()\n","        end = end.item()\n","        _error = error[start:end]\n","        _error = torch.sum(_error, dim=0)\n","        min_index = _error.min(0)[1].item()\n","        model_output_traj_best[:, start:end, :] = model_output_traj[min_index][\n","            :, start:end, :\n","        ]\n","    return model_output_traj_best\n","\n","\n","def get_generator(checkpoint):\n","    n_units = (\n","        [args.traj_lstm_hidden_size]\n","        + [int(x) for x in args.hidden_units.strip().split(\",\")]\n","        + [args.graph_lstm_hidden_size]\n","    )\n","    n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n","    model = TrajectoryGenerator(\n","        obs_len=args.obs_len,\n","        pred_len=args.pred_len,\n","        traj_lstm_input_size=args.traj_lstm_input_size,\n","        traj_lstm_hidden_size=args.traj_lstm_hidden_size,\n","        n_units=n_units,\n","        n_heads=n_heads,\n","        graph_network_out_dims=args.graph_network_out_dims,\n","        dropout=args.dropout,\n","        alpha=args.alpha,\n","        graph_lstm_hidden_size=args.graph_lstm_hidden_size,\n","        noise_dim=args.noise_dim,\n","        noise_type=args.noise_type,\n","    )\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    model.cuda()\n","    model.eval()\n","    return model\n","\n","\n","def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n","    ade = displacement_error(pred_traj_fake, pred_traj_gt, mode=\"raw\")\n","    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1], mode=\"raw\")\n","    return ade, fde\n","\n","\n","def plot_trajectory(args, loader, generator):\n","    ground_truth_input = []\n","    all_model_output_traj = []\n","    ground_truth_output = []\n","    pic_cnt = 0\n","    with torch.no_grad():\n","        for batch in loader:\n","            batch = [tensor.cuda() for tensor in batch]\n","            (\n","                obs_traj,\n","                pred_traj_gt,\n","                obs_traj_rel,\n","                pred_traj_gt_rel,\n","                non_linear_ped,\n","                loss_mask,\n","                seq_start_end,\n","            ) = batch\n","            ade = []\n","            ground_truth_input.append(obs_traj)\n","            ground_truth_output.append(pred_traj_gt)\n","            model_output_traj = []\n","            model_output_traj_best = torch.ones_like(pred_traj_gt).cuda()\n","\n","            for _ in range(args.num_samples):\n","                pred_traj_fake_rel = generator(\n","                    obs_traj_rel, obs_traj, seq_start_end, 0, 3\n","                )\n","                pred_traj_fake_rel = pred_traj_fake_rel[-args.pred_len :]\n","\n","                pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n","                model_output_traj.append(pred_traj_fake)\n","                ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n","                ade.append(ade_)\n","            model_output_traj_best = evaluate_helper(\n","                ade, seq_start_end, model_output_traj, model_output_traj_best\n","            )\n","            all_model_output_traj.append(model_output_traj_best)\n","\n","            for (start, end) in seq_start_end:\n","                plt.figure(figsize=(20,15), dpi=100)\n","                ground_truth_input_x_piccoor = (\n","                    obs_traj[:, start:end, :].cpu().numpy()[:, :, 0].T\n","                )\n","                ground_truth_input_y_piccoor = (\n","                    obs_traj[:, start:end, :].cpu().numpy()[:, :, 1].T\n","                )\n","                ground_truth_output_x_piccoor = (\n","                    pred_traj_gt[:, start:end, :].cpu().numpy()[:, :, 0].T\n","                )\n","                ground_truth_output_y_piccoor = (\n","                    pred_traj_gt[:, start:end, :].cpu().numpy()[:, :, 1].T\n","                )\n","                model_output_x_piccoor = (\n","                    model_output_traj_best[:, start:end, :].cpu().numpy()[:, :, 0].T\n","                )\n","                model_output_y_piccoor = (\n","                    model_output_traj_best[:, start:end, :].cpu().numpy()[:, :, 1].T\n","                )\n","                for i in range(ground_truth_output_x_piccoor.shape[0]):\n","\n","                    observed_line = plt.plot(\n","                        ground_truth_input_x_piccoor[i, :],\n","                        ground_truth_input_y_piccoor[i, :],\n","                        \"r-\",\n","                        linewidth=4,\n","                        label=\"Observed Trajectory\",\n","                    )[0]\n","                    observed_line.axes.annotate(\n","                        \"\",\n","                        xytext=(\n","                            ground_truth_input_x_piccoor[i, -2],\n","                            ground_truth_input_y_piccoor[i, -2],\n","                        ),\n","                        xy=(\n","                            ground_truth_input_x_piccoor[i, -1],\n","                            ground_truth_input_y_piccoor[i, -1],\n","                        ),\n","                        arrowprops=dict(\n","                            arrowstyle=\"->\", color=observed_line.get_color(), lw=1\n","                        ),\n","                        size=20,\n","                    )\n","                    ground_line = plt.plot(\n","                        np.append(\n","                            ground_truth_input_x_piccoor[i, -1],\n","                            ground_truth_output_x_piccoor[i, :],\n","                        ),\n","                        np.append(\n","                            ground_truth_input_y_piccoor[i, -1],\n","                            ground_truth_output_y_piccoor[i, :],\n","                        ),\n","                        \"b-\",\n","                        linewidth=4,\n","                        label=\"Ground Truth\",\n","                    )[0]\n","                    predict_line = plt.plot(\n","                        np.append(\n","                            ground_truth_input_x_piccoor[i, -1],\n","                            model_output_x_piccoor[i, :],\n","                        ),\n","                        np.append(\n","                            ground_truth_input_y_piccoor[i, -1],\n","                            model_output_y_piccoor[i, :],\n","                        ),\n","                        color=\"#ffff00\",\n","                        ls=\"--\",\n","                        linewidth=4,\n","                        label=\"Predicted Trajectory\",\n","                    )[0]\n","\n","                #plt.axis(\"off\")\n","                plt.savefig(\n","                    \"./traj_fig/pic_{}.png\".format(pic_cnt)\n","                )\n","                plt.close()\n","                pic_cnt += 1\n","\n","\n","def main(args):\n","    checkpoint = torch.load(args.resume)\n","    generator = get_generator(checkpoint)\n","    path = get_dset_path(args.dataset_name, args.dset_type)\n","\n","    _, loader = data_loader(args, path)\n","    plot_trajectory(args, loader, generator)\n","\n","\n","if __name__ == \"__main__\":\n","    #args = parser.parse_args()\n","    torch.manual_seed(args.seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    os.mkdir(\"./traj_fig\")\n","    main(args)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["<Utils/line:106> datasets: zara2 test\n","<DataLoader/line:7> path: STGAT/datasets/zara2/test\n","<Dataset/line:162> file: crowds_zara02.txt\n","<Dataset/line:359> time-step數量: 956 (len(seq_list)) , 所有軌跡數量: (6622, 2, 16)  (n_traj, 2, 20)\n","<Dataset/line:427> 記錄各time-step內軌跡的index數量: 956 (len(seq_start_end))\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-4c43e3931385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./traj_fig\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-21-4c43e3931385>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0mplot_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-4c43e3931385>\u001b[0m in \u001b[0;36mplot_trajectory\u001b[0;34m(args, loader, generator)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m#plt.axis(\"off\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 plt.savefig(\n\u001b[0;32m--> 210\u001b[0;31m                     \u001b[0;34m\"./traj_fig/pic_{}.png\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                 )\n\u001b[1;32m    212\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m-> 1229\u001b[0;31m                                                                 renderer)\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtick\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mticks_to_draw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1172\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1174\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1176\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdpi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   1403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m         \u001b[0;31m# Transform the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_non_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \u001b[0;31m# Convert the result back to the shape of the input values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mtransform_affine\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m   2363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m         \u001b[0;31m# docstring inherited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2365\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_non_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mget_affine\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2392\u001b[0;31m             return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n\u001b[0m\u001b[1;32m   2393\u001b[0m                                 self._a.get_affine().get_matrix()))\n\u001b[1;32m   2394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mget_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0;31m# A bit faster than np.identity(3).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2662\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIdentityTransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;31m# docstring inherited\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mtransform_affine\u001b[0;34m(self, points)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_affine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m         \u001b[0mmtx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1796\u001b[0m             \u001b[0mtpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maffine_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mget_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1876\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m         \"\"\"\n\u001b[0;32m-> 1878\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1879\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAABi4AAASTCAYAAADtF8XMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5TcZb0/8PfMbMtuNskGQxKKBVQEC2BXBEFFUfzZrhc7FiygFEUsV1Ga/YpeulyKXeyiFwuiooDKtSIoKIoIUhJCkk2ym20z8/39kRDhZksCu7OT7Ot1zp7Z/c5nvvvmkJPhzJvneUpFURQBAAAAAABoAuXpDgAAAAAAAHAXxQUAAAAAANA0FBcAAAAAAEDTUFwAAAAAAABNQ3EBAAAAAAA0DcUFAAAAAADQNBQXAAAAAABA01BcAAAAAAAATUNxAQAAAAAANI2Wqbz5smVrpvL2AAAAAADAFmTBgu4JZ6y4AAAAAAAAmobiAgAAAAAAaBqKCwAAAAAAoGkoLgAAAAAAgKahuAAAAAAAAJqG4gIAAAAAAGgaigsAAAAAAKBpKC4AAAAAAICmobgAAAAAAACahuICAAAAAABoGooLAAAAAACgaSguAAAAAACApqG4AAAAAAAAmobiAgAAAAAAaBqKCwAAAAAAoGkoLgAAAAAAgKahuAAAAAAAAJqG4gIAAAAAAGgaigsAAAAAAKBpKC4AAAAAAICmobgAAAAAAACahuICAAAAAABoGptdXPzxj3/MwQcfnMc85jHZe++9c955501FLgAAAAAAYAbarOKit7c3r3/967P77rvniiuuyPnnn58vfvGL+f73vz9V+QAAAAAAgBlks4qLq666Kv39/XnrW9+aWbNm5SEPeUgOOeSQfP3rX5+qfAAAAAAAwAyy2VtFlUqle/w8d+7cXHfddZMWCAAAAAAAmLk2q7jYc889M2vWrJxyyikZGBjIzTffnC996UtZtWrVVOUDAAAAAABmkM0qLubOnZszzjgjv/zlL7PXXnvlHe94R57//OenUqlMVT4AAAAAAGAGadncFzz2sY/N1772tQ0/X3zxxVm4cOGkhgIAAAAAAGamzVpxMTQ0lG9961vp6+vbcO3nP/959txzz0kPBgAAAAAAzDybVVy0trbm9NNPz1lnnZVqtZorrrgi3/nOd/LqV796qvIBAAAAAAAzSKkoimJzXnDNNdfkuOOOyw033JBFixblmGOOyf777z/q7LJlayYlJAAAAAAAsOVbsKB7wpnNLi42h+ICAAAAAAC4y6YUF5u1VRQAAAAAAMBUUlwAAAAAAABNQ3EBAAAAAAA0DcUFAAAAAADQNBQXAAAAAABA01BcAAAAAAAATUNxAQAAAAAANA3FBQAAAAAA0DQUFwAAAAAAQNNQXAAAAAAAAE1DcQHAhLre847MOues6Y4BAAAAwAyguACYoWadfkrav/zFCedKd9yRWZ8+N0W50oBUAAAAAMx0iguAGarUtzrd73hrKjf8ddy5jm98NalUMvSiFzcoGQAAAAAzmeICYIZae+TbU1+0OLPfflRSFKMPFUU6vvyFDB1wYIqe+Y0NCAAAAMCM1DLdAQCYJp2dWfPxUzLv35+fji99PoOvODiVv16fjgu+kJRKGXzBv6VUr6XlumvT//4TpzstAAAAADNEqSjG+t9s77tly9ZM1a0BmCTdRxyath98NwOve2M6T/tkStVqkqTo6Mjw0/ZPy29/nRW/vzZp0XUDAAAAcN8sWNA94YziAmCGK1//l8zf78kpjYxs9FzR2pqBQw9P//tOmIZkAAAAAGxtNqW4cMYFwAzW+rNLM+9Fzx21tEiS0shIBl/6iganAgAAAGAmU1wAzEQjI+n80ImZe9ALUrlj6ZhjRZLazg9uXC4AAAAAZjwblgPMMOWbb8qcQw9J629+NeFsKUlp+fIUCxZMfTAAAAAAiBUXADNK23e+lZ6nPWWTSou7lMdZkQEAAAAAk01xATATrF2b2Ucfkbmvf3XKq1eNOTaSSpZm2yTJr/K4XJeHpbx0SaNSAgAAAIDiAmBrV7n2T+l55lMz6wufHXOmaG3N4ItenHfk43l5vpgkOTeH5Im5Msv/NnbRAQAAAACTzRkXAFurokjHZ8/P7Pf/R0qDg2OOVR+0U9acfX5qC3vS8+Cvp+OPQ9npmr/mH7fslKIo58LLF+bgNzYwNwAAAAAzmuICYCtUWtWb7qOPTPv/XDju3OC/vzR9Hz05xezulIqrctxHT9rw3Jo1s3Pttbvlyq+/bqrjAgAAAMAGtooC2Mq0/PbX6Xn63uOWFvWu2Vl9+tlZc8Z/p5jdnSRp6/jLPWa6u/vyhCf8KsvbFk5pXgAAAAC4OysuALYW9XpmnXlauj50QkrV6phjI7vvmdVnn5/6Tjvf43pLy59Hnf/tVXtMakwAAAAAGI/iAmArUFq2LHMOf2PaLv3xuHNrDz08/ccen7S1bfRcufz3ja6tXt2dq6/eMcnaSUoKAAAAAONTXABs4Vov+2m63/yGVO5YOuZMff78rDntUxne/4Bx7rTx7oG1WiVLl5ZTrydlmwsCAAAA0AA+hgLYUtVq6fzwiZn7788ft7QYfvJTsvLSX0xQWiT1+qKNrvX09KZSGUxv731OCwAAAACbRHEBsIXq/M8PpeuTH0+pKEZ9viiX03/Mu7PqG/+T+uLtJrxfvb541OuLF9+epUu9XQAAAADQGD6JAtgS1evpPOv0MZ+uLVqcVd+8KGvf+Z6kUtnEWy4c9fp2292WpUtL9yomAAAAAGwuxQXAlmhgIKlWR31qaP9nZeWlv8jIk5+yWbcca8XF9tvfmiVLFBcAAAAANIbiAmBL1NWVoRf82z0uFa2t6Tvpw1n9ha+m2Gabzb5lrbb9qNd32OEWW0UBAAAA0DAt0x0AgHtnzSdPT3277dP6iytSe9BOWfumt6T2yEfd6/vV66Ofg7Hjjv/MtddacQEAAABAYyguALZUbW3pf+9xk3jDWanXt0m5vPweV3fY4Zb8+MeKCwAAAAAaw94fAGww2nZRO+xwS26/3dsFAAAAAI3hkygANiiK+210be7cVbn9disuAAAAAGgMxQUAGxTF7I2uzZ7dl6VLS6nXpyEQAAAAADOO4gKADYqia6Nrs2f3pVYr5c47rboAAAAAYOopLgDYYKziIimydKniAgAAAICpp7gAYIPRtopqba2mvX0oy5YpLgAAAACYeooLAO6mMurVUqnI3LlFg7MAAAAAMBMpLgC4m5FRr+64YyW77up0bgAAAACmXst0BwCgeQwOviwjI49Nf/9IvvGN5NZba3ngA4fz+c8PpbNzutMBAAAAMBOUiqKYsr0/li1bM1W3BgAAAAAAtjALFnRPOGOrKAAAAAAAoGkoLgAAAAAAgKahuAAAAAAAAJqG4gIAAAAAAGgaigsAAAAAAKBpKC4AAAAAAICmobgAYL0iSXW6QwAAAAAww7VMdwAAmkO5fEvmz39E6vWFqdcXp17fLvX6dhkcPCjV6hOmOx4AAAAAM4TiAoAkSbl8W0qlIpXKklQqS5L8PkkyMvIYxQUAAAAADWOrKACSJOXy7aNer9e3a3ASAAAAAGYyxQUASZJK5dZRrysuAAAAAGgkxQUAScZbcbG4wUkAAAAAmMkUFwAkSSqVmze6Vq/PTVF0T0MaAAAAAGYqxQUASZJy+aaNrtVqD5iGJAAAAADMZIoLAJIklcrGxUW9fv9pSAIAAADATKa4ACCl0pqUyys2um7FBQAAAACNprgAIOXyraNet+ICAAAAgEZrme4AAEy/Wu1hWbZsaSqVW1Iu/yOVys2pVG7OyMgTpjsaAAAAADOM4gKA9WalVntIarWHZGRkurMAAAAAMFPZKgoAAAAAAGgaigsAAAAAAKBpKC4AAAAAAICmobgAAAAAAACahuICAAAAAABoGooLAAAAAACgaSguAAAAAACApqG4AAAAAAAAmobiAgAAAAAAaBqKCwAAAAAAoGkoLgAAAAAAgKahuAAAAAAAAJqG4gIAAAAAAGgaigsAAAAAAKBpKC4AAAAAAICmobgAAAAAAACahuICAAAAAABoGooLAAAAAACgaSguAAAAAACApqG4AAAAAAAAmobiAgAAAAAAaBqKCwAAAAAAoGkoLgAAAAAAgKahuAAAAAAAAJqG4gIAAAAAAGgaigsAAAAAAKBpKC4AAAAAAICmobgAAAAAAACahuICAAAAAABoGooLAAAAAACgaSguAAAAAACApqG4AAAAAAAAmobigrHVaun8xMcy71n7Zs5rX5m2H3wvKYrpTgUAAAAAwFasVBRT90n0smVrpurWNEDX8cem88xT73FteK+903/CB1N91B7TlAoAAAAAgC3VggXdE85YccHoiiLtX//KRpfbfn555u3/1HQfcWjKt982DcEAAAAAANiaKS4Y26xZo14uFUU6vvKlzH/inun8yAeSvr4GBwMAAAAAYGuluGB0pVLWHnbE+CMDA+n6xMcy/4l7puOLn0tqtQaFAwAAAABga6W4YEyDr3tDVp95TmrbLhx3rnLH0nS/7fD0PH3vtP7s0galAwAAAABga+RwbibW15fOM05J55mnpjQwMOH40DOemf7jPpDaLg9rQDgAAAAAALYUm3I4t+KCTVa+7dZ0ffiktH/1gpQm+GNTVCoZfNVr0v+O96RYsKBBCQEAAAAAaGaKC6ZEy9VXpeu496bt55dPOFuf3Z21bz0mA288LOnoaEA6AAAAAACaleKCqVMUabv4++k64di03PC3CcdrO94//e89LkMvfHFSKjUgIAAAAAAAzUZxwdQbGUnH585P139+OOUVKyYef8xj03fCh1N9/BMaEA4AAAAAgGaiuKBhSqt60/nJj2fWuZ9KaXh4wvmh//eC9L3vhNQf+KAGpAMAAAAAoBkoLmi48j9uTNcHjk/Hd7414WzR1paBQ96UtUe/I8XceVMfDgAAAACAaaW4YNq0/Op/M/u4/0jrb38z4Wx9/vz0H/PuDL76kKS1tQHpAAAAAACYDooLpldRpP3Cb6TrA8en8s+bJxyv7vzg9L//pAwf8BwHeAMAAAAAbIUUFzSHwcHM+u+z0nnKySmvWT3h+PBee6f/hA+m+qg9GhAOAAAAAIBGUVzQVEp33pmu//xQOj736ZRqtXFni1IpQwe9LP3veX/qi7drUEIAAAAAAKaS4oKmVLn+L+k64di0X3LxhLPFrFlZe9gRWXv4W5PZsxuQDgAAAACAqaK4oKm1XvbTzD7uvWn50zUTzta2XZi17z42gy97ZVKpNCAdAAAAAACTTXFB86vV0vGVL6XzwyelsnTJhOPVXR+evuM/kJH9nt6AcAAAAAAATCbFBVuOvr50nnFKOs88NaWBgQnHh5/2jPQd/8HUHrZrA8IBAAAAADAZFBdsccq335auD5+U9q98KaUJ/mgW5XIGX/Hq9L/rvSm23bZBCQEAAAAAuLcUF2yxWq75Q7qOe2/arrhswtl61+wMHPm2rH3TW5LOzgakAwAAAADg3lBcsGUrirT98AfpOuHYtPztrxOO17bbPv3veX+GXvySpFxuQEAAAAAAADaH4oKtw8hIOj736XR9/MMpL18+8fjue6b/hA9m5MlPaUA4AAAAAAA2leKCrUpp9ap0/tfJmXXOWSkNDU04P3TAgek/7sTUdn5IA9IBAAAAADARxQVbpfLNN6Xrg8en41vfmHC2aGnJwGsOydq3vzvFNts0IB0AAAAAAGNRXLBVa/ntrzP7uPem9VdXTjhbnzM3a996TAbecGjS3t6AdAAAAAAA/F+KC7Z+RZG2i76T2Se9P5V/3DjheO3+D0j/+07I0PNemJRKDQgIAAAAAMBdFBfMHENDmfXpc9L5iY+l3Ns74fjIYx6XvhM/lOrjntCAcAAAAAAAJIoLZqDSyhXp/MTHMuv8c1IaGZlwfvB5L0z/scen/sAHNSAdAAAAAMDMprhgxir//YbMPum4tH/3OxPOFm1tGTjkTVn7tmNSzOtpQDoAAAAAgJlJccGM13rlL9J13HvS+vvfTThb7+nJ2mPenYHXvD5pbW1AOgAAAACAmUVxAUlSr6f9W19P1wdPSOWWf044Xt1p5/S//6QMP/tAB3gDAAAAAEwixQXc3cBAZp1zVjr/6+SU+yb+szn8pL3Sf+KHUt19zwaEAwAAAADY+ikuYBSlZcvS9fEPp+Nzn06pVht3tiiXs/bt78rao9+ZVCoNSggAAAAAsHVSXMA4Ktf/JV0nvi/tP/zBhLPDe+2dNWedm/qixQ1IBgAAAACwddqU4qLcgBzQlGoP3SWrv/DV9H79O6k+/JHjzrb9/PL07PfktP7kkgalAwAAAACYmRQXzHgj++yblT+6LKtPPSu1cVZUlJcvz7yX/lu6TnhfMjLSwIQAAAAAADOHraLg7vr703nGKen8r4+nVK2OOTbymMdl9dnnp37/BzQwHAAAAADAls1WUbC5urqy9p3vSe93fpDajvcfc6z1t79Oz9P3TttF32lgOAAAAACArZ/iAkZRfezjs/LHl2fowOeNOVNe1Zu5r3tlZr/77cngYAPTAQAAAABsvRQXMIZiXk9Wn//5rPnIySna2sacm3X+OZn3nGekcsNfG5gOAAAAAGDrpLiA8ZRKGXzdG7Ly+z9JdecHjznW+ser0/P0fdL+tS83MBwAAAAAwNZHcQGboPbIR6X3kp9l8MUvGXOmtLY/c97yxsw+6s1Jf38D0wEAAAAAbD0UF7CJitndWXPGf2f1qWel6Owcc27WBV9Iz7P2TeXaPzUwHQAAAADA1kFxAZujVMrQS1+RlT/8Waq7PnzMsZbr/5KeA/ZLx2fPT4qigQEBAAAAALZsigu4F2oP3SUrf/CTDLz6kDFnSoOD6X7HW9P9xtemtHpVA9MBAAAAAGy5FBdwb82alb7//GRWnfvZ1LvnjDnW8e1vpufpe6fl979tYDgAAAAAgC2T4gLuo+HnvTArf3x5RvbYc8yZyk3/yLznPjOzPnW6raMAAAAAAMahuIBJUH/gg9J70SVZe+jhY86URkYy+/3vyZxXvSSlFcsbmA4AAAAAYMuhuIDJ0taW/hM/lFVf+ErqPT1jjrX/8AfpedpT0nrlLxoYDgAAAABgy6C4gEk2/MxnZ+Wlv8jwE5885kzltlsz9wXPSecnPpbUag1MBwAAAADQ3BQXMAXq222fVd+8KP1HvyNFqTTqTKleT9dHPpC5B70wpaVLG5wQAAAAAKA5KS5gqrS0ZO2735dVX/t26gu2HXOs7fKfZv5+T07rT3/SwHAAAAAAAM1JcQFTbGSffbPi0l9k+Kn7jTlTvnNZ5r7khen64AlJtdrAdAAAAAAAzUVxAQ1QbLttVn3lW+k79vgUlcqoM6WiSOcpJ2fe85+d8i3/bHBCAAAAAIDmoLiARimXM3Dk0em98Pupbb/DmGOtv/7f9Dxtr7R9/7sNDAcAAAAA0BwUF9Bg1Sc8MSt/ckWGDnjOmDPl3t7MffXL0vW+dycjIw1MBwAAAAAwvRQXMA2KnvlZ/dkL0vfBj6ZoaxtzrvPsMzPvhQemvHRJA9MBAAAAAEwfxQVMl1IpA284LL3fvSTVB+005ljrr67MvKfvndYrf9HAcAAAAAAA00NxAdOsuvue6f3RZRl80YvHnKncsTRzX3hgZp19RlIUDUwHAAAAANBYigtoAkX3nKw567ys+eTpKTo6Rp0p1WqZ/b7/SPebXpv09TU4IQAAAABAYyguoFmUShl8xcFZ+d0fpfaAB4451nHhN9Pz7Kel8re/Ni4bAAAAAECDKC6gydQe+aisvORnGdr/WWPOtPzlz5n3zH3T9t3/aWAyAAAAAICpp7iAJlTM68nqz38l/e96b4pSadSZct+azH3tK9J10nFJtdrghAAAAAAAU6NUFFN30u+yZWum6tYwY7T+5JLMOfSQlHt7x5wZ3vupWf2p81MsWNDAZAAAAAAAm2fBgu4JZ6y4gCY38rT9s/KSyzLyqD3GnGm7/Gfp2X+ftPz21w1MBgAAAAAw+RQXsAWoP+CB6b3ohxl4+avGnKncdmvmPe+AdHzmvGTqFlIBAAAAAEwpxQVsKTo60vdfZ2TNyaemaGsbdaQ0MpLud74t3Uccmqxd2+CAAAAAAAD3neICtjCDr3pNev/n4tS232HMmY6vXpCeA/dP+R83NjAZAAAAAMB9p7iALVB1z8dk5Y8uz/BT9xtzpuVP16Rn/6em7UcXNzAZAAAAAMB9o7iALVSxzTZZ9eVvpv+tx4w5U17Vm7kv//d0fvSDSa3WwHQAAAAAAPdOqSim7hTfZcvWTNWtgbtp+/530334m1Jes3rMmeGnPSOrzzo3Rc/8BiYDAAAAAPiXBQu6J5yx4gK2AsPPPjC9l/w01V13G3Om7Sc/Ss/+T03LNX9oYDIAAAAAgM2juICtRG2nB2fl936cwRf9+5gzlZtvyrwD90/7BV9oYDIAAAAAgE2nuICtSVdX1px1btZ86GMpWlpGHSkNDmbOUW/O7LcflQwNNTggAAAAAMD4nHEBW6mW/70yc15/cCpLl4w5M7Lno7P6vM+nvsOODUwGAAAAAMxUzriAGaz6hCdm5Y8uz/CT9hpzpvX3v0vP/vuk9WeXNjAZAAAAAMDYFBewFSsWLsyqr38naw89fMyZ8vLlmfuSF2bWKScn9XoD0wEAAAAAbMxWUTBDtH/7m+k+6i0pre0fc2bogAOz5vRPpZgzt4HJAAAAAICZwlZRwAZDz39RVl58aaoPfsiYM+0/+G7mPXPfVK67toHJAAAAAAD+RXEBM0htl4el9+JLM3Tg88acafn7Del59tPS/s2vNTAZAAAAAMA6iguYYYruOVl9/ufT9/6TUpRH/yugtHZt5hx6SLre+85kZKTBCQEAAACAmcwZFzCDtV5xWea88TUp33nnmDMjT3hSVp/72dQXLmpgMgAAAABga+SMC2BcI0/ZJyt/dHlGHvO4MWda//eXmff0vdNy5S8bmAwAAAAAmKkUFzDD1bfbPr0Xfi8Dr339mDOVO5Zm3osOzKxzzkqmbpEWAAAAAMDmFxfXXnttDj744Dz2sY/NXnvtlWOOOSYrVqyYimxAo7S3p++jn8jq089OMWvWqCOlajWz3/uudB/2+qS/v8EBAQAAAICZYrOKi2q1mje+8Y3ZY4898otf/CIXXXRRVqxYkeOPP36K4gGNNHTQy7LyoktSe8ADx5zp+ObX0vOcZ6T89xsaFwwAAAAAmDE2q7hYtmxZli1bluc///lpa2tLT09P9t9//1x33XVTlQ9osNojH5WVl/wsQ8945pgzLdf9KT3P3DdtF3+/gckAAAAAgJlgs4qLhQsXZtddd81XvvKV9Pf3Z/ny5fnhD3+Yfffdd4riAdOhmNeT1V/4avrf8R8pSqVRZ8qrV2Xuq16Szo+clNRqDU4IAAAAAGytSkWxeSft/vOf/8xrXvOa3HLLLUmSxz/+8TnnnHPS0dGx0eyyZWsmJyUwbdp+dHG6D3tDyqt6x5wZ3u/pWX3WuSnmb9PAZAAAAADAlmbBgu4JZzZrxcXw8HAOPfTQHHDAAfnNb36Tyy67LN3d3TnmmGPudUiguQ0/41lZecnPUn34I8ecabv0x+l55r5pufqqBiYDAAAAALZGm1Vc/PKXv8wtt9ySo48+Ot3d3Vm4cGGOPPLIXHLJJentHfv/xga2bPUHPigrv3tJBv/9pWPOVG6+KfMO3D/tF3yhgckAAAAAgK3NZhUXtVot9Xo9d99danh4eNJDAU2oszNrTj87az5ycorW1lFHSkNDmXPUmzP7mLcmQ0MNDggAAAAAbA02q7jYc88909nZmdNOOy0DAwNZuXJlzjrrrDzucY/LvHnzpioj0CxKpQy+7g3pvfB7qS1aPObYrM+dn3nPPyDlW29pYDgAAAAAYGuwWcVFT09PzjvvvPzud7/LPvvsk+c+97np6OjIySefPFX5gCZUfdwTsvJHl2f4yU8Zc6b1d79Nz/77pPXynzUwGQAAAACwpSsVd9/3aZItW7Zmqm4NNIORkXSddFw6P3X6mCNFuZz+Y0/IwFuOTEqlBoYDAAAAAJrNggXdE84oLoD7rP3b30z3UW9JaW3/mDNDBz4va049M0X3nAYmAwAAAACayaYUF5u1VRTAaIae/6Ks/MFPUt35wWPOtH/3O5l3wNNSuf4vDUwGAAAAAGxpFBfApKg9bNf0Xnxphp793DFnWv56feY9a7+0/c+FDUwGAAAAAGxJFBfApCnmzM3qz3wxfceekKI8+l8v5f6+zD3k4HSd8L6kWm1wQgAAAACg2TnjApgSrT+7NHPe9NqUV6wYc2b4Kftk9dmfTrFgQQOTAQAAAADTxRkXwLQZeep+WfmjyzOyx55jzrRdcVl69t8nLb/9dQOTAQAAAADNTHEBTJn6Djum9zsXZ+BVrxlzpnLbrZn3vAPS8ZnzkqlbAAYAAAAAbCEUF8DU6uhI38mnZs0nT0/R3j7qSGlkJN3vfFu6jzwsGRhocEAAAAAAoJkoLoCGGHzFwen9n4tT22HHMWc6vvKlzHvuM1O+6R+NCwYAAAAANBWHcwMNVVq+PHMOfV3afnbpmDP1efPS/673pvagnVJftF3qixal6JmflEoNTAoAAAAATLZNOZxbcQE0Xq2Wzo9+MF3/9fFNfknR0ZH6wkWpL1qc2uLF6wuNxakvXrzu2qJ1j5k1awqDAwAAAAD3heICaGpt37so3UccmvKa1ZN2z/q8eakv3i71hYtSW7zdumJj4eJ11xYtWvd4vwVJpTJpv3Ms5X/enFnnfCoDh74l9e22n/LfBwAAAADNTnEBNL3KDX/NnNe+Mi1/vq5hv7OoVFLfduH61RrrCo3a+rKjvni7DSVH0T3nPm1PVf7HjZn3/56VUn9/+o89PoOvOSQpO1oIAAAAgJlLcQFsGfr60n304em48JvTneQeis6u9dtSrf9av4KjdvefFy5KWlvHvEdpVW+6Tjo+sz53fkYe94Ss+cRpqe3ysAb+UwAAAABA81BcAFuOokjH5z+TWWeckpYb/z7daTZZUSql2OZ+/9qWatF2/zp3424/t1x3bWYfc2uE/F8AACAASURBVFQqN/0ja496e9Ye9fakvX264wMAAABAQykugC1PvZ7yHUtTvv22lJcsWf94eypLbl/3/dIlKd9+e8qreqc76WYpOjpS33bbpFZP+bZbU8ybl8EXHZTqE56Y2l1lx8JFSUfHdEcFAAAAgCmjuAC2XmvX/qvQWHL7ujJjybqyo3JX6bHktpSGh6c76Wapz5+f2+73yJw98ro84nW/ywMeP5x5939QFixYkEplYer1bVOvL0hRzEty78/fAAAAAIDpoLgAZraiSGnFivUFx91WcNx+e8pL15UdlSW3p3TnspSm7q/CzXJzdsweuSorMz+XXbZ39t77ilHn6vW29QXGtuvLjG3Xf78g9frCDdfWzfREyQEAAABAM9iU4qKlATkApkeplGKbbVLbZpvUHv6IsedGRtZtQbXkrjLjnttUbVjR0d835ZFPz+FZmflJkoULl445Vy4Pp1y+NcmtE96zKFpTr2+bkZF9smbN2ZMVFQAAAACmhOICoLU19R12TH2HHccdK61ZvX5Lqtv/dfbG3balKt9+e8p3LE2pVrvXUQYya8P34xUXm6NUGkmlcmuq1ZUTzra3fzldXcdvWKlRFPNSr89LUfSsf5yXen3d9Xt+PydWdQAAAAAwGRQXAJuo6J6TWvec1B66y9hDtVrKdy7715ZUS9advVG55ZZUrv1jKjf9I6W+vjE/4j8oX80ZeUva2oczd+7qSc1/5ZWL87vftWb33Wt52MPqaW3deKZcvi2VyrqvzVEU5XuUHHf/vr//hBTFxEsAAQAAACBRXABMrkol9YWLUl+4KNkjqVxzdTq+8sW0/eSSlJcvz8gee2bwJa/I0LOenfLw0D3P3VhyWx63ZEku+NN7c27tmRkcbE9Hx9CkRbviisU59tiOJEl7e5Hddqtn991r2X33dY+77FJPV9cd9+repVI9pdKKlMsrNnqur+8DE7x2TebP33P96o35qdcXplZbmHp90fqvf31fFPOTlO9VRgAAAAC2DIoLgCnQcvVV6T7qLWn50zWp329BBg96eQZf8vLUdnv4hplaktpOD97otU9b/3XLLXfk2mv7c+ONd2bp0mXp7V2WcnlZFi5cmkWLlmThwqX3+Jo1a3DcTEuWLNrw/dBQKb//fSW//31lw7X29iIXXrgiBxxwX//p/6Uo2pK7bX81mlJpZcrlO1IuT1ya3HVex93LjNG/3zbe4gAAAAC2TD7VAZgCpTVrUt11t/S/+9gMP+0ZGXVfpgnMnVvKk540O0960uwkD0yS9PYmV19dyVVXVXLRReVcdVUlN99cTlJkzpzVG5UZdy84rr12t3F/39BQKa2t927FxVjq9Z5MdPZFqdS7yfe767yOSmX8Q8n7+9+ftWuPmeBeK1MUnUnaN/n3AwAAADD1FBcAU2Bkr70zstfek37fefOSffapZZ99/nUA+MqVyR/+UMnVV3fkD394UP7whwfniivu3XZKP/3pvlmzpjvbbLM88+evSE/Pysyfv+Jeb1lVFPMmnCmXJz40fHPVaosmnOnuPjTt7d9PvT4v9fri1Go7pl6/f2q1+294rNXun6JYEAePAwAAADROqSiKYqpuvmzZmqm6NQDjWLHirjKjkquuKufqqyv55z/v/dkQHR0D6elZmb33XpbXvGZZnvSkO1Mu96ZcXrl+q6feezyWSr0pl3tTrT4sq1Z9f9x7t7V9O3PnvupeZxtNb+83MjKy/7gz8+Y9Na2tv5/wXkUx6x6lxr+KjR1Trz9g/bZUzt0AAAAA2BQLFnRPOKO4AJghli8v5Q9/KN+jzLjllnv3gftDH1rL4YcP59/+rTrBLlhFJlqt0NLyy8ya9amUyytTLt+Zcvn2lMvL71Wuu6xY8fPUao8cd2b+/IelUrntPv2eJCmK9tRqO2RkZJ/09Z1yn+8HAAAAsDVTXAAwrjvvLOXqq8v5wx/+VWbceuumlxnbb1/Pm988nJe/fCRdXZOZbHj9gd1LUi4vXf949+/verwjpVJto1ffeecN67d4Gks997vf/VIqVSct8dDQs7J69dfGnWlp+U3a2n68YbXGutUb28eKDQAAAGCmUFwAsNluvbWUc89ty2c+05r+/k0722H+/Hpe//qRHHLIcHp6pjjgPdRSKt2ZSuWexca6g7nHLgNKpWW53/12ntQkAwNvSF/fyePOzJr1ycyefdw9rhVFR2q1B6VW23mjr3p9cZyvAQAAAGxNFBcA3Gu9vcmnP92Wc85pzZ13btqKgM7OIgcfPJLDDhvO4sVT9vZyn5VKveno+PSGoqNSuTXl8s0pl5ekVLp3ufv6TsrAwFHjzsye/bbMmnXeJt+zKDpTq+20UaFRre6cotg2Sg0AAABgS6O4AOA+W7s2ueCC1px5ZtsmH/Dd2lrkoINGcvjhw9l55+YtMDY2lHL5llQqN6dS+WfK5ZtSqdyccvmf6x9vS6lUH/WVq1Z9NsPDLxz37nPm/Fva2y+ZlKT1endqtZ3S2/vjJG2Tck8AAACAqaa4AGDSjIwkF17YktNOa8uf/1zZpNeUSkWe+9xqjjxyOLvvPvoH/luWkZTLt64vMW5eX3Cs+76v76MTHgje0/O4tLT8ZdLS1OvbZvnyv407UyqtTFvbDzes1iiKhu7lBQAAAHAPigsAJl29nlxySSWnnNKe3/xm0wqMJNlnn2qOOmo4T3lKLaUZucNRkW22eUDK5d5Ju+PIyJPS23vxuDOtrT/LvHn/b8PP9fr81GoPTrW6S2q1XVKrPTTV6i6p1x8Qh4QDAAAAU01xAcCUKYrkyisrOfXUtvz4xy2b/LpHP7qWI44YzrOfXU15xn1OXku5fPv6raf+kUrlxlQqN6z/+vtmlxoDA69MX9+Z4850dJyf7u63TnivouhItfrQ1GoPTa22y92KjZ1jKyoAAABgsiguAGiIP/6xnNNOa8u3v92Sen3TllM85CHrCowXvaiaNp+LJylSKq1IpfK3u5UZ6wqNSuWGlMsbv6f29R2XgYG3j3vXrq73prPztHufqqisPyB8l/WFxkMzPPycFMXce31PAAAAYOZSXADQUDfeWMqZZ7bly19uzdDQphUY221Xz2GHDeeVrxxJV9cUB9xiFSmVlm0oM1pa1j0ODLw2IyP7jfvKOXNemvb2701qmuXLr0u9vv2k3hMAAACYGRQXAEyLpUtL+e//bs2nP92Wvr5NKzB6eoq8/vXDOeSQ4cyfP8UBZ5DJPxC8O8uX35Jk7H+vpdLqzJnz0nucoVGr7ZJ6fbtxXwcAAABs/RQXAEyrVauSz3ymLWef3Zo779y0Ay06O4u86lUjOfTQ4Wy//ZS9Rc0Y5fKt67efumsLqr+lUrk+lco/UirVN/t+IyOPTm/vT8edaWn5dXp6nr7R9Xp9bmq1XVOt7pZqddfUag9PtbprimKbzc4BAAAAbJkUFwA0hYGB5IILWnPmmW25+eZNKzBaW4u8+MXVHH74cB7ykM3/gJ2JDK7fdurPqVT+kkrl+rS0/CWVyl9TKg2P/arBl2XNmrPHvXN7+xczZ85hm5ykVluYWm23VKu7bXisVh+WxN5hAAAAsLVRXADQVKrV5MILW3LaaW257rrKJr2mVCry7GdXc+SRw3n0oxUYU6+aSuUf61dl/GV9mfHnVCrXp1zuS1/f8RkYOHrcO3R1vT+dnf91n1IURSn1+gNSra5blTE4eIhzNQAAAGAroLgAoCkVRfKjH1Vyyilt+dWvWjb5dU95SjVHHDGcffetpeSohAYrUi7flqJoT1Hcb9zJOXNekvb270/qb1+x4rep1R4yqfcEAAAAGk9xAUDTu/LKSk47rS2XXLLpBcajHlXLkUcO58ADq6ls2sINGmj27CPS1vaTVCr/nJT7FUVH7rzz9iTj/csezrx5z1l/EPiu61dq7Jai2DYOBAcAAIDmobgAYIvxpz+Vc/rpbbnwwpbUapv2QfODHlTP4YcP56CDRtLePsUBuRf60tLy1/VbTv05lcq1aWm5LpXKTZt1l5GRPdLbe9m4M5XKnzJ//pM2ul6vb5Nq9RHri4xHplZ7RKrVXZJ0bFYGAAAAYHIoLgDY4tx0UylnntmWCy5ozeDgphUYCxfW86Y3DefVrx5J98TvfUyzUml1KpU/ry8xrk1Ly7qvcnnZqPObdiD41zJnziGb9PuLopJa7aHrC411X7XaI1OvL4zVGQAAADC1FBcAbLHuuKOUc89tzfnnt2X16k37MHnOnCKve91w3vCGkSxYMGVvb0yRUmnZhhKjUrkuLS1/SqVyXdaufVcGBo4a97VdXSeks/Pk+/T7163OeOT61RmPyPDwASmKbe7TPQEAAIB7UlwAsMVbsyb57Gdb86lPteWOO8qb9JqOjiIvf/lIDjtsOA94gAJjy1YkGU4y/l5gU3Mg+M9Tqz1yUu8JAAAAM53iAoCtxuBg8rWvteb009ty442bVmBUKkVe8IJqjjhiOLvtVp/ihEyn2bPfltbWS1Op3JhS6b7/p01RtKw/EHy8wqSWrq7jU63uuv78jF2StN3n3w0AAABbM8UFAFudWi256KKWnHpqW665prLJr9t//3UFxhOfWJvCdEy//rS0/GXDVlPrvq5JuXznZt2lWn14Vq785bgzlcrfMn/+ozf8XBQtqdV2ycjI49PXd8q9Sg8AAABbO8UFAFutokh++tNKTjutLVdc0bLJr3v846s58sjh7L9/LSXnMM8QRUqlO9LScs2GIqOl5Y+pVK5PqVQd9RWDgy/JmjXnjHvXtrYLM3fuwRtdHxl5THp7L52U5AAAALC12ZTiYtM/6QGAJlIqJfvtV8t++w3kt78t57TT2vK977VO+Lpf/aolr3xlSw4+eDgf+chQWrwTzgClFMXCjIwszMjIM+52fSiVyl/S0vLHu31dk3J5earVR0x415aWa0a9Xq06FwMAAADuCx/XALDFe8xj6vnMZwZz/fXDOeOMtnztay2pVsdfTvG5z7XlgQ+s5/DDRxqUkubTnlrtUanVHpWhobuuFSmXl6YoJi7BWlr+NOr1avXhkxcRAAAAZqBNO90UALYAD31oPaecMphf/7o/b3rTcDo7x98N8WMfa8+NN9ovirsrpV5flKLYZsLJcvm2Ua/XalZcAAAAwH3hjAsAtlorViTnndeWc89ty8qVoxcUe+9dzde/PuC8C+6FIuXykrS0XJNK5V9nZ/T2XpKimDvd4QAAAKApOZwbAJL09yef/Wxrjj++Y9TnTz11IC996eiHNAMAAAAweTaluLBVFABbva6u5M1vHslrXzs86vPvf39H7rjDkgsAAACAZqC4AGDGOPbYoSxeXN/oem9vKe97X/s0JAIAAADg/1JcADBjdHcnH/3o4KjPfetbrfnhDysNTgQAAADA/6W4AGBGOeCAWp73vJFRn3vnOzvS19fgQAAAAADcg+ICgBnngx8cyty5xUbXb7utnA99yJZRAAAAANNJcQHAjLNwYZETThh9y6jzzmvNr3/t7REAAABguvhkBoAZ6WUvq+YpT6ludL0oSnn72zsyPDwNoQAAAABQXAAwM5VKycc/PpiOjo23jPrznys57bS2aUgFAAAAgOICgBlrp52KHHPM6EsrPvnJtlx/vbdJAAAAgEbziQwAM9phhw3n4Q+vbXR9eLiUo49uT70+DaEAAAAAZjDFBQAzWmtr8slPDqZc3njLqF/9qiWf+1zrNKQCAAAAmLkUFwDMeHvsUc+b3jQy6nMnntie228vNTgRAAAAwMyluACAJO9851Duf/+N94Xq6yvlXe9qT7HxggwAAAAApoDiAgCSdHUl//mfg6M+94MftOaii1oanAgAAABgZlJcAMB6++1Xy0EHjb5l1H/8R3t6exscCAAAAGAGUlwAwN2ceOJg7ne/jbeMuuOOck48sX0aEgEAAADMLIoLALib+fOTk04aGvW5L3yhLT//eaXBiQAAAABmFsUFAPwfL3pRNU9/enXU597+9o4MDDQ4EAAAAMAMorgAgP+jVEo+9rHBdHYWGz3397+X84lPtE1DKgAAAICZQXEBAKPYccci73nP6FtGnX56W/74R2+hAAAAAFPBpy4AMIZDDhnJox9d2+h6rVbK0Ud3pLbxUwAAAADcR4oLABhDpZJ84hODaWnZeMuoq66q5JxzWqchFQAAAMDWTXEBAOPYbbd6jjhieNTnPvKR9tx0U6nBiQAAAAC2booLAJjA2942nJ13rm90fe3aUj70ofZpSAQAAACw9VJcAMAEOjrWbRk1mm9/uyU33GDVBQAAAMBkUVwAwCZ40pNqedWrNt4yql4v5dRTrboAAAAAmCyloig2PnF0kixbtmaqbg0ADbdkSSmPfWxXhofvucKipaXI//5vf3bc8f+zd99xdtVlHvifc9ukT0ISAglFirRUEIyCFFmXVQREwsKKLlhAQRGw/Cy7rutvi8vPgogL6LIqq+KC0pQivSu9pNGRmgAbAqmTmbnl/P6YMRDuDWkz986d+36/XnkNfM+Zc55oJjOcz3m+T799SwUAAAAYFMaPH7nOc3RcAMB62mKLND7ykWLVeqmUxNlnFxpQEQAAAMDgI7gAgA1w8sndkc1Wd1ZccEE+Xn7ZrAsAAACATSW4AIANsO22aRx5ZKlqvasriXPP1XUBAAAAsKkEFwCwgU49tSuSpLrr4vzz8/Hqqw0oCAAAAGAQEVwAwAbaccc0Dj20uuuioyOJ//ovXRcAAAAAm0JwAQAb4bTTumuu//SnhVi+vM7FAAAAAAwiggsA2AhTplTioIOquy6WLk3i5z/XdQEAAACwsQQXALCRTjutq+b6j3+cj46OOhcDAAAAMEgILgBgI+25ZyX23be66+KVVzLxq1/lG1ARAAAAQPMTXADAJvjCF2rPujj77EJ01W7IAAAAAOAtCC4AYBPss0859tyzXLX+4ouZuOgiXRcAAAAAG0pwAQCbIEkivvjF2q0VP/pRIUrVO0kBAAAA8BYEFwCwif7qr8oxdWp118Wzz2bisstyDagIAAAAoHkJLgBgEyVJxGmn1Z518cMfFqJSqXNBAAAAAE1McAEAfeCDHyzFTjtVd108/ng2rrpK1wUAAADA+hJcAEAfyGQiTjmldtfFmWcWIk3rXBAAAABAkxJcAEAfOeKIUmyzTfW+UHPnZuOmm7INqAgAAACg+QguAKCP5HJr77o444w2XRcAAAAA60FwAQB96Oiji7HlltVdF/fem40//UnXBQAAAMC6CC4AoA+1tUV89rO1uy5+8INCnasBAAAAaD6CCwDoYx/7WDHGjavuurjttlzcf79vvQAAAABvxdMTAOhjw4dHfOYzxZrHzjyzrc7VAAAAADQXwQUA9INPfKI7Ro2qnsZ97bW5mDfPt18AAACAtfHkBAD6wahREccfX3vWxQ9/aNYFAAAAwNoILgCgn3z6090xbFh118Xvf5+LJ59MGlARAAAAwMAnuACAfrLZZhHHHVc96yJNkzjrLLMuAAAAAGoRXABAP/rsZ7ujra266+K3v83Fc8/pugAAAAB4M8EFAPSjCRPSOOaY6q6LcjmJ//xPsy4AAAAA3kxwAQD97OSTuyOXq+66+N//zcdLL+m6AAAAAHgjwQUA9LOtt07jb/+2VLXe1ZXEOefougAAAAB4I8EFANTBKad0RSZT3XXxi1/kY/FiXRcAAAAAfyG4AIA62GGHNA47rLrroqMjifPOyzegIgAAAICBSXABAHVy6qndNdf/+78LsWxZnYsBAAAAGKAEFwBQJ5MnV+L97y9WrS9blsTPfmbWBQAAAECE4AIA6uq002p3XfzkJ/lYubLOxQAAAAAMQIILAKijPfaoxP77V8+6WLw4E7/8pVkXAAAAAIILAKizL3yhdtfFOecUoqurzsUAAAAADDCCCwCos3e/uxzvfGd118VLL2Xiwgt1XQAAAACtTXABAHWWJBFf/GLtrosf/agQxer53QAAAAAtQ3ABAA3w3veWY/r0ctX6c89l4tJLcw2oCAAAAGBgEFwAQAMkScSpp9buujjrrEKUqzMNAAAAgJYguACABjn44FLsvHN1QvHEE9m46ipdFwAAAEBrElwAQINkMmvvuvjBDwqRpnUuCAAAAGAAEFwAQAMdfngptt22UrU+f342brgh24CKAAAAABpLcAEADZTLrb3r4owz2nRdAAAAAC1HcAEADXbUUcWYOLG66+L++7Nxxx26LgAAAIDWIrgAgAYrFCI+97naXRdnnlmoczUAAAAAjSW4AIAB4KMfLca4cdVdF7ffnot77/XtGgAAAGgdnoQAwAAwbFjEiScWax4788y2OlcDAAAA0DiCCwAYID7xie5ob6+exn399bmYO9e3bAAAAKA1eAoCAAPEyJERxx9fe9bFD39o1gUAAADQGgQXADCAnHBCdwwfXt11ccUVuXj8cd+2AQAAgMHPExAAGEA22yzi4x+vnnWRpkmcdZauCwAAAGDwE1wAwABz4ond0dZW3XVxySW5ePbZpAEVAQAAANSP4AIABpgJE9L42Mequy7K5SR+9CNdFwAAAMDgJrgAgAHoc5/rjlyuuuviwgvz8eKLui4AAACAwUtwAQAD0FZbpXHUUdVdF93dSZxzjq4LAAAAYPASXADAAHXKKd2RyVR3Xfzyl/lYsaIBBQEAAADUgeACAAao7bdP4/DDS1XrHR1JXH11rgEVAQAAAPQ/wQUADGCf+1x3zfVLL83XuRIAAACA+hBcAMAANnVqJXbdtVy1fuut2Vi0yJBuAAAAYPARXADAADdrVvV2UeVyEr//ve2iAAAAgMFHcAEAA9yHP1ysuX7xxbaLAgAAAAYfwQUADHBbb53GzJnVXRf335+Np5+2XRQAAAAwuAguAKAJ1NouKiLisst0XQAAAACDi+ACAJrAoYeWIpdLq9YvuSQXafUyAAAAQNMSXABAExg7No0DDyxXrT/xRDbmzfPtHAAAABg8POkAgCYxa5Yh3QAAAMDgJ7gAgCZx0EGlGDasel+oyy7LRbm6GQMAAACgKQkuAKBJDB8ecfDB1UO6X3opE3femW1ARQAAAAB9T3ABAE1kbdtFXXJJrs6VAAAAAPQPwQUANJH99ivHuHGVqvUrrshHV1cDCgIAAADoY4ILAGgi+XzEYYdVbxe1bFkSN9yg6wIAAABofoILAGgya9su6tJLBRcAAABA8xNcAECT2XPPSmyzTfV2Udddl4tlyxpQEAAAAEAfElwAQJNJktpdF11dSVx1la4LAAAAoLkJLgCgCR1xRPWci4iISy7J17kSAAAAgL4luACAJrTzzpWYMqVctX7HHdl4+eWkARUBAAAA9A3BBQA0qVrbRVUqSVx+ue2iAAAAgOYluACAJvXhD5ciSdKqddtFAQAAAM1McAEATWrixDT23rt6u6iHHsrGU0/ZLgoAAABoToILAGhihnQDAAAAg43gAgCa2KGHFiOfr71dVFq9DAAAADDgCS4AoImNHh3xV39V3XXx9NOZeOgh3+YBAACA5uOJBgA0uSOPtF0UAAAAMHgILgCgyf31X5dixIjqfaEuuywX5erZ3QAAAAADmuACAJrc0KERH/xgddfFokWZuP32bAMqAgAAANh4ggsAGASOOKJYc912UQAAAECzEVwAwCCw777lGD++UrV+1VW5WLWqAQUBAAAAbCTBBQAMArlcxOGHV28XtWJFEtdfn2tARQAAAAAbR3ABAIPErFlr2y5KcAEAAAA0D8EFAAwSu+9eie22q94u6sYbc7FkSQMKAgAAANgIggsAGCSSpPaQ7u7uJK680pBuAAAAoDkILgBgELFdFAAAANDsBBcAMIjsuGMa06eXq9b/9KdsLFyYNKAiAAAAgA0juACAQaZW10WaJnHZZbouAAAAgIFPcAEAg8zhh5ciSdKq9ZtvFlwAAAAAA5/gAgAGmS22SGPmzOrtoubNy0RanWcAAAAADCiCCwAYhHbfvVK19uqrGXMuAAAAgAFPcAEAg9DUqdUdFxERc+Zk61wJAAAAwIYRXADAIDRtWnXHRUTE3Lm+9QMAAAADm6cXADAI7bBDJYYNqx5oMXeujgsAAABgYMttyMn33ntvfPKTn1xjLU3TKBaL8dhjj/VpYQDAxstmI3bbrRL33bdmUDFnjncWAAAAgIFtg4KLvfbaK+bOnbvG2o9//ON49NFH+7QoAGDTTZ1argouXnwxE4sWJTF+fHU3BgAAAMBAsEmvXS5cuDB+/vOfx1e+8pW+qgcA6CPmXAAAAADNaJOeXPzwhz+MWbNmxcSJE/uqHgCgj0ydWq65Pm+eORcAAADAwLVBW0W90QsvvBDXXXddXHfddX1ZDwDQR3beuRL5fBrFYrLGujkXAAAAwEC20U8uLrjggjjooINi/PjxfVkPANBH2toidtmleruouXN1XAAAAAAD10YHF9dee20ceOCBfVkLANDHam0X9fTTmVi2rAHFAAAAAKyHjQouHnnkkViwYEHss88+fV0PANCHpk6tPaB7/nxdFwAAAMDAtFHBxcMPPxyjR4+OESNG9HU9AEAfWtuAbnMuAAAAgIFqo55avPLKK2ZbAEATmDy5EkmSVq2bcwEAAAAMVEmaptVPM/rIokXL++vSAMB62mefYfHEE2sGFbvuWo5bb+1oUEUAAABAqxo/fuQ6z7FPBAAMcrXmXDz+eCZWrWpAMQAAAADrILgAgEGu1pyLcjmJRx7xYwAAAAAw8HhiAQCD3LRp1R0XEeZcAAAAAAOT4AIABrkpU6o7LiIi5szxYwAAAAAw8HhiAQCD3JgxEdtsU911MW+ejgsAAABg4BFcAEALqNV18fDDmSgWG1AMAAAAwFsQXABAC6g156KrK4knnvCjAAAAADCweFoBAC1g6lRzLgAAAIDm4GkFALSAWh0XEeZcAAAAAAOP4AIAWsCECWmMH18dXui4AAAAAAYaTysAoEXU6rqYBO/UtAAAIABJREFUNy8bldrNGAAAAAANIbgAgBYxbVr1nIsVK5J45pmkAdUAAAAA1Ca4AIAWMWVK7daKuXPNuQAAAAAGDsEFALSIWh0XEeZcAAAAAAOLJxUA0CK22SaN9va0al3HBQAAADCQCC4AoEUkScTUqdVdF3PnZiKtzjMAAAAAGkJwAQAtpNaci8WLM/HiiwZ0AwAAAAOD4AIAWog5FwAAAMBA5ykFALSQqVOrOy4izLkAAAAABg7BBQC0kB13rMTQobUGdPuRAAAAABgYPKUAgBaSzUbstlt114WOCwAAAGCgEFwAQIupNediwYJMLF5sQDcAAADQeIILAGgxa59z4ccCAAAAoPE8oQCAFlOr4yIiYs4c20UBAAAAjSe4AIAWs/POlcjlqgd0z5vnxwIAAACg8TyhAIAW09YWscsu1dtF6bgAAAAABgLBBQC0oFrbRf35z5lYvrwBxQAAAAC8geACAFrQ2gZ0z5+v6wIAAABoLMEFALSgqVPXNqDbjwYAAABAY3k6AQAtaLfdKpEk1QO6587VcQEAAAA0luACAFrQiBERO+5Ya0C3Hw0AAACAxvJ0AgBaVK05F48/nonOzgYUAwAAANBLcAEALarWnItyOYlHHvHjAQAAANA4nkwAQIuq1XERYc4FAAAA0FiCCwBoUbU6LiLMuQAAAAAay5MJAGhRY8ZEbL11ddfFvHk6LgAAAIDGEVwAQAur1XXx8MOZKJUaUAwAAABACC4AoKXVmnPR2ZnEE0/4EQEAAABoDE8lAKCFTZtmzgUAAAAwsHgqAfSPNI3cA/fF0B9+P4Z959uReebpRlcE1FCr4yLCnAsAAACgcXKNLgAYZDo6YshlF8eQ838a+dkPrl4eds5Z8do1N0d5l10bWBzwZhMmpDF+fCUWLVrzXYaurgYVBAAAALQ8HRdAn8g++UQM/8ZXY+z0XWLkF05eI7SIiEg6OmLYWWc0qDpgbZIk4sgjqydx77FH7S2kAAAAAPqbjgtg4xWLUbjm6hh6/n9H4fZb13l65tXFdSgK2FCnndYVTz+dxDXX5COXS+O444px9NHVYQYAAABAPQgugA2WeXFhDPnl+THkl+dH9uWX1vvzOj98ZD9WBWysMWMi/ud/OmPZss5I04jRoxtdEQAAANDKBBfA+knTyN92Sww9/6dRuOaqSMrrv41MZVR7rPz6P0XXUR/pxwKBTZEkEe3tja4CAAAAQHABrIfcA/fFiH/8SuTvv2+DPq84dXp0fvKE6Dx8VsTw4f1UHQAAAAAwmAgugLVKXn45Rvz7t2LIhRes9+ekbW3RdfisWPXxT0Vpjz17XuMGAAAAAFhPggugWnd3DP2vc2PYGd+JzIrl6/Up5bdtF6uO+1R0fuSjkW42tp8LBAAAAAAGK8EFsIbCDdfG8G98LXJ/fmqd56aZTHQf9IFY9fFPRfGAAyMymTpUCAAAAAAMZoILICIisk89EcP/6evRdsN16zy3Mn7zWPX3x0Xnxz4ela22rkN1AAAAAECrEFxAq6tUYtj3To9hP/x+JMXiW56aDhsWHad+KTpO+nzEkCF1KhAAAAAAaCWCC2hllUqM+OLnY+ivf7nOUzuPODJWfvNfozJxUh0KAwAAAABaleACWlW5HCNP+1wMuejXb3lacer0WPHv34nSu95dp8IAAAAAgFYmuIBWVC7HyM+fGEMuvmitp1TGjo2V//DP0XnM30dks3UsDgAAAABoZYILaDWlUow8+dMx5NKLax5Os9lY9alPR8eXvxbp6DF1Lg4AAAAAaHWCC2glpVKM/OzxMeTyS2seTocMiaXn/zqKB76vzoUBAAAAAPQQXECrKBZj1Gc+GW1X/q7m4XTo0Fj6iwujuP9761wYAAAAAMDrBBfQCrq7Y9SnPxFtV19R83A6dGgs/dVvorjv/nUuDAAAAABgTYILGOy6umLUCcdF2zVX1zycDhseS3/92yju/Z46FwYAAAAAUE1wAYNZV1eM+uTHou36a2seTocNj6UXXhLFd+1d58IAAAAAAGoTXMBg1dkZoz7x0Wi78fqahysjRsbS/70kSjPfVefCAAAAAADWTnABg9GqVdH+8WOicPONNQ9XRo6KpRdeEqW9Zta5MAAAAACAtya4gMGmoyPaj/tIFG69uebhyqj2WPqby6K0x551LgwAAAAAYN0EF9DEhv/btyLNZKLjH77Zs9DREe1/f3QUbr+15vmV9tGx9LeXR2nGHvUrEgAAAABgA2QaXQCwkTo7Y8jP/zsin+/595Uro/2jf7v20GL06Fh6ye+FFgAAAADAgKbjAppU4ZabIrN8WXR96IiIFSui/Zgjo3DXn2qeW9lss1jy299Heeq0+hYJAAAAALCBBBfQpNouvyRKu06OysSJMfojsyJ/9501z6uMHRtLLr4iypOn1LlCAAAAAIANZ6soaEarVkXh2j9E1/sPjvajPrz20GLcuFhy6VVCCwAAAACgaei4gCZUuPH6yKxcEYXr/hD5+fNqnlMZNz6WXHpllHfZtc7VAQAAAABsPMEFNKEhl1wU6dChaw0typtPiKWXXhnlnXauc2UAAAAAAJtGcAFNJlnwQhT+cFUklUrN4+UJW/SEFm/fKaJUisj5MgcAAAAAmocZF9BEklcXx+gPfWDtocWWE2PZBRdFbvaDMerYj8S47baMIef/tM5VAgAAAABsPK9iQ5NIFi+O0UceFrnnnq15vDJ6dJS33zFGH/zXkXR3R/Ede8XKr38zuo48qs6VAgAAAABsPMEFNIFk8eIYPevQyD1ce6ZFGhGZJUsiKXbHym/+S3R98LCoTNqqvkUCAAAAAPQBwQUMcMkrr/SEFo/Mr3k8bWuLjlO+GJ0fOy4qW06sc3UAAAAAAH1LcAEDWLJoUbx62Emx/KmVsV2N4+VJW8WS318Tla23qXttAAAAAAD9wXBuGKAWP/9sfGnWfbHzU9fG9vF0fCguj87Irz5e3vZtseTK64QWAAAAAMCgIriAAWjx4pcjP+KI+OervhZbbfV8RET8Pj4UZ8SXIyKi/LbtYsnv/mCOBQAAAAAw6AguYIB55ZWF0dZ2cOyw0xOx/fZPx003HRgTJy6IiIgHY/cobb9DT2gxcVKDKwUAAAAA6HuCCxhAXnnl+Rg27ODYbrsnVq+9/e1Pxo03/lVMmPBS7Dzm5Vh62VWGcAMAAAAAg1aSpmnaXxdftGh5f10aBp1Fi56NUaMOia22erbm8et+9zex8xY/imHbb1HnygAAAAAA+sb48SPXeU6uDnUA6/DKK3+O9vZDY9Kk52sef+LxXWObnf4zho2bUOfKAAAAAADqS3ABDfdkjB17SGy++cKaRx97bGqk6e9i7Lhxda4LAAAAAKD+BBfQQEmyJDKZo2KzzWqHFg8/vHtks5fF2LGb1bkyAAAAAIDGEFxAw1Qinz8h2tufrHl03rw9o1C4NMaMGV3nugAAAAAAGifT6AKgVQ0b9u1ob7+25rEHHpgZbW1CCwAAAACg9QguoAEKhSti+PDv1Dx2zz17xfPPXx6jRwstAAAAAIDWI7iAOstmH40RIz5T89iLL24Rv/jFRbH33sPrXBUAAAAAwMAguIA6SpIlMWrURyKbXVF1rLs7Hyec8Js49dRxDagMAAAAAGBgEFxA3VRi5MhPRy73VM2jp5xyVsyatWfYIQoAAAAAaGWCC6iTYcO+G21t19Q8dt55x8cLL3wyDjmkVOeqAAAAAAAGliRN07S/Lr5o0fL+ujQ0lXz++mhvPzKSpPrL7a67ZsZhh90SN91UigkT+u3LEQAAAACg4caPH7nOc3RcQB1ksy9Fmuaq1l96aULMmnVJ/MM/hNACAAAAACAEF1AXS5b8fRx99M2xYMHE1WulUjaOOuo3scMOE+KYY4oNrA4AAAAAYOAQXEAdnHFGIS6+eJ/YY48H4pZb9o+IiC9/+Xtx3337xve/3xlJ0uACAQAAAAAGCDMuoJ/Nm5eJgw4aFqVSTzqRzZbi7/7uwrjggo/Gt77VFZ/9rG4LAAAAAKA1rM+MC8EF9KM0jTj88KFx553V8y1mzCjH1Vd3RK76EAAAAADAoGQ4NzTYrbdma4YWuVwaP/hBp9ACAAAAAOBNBBfQp15vYErTiNNPb6t51uc/3x2TJ1fqVRQAAAAAQNMQXECf6Yj29kOiULgyIiKuuy4bDzyQrTpr3LhKnHJKd72LAwAAAABoCoIL6BOVGDXqM1Eo3B6jRn00hgw5K04/vVDzzNNO647hw+tcHgAAAABAkxBcQB8YPvyb0db2u4iISJI0Ro78Rpx88smRyxXXOG/LLStx7LHFWpcAAAAAACAijAaGTTR06Pdj2LCzqtZPPPEnERFx0kk/Xr32xS92x5AhdSsNAAAAAKDpJGmapus+beMsWrS8vy4NA8KQIf8VI0d+ueaxxYs3i3e966548sm3R0TENttU4k9/WhmF2jtIAQAAAAAMeuPHj1znObaKgo3U1nbBWkOL7u58fPjDl60OLSIivvzlLqEFAAAAAMA6CC5gIxQKv4uRIz9X81ilksRxx/1P3H77fqvXdtyxHEceWapXeQAAAAAATUtwARson78hRo36ZCRJpebxE0/8cVx44UfWWPvKV7ojZ6IMAAAAAMA6CS5gA+Tzd0R7+0cjSYo1j3/pS9+L88779Bpru+5ajsMO020BAAAAALA+BBewnvL5m6O9fVYkyaqax7/3vX+KM874UtX6177WHRlfaQAAAAAA6yVJ0zTtr4svWrS8vy4NdVUo/CFGjTo2kqSr5vE//enzsc8+P4yIZI31GTPKce21HZEkNT8NAAAAAKCljB8/cp3neA8c1qFQ+H2MGvWxtYYWy5YdG4cccma8ObSIiPja17qEFgAAAAAAG0BwAW+hre03MWrUcWudadHZeWR8+9vnxmuvVX8pzZxZive+t9zfJQIAAAAADCqCC1iLIUN+GSNHnhBJUjt86Ow8Jp577rw455yhNY9//evdui0AAAAAADaQ4AJqyGafjBEjPh9JUnsEzKpVn4rly8+Jc84ZGsuXV6cT++1Xir331m0BAAAAALChBBdQQ7m8Y6xc+S81j3V0fDZWrDgjFi3KxnnnFWqe87Wv1Z6HAQAAAADAWxNcwFqsWvX56Og4aY21jo4vxcqV/xERSZx1ViE6Oqq7LQ46qBR77lmpU5UAAAAAAIOL4ALWKomVK/8jOjuPiIiIlSv/MVau/GZEJPHii0mcf36+5md99au6LQAAAAAANlau0QXAwJaJ5ct/HN3dh0RX15GrV3/wg0J0dVV3Wxx2WDGmTtVtAQAAAACwsZI0TWtPH+4DixYt769LQ8M8+2wSe+89PIrFNYOLTCaN227riJ12ElwAAAAAANQyfvzIdZ5jqyhaVj7/p8jl7trgzzvjjLaq0CIiYtasktACAAAAAGATCS5oSW1tF0R7+6HR3v6RyGSeWe/Pe+qpJC66qHqHtWw2jS9/2WwLAAAAAIBNJbigxZRj+PBvxqhRJ0WSFCOTWRzt7UdHkixbr8/+7nfbolKp7rY45phibLddv+26BgAAAADQMgQXtJAVMWrUR2PYsDPXWM3lHomRIz8ZEeW3/OyHH87EZZdVd1sUCml84QvdfVkoAAAAAEDLElzQEjKZ52PMmL+Jtrarax5va7su2tr+9y2v8Z3vFCJNq7stjj22GFttpdsCAAAAAKAvVL8+DoNMkiyOMWPeG5nM/631nI6OL0VX1zFrPT57diauvjpftT50aBqnnqrbAgAAAACgr+i4YNBL07HR2Vk7lEjTQixb9pNYufKf462+HE4/va3m+ic/WYwJE3RbAAAAAAD0FcEFLWHlym9FV9cH11irVMbFkiVXRlfXR97yc+++Oxs33ljdnDR8eBonn6zbAgAAAACgLwkuaBGZWLbsvCiVpkZERKm0a7z22s1RKr3rLT8rTSNOP71Q89hnPtMdY8fqtgAAAAAA6EuCC1rIiFi69MLo7Dwmliy5PiqVbdf5Gbffno0//rG626K9PY2TTtJtAQAAAADQ1wznpqVUKlvH8uU/Xq9z0zTiP/6j9myLz32uO9rb+7IyAAAAAAAidFzAWt1wQzbuvz9btT52bCWOP163BQBsrOyjj8ToQ/8msnPnNLoUAAAABiDBBdRQqUScfnrtbotTTumOESPqXBAADBL5m66P0Qe/L5Lly6MyaVKjywEAAGAAElxADVddlYu5c6u7LSZMqMTHP15sQEUA0PyG/PS/ov2Yv43iu/eOJVdeG+lmYxtdEgAAAAOQ4ALepFyO+O53CzWPfeEL3TF0aJ0LAoBmVyrFiK9/OUZ+/cux6oSTYtkvLox0xMhGVwUAAMAAZTg3vMnll+fi0Ueruy223roSH/2obgsA2BDJ8mUx8tOfiMItN8Xy7/wgOj/+qUaXBAAAwAAnuIA3KJUivvOd2rMtvvSlrmirfQgAqCHz3LPR/rGjIrNwYSz930uieMCBjS4JAACAJiC4gDf4zW9y8fTT1TuobbddJY46qtSAigBg4HvmmST+9Kvn46WbHottVj0ef7fPM5HdZ68Y8Y9fjXTY8Fhy9Q1R3mnnRpcJAABAkxBcQK+urojvfa92S8VXvtIVOV8tAFDlxz/Ox5zZV8YVVx4SXV27RkTEwqf+Jf7lF5+M0ow9YumvL4503LgGVwkAAHWSphHd3RGFQkSSNLoaaFoexUKvCy7IxwsvVHdb7LJLOQ4/XLcFALzZ888n8eijl8dvL/5I3Hnnu+K/PnBCnLz0P+Md8WCUIhvlbd8WybKlkY4d6z/aAAAYfNI0Mi88H7nZD0VuzkORn9PzMfPKK5EOGRLliZOiMmmrqEycFOVJk6IycauoTJoU5d6P6aj2Rv8OYMBK0jRN++viixYt769LQ59atSrine8cHi+/XB1c/Oxnq+KQQwQXAPBmd99djj333CW22OLliIhYesrIePTnu8SyFe3xjrg/xiRLIknTqIwbH8W9Zvb8eue7ojR9RhgcBQBAU0nTyDz7TE9A0RtU5ObOjsyrr270JSsjRkZl0qTeYGOrNT5WJm0V5YmTIoYN68PfBAwM48ePXOc5gguIiHPPzcc///OQqvWpU8txww0dXhIFgBo6O6+Lrbc+co21jo6hcfyx/x1n3Pj/RuHy8yP74sLI3Xt35O+5O/IP3BdJR0ekhUKUpu8exXe+qyfMeNe7I91sbIN+FwAA8CaVSmSf+XNvJ8XsnpBizuzILF1S/1LGjInKxK16Ozaqg43KlhO9FETTEVzAelixImKvvYbH4sXV3Ra//nVHvO995QZUBQAD35Ah58XIkV+qWn/21wfEyK3/vyjvsuuaB0qlyM2f2xtk3BX5e+6O7MIFUX7bdvHqPbPrVDUAALxBpRLZp57sCSdWd1LMiczyZY2ubL1Vxm++eiuqWltSVSZsEYa3MpAILmA9nHlmIb797epkes89y3HVVbotAGBthg371xg+/LtV66+88myk6Zj1ukZmwQuRrFoV5R3f3tflAQDAmsrlyD7xeG8HRc+WT9l5cyOzckWjK+tXaSYTlS22fFPHxuvBRnniVpGOHx+RqX6pF/rD+gQXojZa2tKlEWefXah57Otf7xJaAMBbyGSWVq2laSbSdPR6X6Myaau+LAkAAHqUSpF9/LHegOLBni2f5s+NpKOj325ZGTEySlOnRXnX3SJZsSIyCxdEZsELkV24IJKurn6777oklUpkFy6I7MIFkb/vnprnpPl8VLactHpLqtVbUa3+OCnSMZuFh2XUi+CClnbuuYVYurT6L9z3vKcU++5riygAeCtJsrJqLU1HRIT/mAEAoI6Kxcg++kjkezspcnMeitz8eZF0dvbbLSuj2qM0bXqUps3o+Th9RpS326F210KaRrJ4cWQXvhCZBQsis/CFyK7xcUFkXlwYSanUb/WuS1IsRva5ZyL73DNrPScdOrQnxFjdqdEbbLxhe6p05Kj6Fc2gJrigZS1enMRPflK72+KrX+2uczUA0HyS5LWqtZ7gokl1d0cUav9sAADAANHVFblHH37D4OwHI/fw/Ei6++9ZTmX06ChN2z1K03tCiuK0GVF523br332QJJGOGxelceMips2ofU65HJlF/xeZBS9EZuGCyC7oCTmyC3sCjsyCBZF5+aVI+m/X/3VKVq2K3FNPRjz15FrPqYwcFZWJE6P8tu2itNvkKE2ZFuXJU6L8tu1tRcUGEVzQss4+Ox8rV1Z/gznwwFLMnKnbAgDWJZt9pmqtUtmy/oX0gcL118SIL3w+Xn3w4Yh8vtHlAAAQEdHZGbmH5/UGFL3Dsx99OJJisd9uWRk7treLYkYUp82I0vQZUdl6m/7fIimb7ZlDscWWEe/Yq/Y5xWJkXnqxN9B4YY2PmYW9//zKK/1b5zpkli+LzGPLIvfYo9F27R9Wr6fDhvcGGVOjNHlqz8dddosYPryB1TKQCS5oSS+/nMRPf1r7jcqvfa1xew4CQPOoRDb7dNVqubx9A2rZdJXRYyL7fy9H7uF5UZq+e6PLAQBoPR0dPSHF7N7B2XNmR/axR/p1+6TK+M2j2NtF8ZeOisrESQN3jkM+H5Wtt4nK1tvEWv9X6ezsDTFen6+RefO2VEuX1LPqiIhIOlZG/r571pixkSZJlHfYcXWQUZ48JUqTp/aENwP1/wPqRnBBSzrrrEKsWlX9F+AHPlCMGTMqDagIAJpLJvNMJMmqqvVmDS5KU6dHms9H7r57BRcAAP1txYrIzZ8X+TkPru6myD7+WCTl/tsBo7zFlq/PpJi+e5SmTR+cD8iHDInK9jtEZfsd1n7OihVvCjbesD3VwgWRXbAgko7qeXZ9LUnTyD35ROSefCLid5euXq+MHRul3Xq7MiZP6dlu6u076YxuMUma9t/GaIsWLe+vS8NGW7AgiZkzh0d395rfmJIkjZtv7ojddhNcAMC6tLX9OkaNOrFqfdmy86Or64gGVLTpRv/NAVHe4e2x/JzzGl0KAMCgkaxYHrm5cyI3+w0hxROP9+ushvKkraI0dfobZlLsHumECf12v0EnTSNZuqRnK6oXa3Rs9AYeSVf9di1JC4Uo7bxrT1fGX7abmjwl0tFj6lYDfWf8+JHrPEfHBS3njDMKVaFFRMThh5eEFgCwnvL5u2uuF4vvqnMlfaf4jr2icNMNjS4DAKBpJcuW9oYTvUOzZz8U2T8/1b8hxdbb9HZRzIjitOlRmjoj0vHj++1+LSFJIh09Jsqjx0R58pTa56RpJIsXv2HGxl+CjRci+9xzkX30kcis6LuX2pPu7sjPnR35ubPXWC9vtXVPkLFbT2dGafKUqGz7NoPABwEdF7SUp59OYp99hkeptGZwkcmkcccdK2PHHfvvGykADCZjxuwRudyTa6yVy9vGq6/ObVBFm67t4oti1GdPiFcefTrSzcY2uhwAgAEtee3VN4QUD0V+9oORfaZ6BlpfKm/7tij2bvPUM0B7up/bBqpKJTLPPhO5+fMiN29Oz/ySeXMj+8Lz/X/rESOjvNvk1dtMlSZP6RkEPmxYv9+b9aPjAt7k+99vqwotIiKOOqoktACA9ZTNPlEVWkREFIszG1DNelqxImL48Lfcw7j4jr0iIiL/4P3R/VcH1asyAIABL1m8OHJzeodmz34ocnNmR/a5Z/r1nqXtd+jZ6mnqjN6P02wL1Ewymahst310b7d9dB9y2OrlZMlrPWHG/Lk9Qcb8eZF77JFIurv77tYrlkfmnrsif89dq9fSTKZnEPhftpmaMjXKk6dGZfMJg2/OySCh44KW8fjjmdhvv2FRqaz5l1Eul8add66MbbcVXADA+hg69EcxYsQ/Vq0vW3ZedHUd3YCK1qFSibFTdozK+M2j46TPR9cRfxtRKFSfl6YxdrftY9XHj4+Or1b//gAAWkHyf/8X+bkPRW5276+5s/v1Lfk0SaK849t7Oyh6Q4opUyMd1d5v92SAKRYj+8TjPZ0Z8+f1/poTmcWL+/3WlXHj1+zMmDItyju+PSLnff/+tD4dF4ILWsYJJwyJ3/0uX7V+3HHd8d3v1m+YEAA0u/b2D0Sh8Mc11tI0G4sXPxVpulmDqnpruXvvjmFnfi/arr82yltOjFWf/mx0HvvxSEeOWuO8UR/920iKxVj6m8sbVCkAQP1kXnqxp5OiN6DIzX4osi8u7Lf7pZlMlHfaefXg7OK03aM8ZUqkI9b9EJMWk6aRefmlyM2b09OVMW9u5ObPjexTT/brzJSIiLStLUq77BalyVN6h4FPi9JukyNtH92v920lggvoNW9eJg48cHjVeltbGnffvTImTtRtAQDrI5NZGJtttmskyZrfO7u73xNLl17doKrWX/bRR2LouT+KIRdfFOmQodF57Cdi1adPisqWEyMiYtgZ34mh5/4oFj/ytLesAIDBI00j8+LC3i6KB18PKf7v5f67ZTYb5Z12eX1o9rTdozR5Ss/2nbCxVq6M3KMPrw4ycvPmRu7h+ZF0rOz3W5e32bZ3CPjr201VttnWVlMbQXABvY49dkhcc011t8VnPtMd//qvui0AYH0NHfqfMWLEP1Str1jx7Vi16uQGVLRxMi8ujKHn/TiG/M/PIulcFV2zjoqOE0+OYd/9dgy56opIhwyNVcd+PFZ+698FGABAc0nTyLzwfG8XxV9mUjwUmVde6b9b5nI9b6hPn7F6aHZptykRQ4f22z1htUolss/8ubczo3e7qXlzI7twQf/feuSoNTszJk+J0s67+rO/DoILiIgHHsjE+99fneYPG5bGPfesjM03120BAOtr9Oj3RT5/zxpraZrEq68+GpXKlg2qauMly5fFkF/+Twz9ydlrbIvw7fha3BXvjs+8/6l45y+Ob2CFAABvIU0j8+wzPUOz58xe3U2RefXV/rtloRClXSe/HlBMnxGlXSdHtLX12z1hYySvLn59EPhfwozHH42kWOzX+6bZbM/clum937rFAAAgAElEQVS7x6pPHB+ld+zVr/drRoILiIijjx4aN99c/abkKad0xTe+0d2AigCgeSXJ4mhr+320tV0c+fwdkSRpdHfvG0uXXtXo0jZNd3eMPvh9sWLeMzGmsiQejOmxRzwY+SjGr7/9aOx//HaNrhAAaHW9b5Xn5vRs85Sb81Dk5syOzNIl/XbLtK2t5w3yqb1Ds6fP6HmbvFDot3tCv+rujuzjj71hm6meLo3Ma6/12y2X/vKi6P6bD/Tb9ZuR4IKWd9dd2TjssGFV6yNGpHHffStis4E5PxQAmkImszDa2i6Ncnm76O7+YKPL2WTD//X/ie5v/G+8/IUJsfOvn4hD43dxZRwWmw9dGrfcn41x43RpAgB1UqlE9qknXx+cPeehyM2dE5nly/rtlunQoT379k+bHsXpu0dp2owo77RzRL56620YVP4yA+aN20zNnxvZp//cJ4PAi7vvEUuuvWXT6xxE1ie4sGEvg1aaRvzHf9R+A+DEE7uFFgCwiSqViU0112JdKqdtHqM3XxajL1gW8YmIf8//Y4z+76Vx0UVHx29/W4mTTurflnIAoEWVy5F94vHeDoqeLorc3DmRWbmi326ZDhsepanTeodm98ylKL99J7O9aE1JEpWJk6J74qToPugNnRErVkTukfm9g8DnRW7+nMg98nAkHR0bdvkV/fe1PJj524hB67bbsnHnndV/xEePTuPEE20RBQCsKTfx0df/5X0R02Je/HL/Y+Ppp7eLxx9/Z+MKAwAGj1KpZ5uaOQ9FfvaDPSHF/Lkb/CB0Q1RGjIzS1Gk9AUXv8OzyDjtGZLP9dk8YFEaMiNJeM6O018zX18rlyD7959VbTWV752e8cV7em3UefUwdih18BBcMSmkacfrptYdCnXxyd4waVeeCAIABL0mq94culzPxxz/uE8cc09mAigCAplepRG7+3MjfdmsUbrs58nff2b8hxaj2noHZbxicXd5uh4hMpt/uCS2ld/B2ece3R9eHjli9nCxe/PrcjPlzI/voIxGFfHQd+uFYdeLnGlhw8xJcMChdf3027r+/+s2BceMq8alP6bYAAKqlaXvV2quvbhaf/3x3HHlkqQEVAQBNJ00j88zTUbj91sjfdksU7rg1Mq++2i+3qoweHaVpu68OKIrTZkTlbdtFJEm/3A9Yu3Ts2Cjud0AU9zug0aUMGoILBqWzz6492+LUU7tj+PA6FwMANIU0HV21Nm7ca/FP/9QZEd5SBABqSxYtisIdvUHF7bdG9rln+/welbFjV8+iKPZu+VTZehshBTBoCS4YdJ5/Pqk522LLLStx3HGGagIAtVUqY6vWkqQcSbIk0nSzBlQEAAxIK1ZE4a4/9m7/dEvkHp7Xp5evjBsfxel/mUfR01FRmbSVkAJoKYILBp3LLsvXXD/ppO4YMqTOxQAATaNWcBERkcksjnJZcAEALatYjNz990Xh9lt6gor7742k1DfbSJYnbLF6YPZfhmdXtthSSAG0PMEFg84ll1T/sc5m0zjiCHtTAwBrt7auiiR5rc6VAAANlaaRfXh+FG6/JfK33RL5O/8UmZUrNv2y2WyU3rFXdL9nvyi9Y88oTZsRlQlb9EHBAIOP4IJBZf78TDzySPVQ7v32K8fmm6cNqAgAaB5re7PRG48AMNhlnn8uCrfdEvnbb4nCbbdG5pVFfXLd0q6To3u//XuG9r57n0hHjOyT6wIMdoILBpVa3RYREbNmmW0BAKxLeS3r1S9FAADNLXl1ceTvuC0Kt90ahdtujuwzT/fJdctbbR3d+x0Qxf0OiO737B/p5pv3yXUBWo3ggkGjUqk932Lo0DQOPtg2UQDAugguAGDQ6uiI/N139nRV3HZL5ObNiSTd9J0ZKmPGRPE9+0f3vvtH934HRGW77c2nAOgDggsGjbvuysaCBZmq9fe/vxQjRjSgIACgqWQytWdZpOnwOlcCAGyyUilyDz3Qu/3TrZG/9+5Iurs3+bLp0KFRnPnu6N73gCjuf0CUpkyLyFQ/iwBg0wguGDRsEwUAbIpM5sWa6+XylnWuBADYYGka2ccfi8JtN/cEFX+8IzLLl236ZTOZKO2+R+/2T++N4p7vjGhr64OCAXgrggsGha6uiN//vnqbqM02q8R737u2bR8AAF5XK7ioVNojQscFAAxEmYULIn/bLau7KrIvv9Qn1y3ttHNPULHvAVHce59I20f3yXUBWH+CCwaFG2/MxdKl1XtIHnZYKfLVeQYAQJVs9vmqtUpliwZUAgDUkix5LfJ/vGN1V0XuySf65LrlLSf2DNPed/8o7ndAVLbQbQnQaIILBoVLL13bNlGGcgMA6yONbPbRqtVy+W31LwUA6NHZGfl77urtqLglcrMfiqRS2eTLVka1R3GffXu3fzogyju+3UBtgAFGcEHTW7484rrrqv8ob711JfbayzZRAMC6ZTIvRiaztGq9XJ7cgGoAoEWVy5Gb81Dkb781CrfeEvl774qks3OTL5u2tUXxne/q3f5p/yhN3z0im+2DggHoL4ILmt5VV+Wis7P6zYgjjihGJtOAggCAppPNPlxzvVTatc6VAEALSdPIPvXk63Mq/nh7ZJYu2fTLJkmUps+I4n7v7dn+6Z3vihg6tA8KBqBeBBc0vYsvrj3EwjZRAMD6yuVm11wvlXarcyUAMMh1d0fh9luicNUVUbjphsguXNAnly3tsGMU990/uvd7bxT3eU+kYzbrk+sC0BiCC5rayy8ncccd1e2dkyeXY5ddNn3fSwCgNaTp8CiVdo5c7rE3rBWiXN6pgVUBwCDR2RmFW2+Otisuj8I1V0dmWfX2jBuqvPmEnqBi//dGcd/9ozJpqz4oFICBQnBBU7vsslxUKtXbRM2aVWxANQBAs+rsPDE6O0+MJFkSudwDkc/fF0myNCLaGl0aADSnjo4o3HRDtF15eRSuvSYyK1ds0uUqI0ZGcZ/3rO6qKO+8i4HaAIOY4IKmdskl1dtEJUkaRxxhmygAYMOl6egoFg+MYvHARpcCAE0nWbE8CjdcF21X/C4KN14XSUfHRl8rzeejuNfM3qDigCjN2CMiX3uraAAGH8EFTevJJ5OYPbt6m6i99y7HxIlpAyoCAACA1pIsWxqFa//QE1bcfEMkXV0bfa3i1Omrg4rizHdHDB/eh5UC0Ew2Krg499xz44ILLogVK1bEjBkz4t/+7d9iq63sJUh9GcoNAAAA9Ze89moUrrm6Z2bFrTdHUty47ZrLm0+I7r/5QBT3OyC699kv0nHj+rhSAJpVkqbpBr2afsEFF8SvfvWrOPvss2PzzTePM888MyIivvGNb1Sdu2jR8r6pEt4kTSNmzhwezzyTWWO9UEhj/vwV0d7eoMIAAABgEEoWLYq2P1wZbVdcHvk/3h5JaeNeGixvOTG6Dv1QdB/yoSjuNTMiW72TAgCD2/jxI9d5zgZ3XPzsZz+Lr371q7H99ttHRO3AAvrbAw9kqkKLiIj3va8ktAAAAIA+kHnpxShcdUW0Xfm7yN/5x0gqlY26TnmbbaPrg4dF16EfitIee0Zkqv97HgDeaIOCi5dffjleeOGFWLp0aRx88MGxePHimDlzZnzrW9+K/5+9O4+Oq0zzPP+798aNkGV5wyt2pjfMDgl4wRjwvu8Gm50EbDmnq2ubMyerpmems7uquqq7qruqq7r7nMzKqraEIdmShMQbeJWNd7ANCZgEs9kG23g3XmRJEXd554+QZZsISSEpQqHl+zlHR1LoxhuPMgM5bvzu87zXXHNNrmoEUqTblFtiTBQAAAAAAE1hHzms2Krliq1crsjud2U1bFBHDX/QYCVmz0uGFT+6U7KsLFcKAGjLGhRcHDt2TJK0Zs0aPfvsszLG6E//9E/1s5/9TL/4xS9yUiDwfb4vLVuW+tTt1Mlo8mSCCwAAAAAAGsI+eECxVSsUe3O53Pf2NHod/8abqjsr5im45VbCCgBAozUouLi0HcbixYvVu3dvSdKf/Mmf6Cc/+Yni8bhisVj2KwS+Z8sWR6dOpbaVzprlq6AgDwUBAAAAANDKOF99odjK5YquWiH3ow8avY5/y22Kz56r+Ky5Cm68KYsVAgDaswYFFz169JAkde7cuea2fv36yRij06dPq2/fvtmtDkjjtddqGxPlNXMlAAAAAAC0EsbI+WyfYiuXKbZqhSKf/r7RS3l33FW9wfYcBYOHZLFIAACSGhRc9OnTR0VFRfr000916623SpKOHDki13XVq1evnBQIXOniRemtt1Kftr17h7rvviAPFQEAAAAA0EIZI+fjvYq9Wb1nxRefN3opb9gIxWfPU3zmbIUDBmavRgAA0mhQcBGJRLRgwQL98pe/1IgRI1RUVKSf//znmj17tiKRBi0FNMratRFVVKTOyHzgAV+Ok4eCAAAAAABoSYxR5IP3k3tWrFwm5+CBxi1jWfJGjlJi9lzFZ85R2LdflgsFAKB2DU4bfvrTnyqRSOihhx6S53maOnWqfvazn+WiNiDF66+nHxO1YAFjogAAAAAA7VQYKrJnt2Krliv25go5h75p1DLGtuXdN1rxWXMVnzFbpnp/UwAAmptlLu24nQMnT17I1dJoh06ftnT77R3l+1d3XFx/faBt2ypkpTZiAAAAAADQNgWB3F3vKFq9Z4Vz7GijljGRiLzRY5NjoKbNlKne3xQAgFzp2bNTvccw3wmtxooVkZTQQpLmz/cJLQAAAAAAbZ/vy92xTbGVyc4K+9TJRi1jolElxk1QfNZcJabNkOnaLcuFAgDQNAQXaDVefz390/XBBxkTBQAAAABooxIJuds2J8OK1atknznTqGVMQYESEyYrPnuuElOmyXTqnOVCAQDIHoILtArffGNp167Up+vw4YEGDszZtDMAAAAAAJpfVZWimzcptnKZomtXyz53tlHLmMKOik+emgwrJkyWioqyXCgAALlBcIFW4be/Tb8p9/z5dFsAAAAAANqAigpFN25QbNUyRdetlV3euH1Dw6JOSkydrvjseUqMnyh16JDlQgEAyD2CC7R4xqQfE+U4RnPm+HmoCAAAAACALCgvV2zDWsVWLle0bJ2siopGLRN26arE9JmKz5qjxNgJUiyW5UIBAGheBBdo8T7+2NZnnzkpt48bF6hnT8ZEAQAAAABaD+v8OUXXrk6GFW+XyaqqatQ6Yffuis+YrfjMOfLuHyNFo9ktFACAPCK4QIv3+uuMiQIAAAAAtF7Wd2cUXfOWYquWK/r2Rlle485ng169lZg5W/FZc+WNuk+K8LYOAKBt4l84tGhBIL3xRurTtLDQaNo0xkQBAAAAAFom6+RJxVavUmzlMrnbt8ryG3cOG/Ttp/isOYrPmid/xN2SkzqRAACAtobgAi3azp2Ojh61U26fNs1XUVEeCgIAAAAAoBb2saOKvrlSsVXL5e7cLisMG7VO0H+A4rPmKj5rjvyhwyU79bwYAIC2jOACLVq6TbklacECxkQBAAAAAPLPPnJYsVXLFVu5XJHd78oyjduL0R80WIk5DyTDih/dKVlWlisFAKD1ILhAixWPSytXpu5v0b17qLFjgzxUBAAAAACAZB88oNiqFYq9uVzue3savY5/402Kz5yj+Ky5Cm69jbACAIBqBBdosTZsiOj8+dQXbXPn+nLT79cNAAAAAEBOOF99odjK5YquWiH3ow8avY5/6+3Ve1bMVXDjTVmsEACAtoPgAi1WbWOi5s9nTBQAAAAAIMeMkfPZPsVWLlNs1QpFPv19o5fy7rxL8VlzlZg1R8HgIVksEgCAtongAi3S+fPS+vWpT8/+/UMNH964zc0AAAAAAKiTMXI+3qvYm9V7VnzxeaOX8obfXbPBdth/QBaLBACg7SO4QIv01lsRxeOpY6Lmz/cY+QkAAAAAyB5jFPngfcVWLlds1XI5Bw80bhnLkjdylBKz5yo+c47Cvv2yXCgAAO0HwQVapNWraxsT5TdzJQAAAACANicMFdmzOzkG6s0Vcg4fatQyxrbl3Tc62VkxY7ZM795ZLhQAgPaJ4AItTmWltHlz6lPz5psD3XADY6IAAAAAAI0QBHLf3anoquWKrVoh59jRRi1jIhF5o8cqPnue4tNmyvTokeVCAQAAwQVanG3bHFVUpM6DmjaNbgsAAAAAQFJk17vq9H/9kc69+BuFAwelP8j35W7fqtiqFYq9uUL2qZONeiwTjSoxfqLiM+coMW2GTNduTagcAADUh+ACLc6aNemfllOnElwAAAAAAKTIOzvV5bH58n90h8I+1179w0RC0a1vK7pqhWKrV8k+c6ZRj2EKCpSYMFnx2XOVmDJNplPnLFQOAAAyQXCBFiUMpbVrU5+WvXuHuvNOxkQBAAAAQHvn7tyuLo8tkHfXUJ174VWpoECqqlJ08ybFVi5TdM1bss+fa9TaprCj4pOnJsOKCZOloqIsVw8AADJBcIEW5Xe/s3XihJ1y+5QpvuzUmwEAAAAA7Yi7fau6PPGQvGEjdO5fn1V0U5liq5YpunaN7IvljVoz7NRZiSnTFJ89T4nxE6UOHbJcNQAAaCiCC7Qo6botJGn6dMZEAQAAAEB75m7drC5PPKRg0GCZok7qMew2WRUVjVor7NpViWkzk50VY8ZLsViWqwUAAE1hGWNMrhY/efJCrpZGGzVmTKH27XOuuq2w0GjfvnIVFOSpKAAAAABA3ljnzqrD//xHFf7if0nGyGrk2xhh9+6Kz5it+Ky58u4fI7lulisFAACZ6NmzU73H0HGBFuPAASsltJCk8eN9QgsAAAAAaEesM6cVXbs6uWfFpjJZQdCodYJevZWYOVvx2fPk3XOvFOFtEAAAWgP+xUaLsW5d+qfj1KmMiQIAAACAts46eVKx1asUW7lM7rYtjQ8r+vZTfNYcxWfNkz/ibslJvUAOAAC0bAQXaDHWrEl9Otq20eTJjXuxCgAAAABouSzrjBznHX17YLMcs1VPzi5V0dEf6W/1skapYeeBQf8Bis+aq/isOfKHDpdsO0dVAwCA5kBwgRbhu++kd95JvQrm7rsDde+es21YAAAAAADNxLYPy3V3yHV3yrZ3KBb7VJLUrVvy54PvP6Df/OZhzdEKfazb1Fsn6lzP/2F/JR5YoPjsufJ/dKdkWbn+FQAAQDMhuECLsGFDREGQ+iKTMVEAAAAA0BoZOc4X1UFFMqxwnK/rvMfo0Vv1m988rFPqqZ0apXlanrqq60q+L8sYRQ59I7v0f8vdvEnBdUMUXDdE8TkPKLjxplz9UgAAoJkQXKBFWLs2/VNx+nSCCwAAAABo+XxFIh/VhBTJropTDVphzJgtNV930bnLK996u+Kz5yo+a66CG26U4nE5Xx+U89WXyY/9X8r58gtFt26WVVmpi//xP2XttwIAAPlhGWNyNofn5MkLuVoabUg8Lt10U5EuXry64+L66wNt316Rp6oAAAAAAHVx3e3VHzsUieySbZc3ab0wtHTNNWc04txuvXnHv1Ni9jzFZ81ROPi6LFUMAABagp49O9V7DB0XyLvt252U0EKSpk2j2wIAAAAAWqqioj9RJPJlVtY6c6ab9uy8R//5wTVa8G9u07nBm7OyLgAAaJ0ILpB3a9akfxqyvwUAAAAA5Esoya7zCM+7r9HBxaFDP9DWraO1detoVVaO0sSJQzR5stFddzdqOQAA0MYQXCCvjEm/v0WPHqGGDQvzUBEAAAAAtDdGtr2/em+K5Gba8fgjqqj4f+u8l+eNUocOz2X0CPv23VgTVGzZMkanTvXXI4/4WrTI0w03hJJyNsUaAAC0QgQXyKu9e20dPZp6Fc+UKb4cJw8FAQAAAECbF8hxPqnenyIZVjjO8auOCMOdtd7bGGnrVkerVo3Xs8+mWT2w9cEHd2rLljHaunW0tm27XydP9pIkDRkS6A/+wNPDD19Up/rHWwMAgHaK4AJ5tXp1bWOigmauBAAAAADaqrgikd/VdFO47ruy7XN13sN1d0nyJLk1t5WXS6++6qq01NXnnzuSrtdf/3U/9ehxSu++O7Kmo2LnzlG6cKFzzf0sy2jqVF/FxQmNGRPIrnsCFQAAAMEF8ivdmKiCAqOxY9nfAgAAAAAaw7IuKBLZdUVHxXuyrKoGrlGhSORD+f5wffWVpdLSqF55xdWFC9aVR2nChI36+usBSiRiKWt07Wr0xBOennkmoQEDGAUFAAAyR3CBvDl0yNLHH6fOgxo7NlBhYR4KAgAAAIBWKhLZpVjst3LdnYpEPpRlNX3PwP3739Gf//lobdpU+1sHX3xxQ8ptt94aaPFiTw884HFuBwAAGoXgAnmzbl36p9+0aXRbAAAAAEBDuO4uFRb+IitrnT59ncrKRutf/uXuOkOLK0UiRrNmJTfbHjkykGXVfx8AAIDaEFwgb9Ltb2FZRpMnE1wAAAAAQFIo2z6mMOxb51GeN6pRqxtjKQhu07Fj92rZsjH6x38cpwMH6n6sK/XsGeqppzw99ZSna69lHBQAAMgOggvkxfnz0o4dqWOihg0L1asXL3YBAAAAtFde9UbaO6s30t4pYzrozJl9kmpvY/D9O2RMR1nWxTpXN8aV7w+T592ryspReuut+/TP/9xTO3c27O2BYcMCLV6c0OzZvqLRBt0VAACgXgQXyIuysoh8P/VFN2OiAAAAALR95XKcg3KcAykftn1IlvX986Kzsu2DCsNBdawZkefdrWh001W3hmGRfP9ued691R/DdOJEoV54wdVzz7k6etTOuOpYzOiBB3wtWpTQnXc2fQ8NAACA2hBcIC/WrmV/CwAAAABtlZFlnUgbTDjOQdn2iQav6Lo7FI/XFVwkx0VFInurA4pR8rx75fu369Kp/3vv2SopiWrFiogSicw3oejXL9TChZ4ef9xTjx50yAMAgNyzjDE5e9Vx8uSFXC2NVszzpJtvLtL581e/UB40KNQ771xkEzcAAAAArVokslvduk3M6pqVlT9WefnP6zmqSlJMV46UqqqSli+PqLQ0qt/9LnVcb11Gj05utj11qq8Ilz0CAIAs6dmzU73H8NIDzW7nTicltJCkqVN9QgsAAAAALYZlnavukLhylNO3On/+N6prv4kgGJz1Wlx3RwZHFdR8deSIpeeec/XCC65Oncp8HFRhodHDD3tatMjTTTcxDgoAAOQHwQWaXW1joqZPZ0wUAAAAgOYUyraPVQcSB+Q4+6/ae8K2z6S9l2WdlDG9al3VmGsUhp1l2+ebVJ0xEfn+HdWjn+6TZFRXYGKMtGOHo5ISV6tXRxQEmV8ZNnhwqEWLEnrkEU9dujSpbAAAgCYjuECzMkZasyb1adetm9GIEUEeKgIAAADQtsXlOF9XhxIHZNtXbor9tSyrqsErOs4B+X7twYVkKQgGybY/zHjNIOinIBioIBikMBwszxsuzxshqWO99714UXrtNVelpa4+/TTzcVCWZTRpUqDi4oTGjQtkZ96YAQAAkFMEF2hWn3xi69Ch1FfDkyczMxUAAABA9hUU/FqdOv1xVtd0nP3y/ZF1HhOGAyVdDi6MiVUHE5fCiUEKgksfA3TlmKdM7d9v6dlno3r5ZTftON7adOli9Nhjnp55JqHBg9lsGwAAtDy8VYxmla7bQkrubwEAAAAA6QWy7SPVXRIHa0Y7SYW6cOGf675nMCjr1TjOwXqPqax8WvH41OqAYqDC8FpJTW9pCENp0yZHJSVRlZU5MibzwOLmmwMVF3uaP99Tx/obOQAAAPKG4ALNKt3+FtGo0fjxBBcAAABA+3RRjnNUtn3p41jN15dvPyLL8lLuGYbd6109m8GFMbbC8AcyJlrvsZ43KWuPK0nnz0svv+yqtDSqAwcyD0Acx2jGDF/FxZ5GjQpkZZ5zAAAA5A3BBZrN0aOWPvggdd7q6NGBioryUBAAAACAZhWNrlQstvJ7IUXjN7C27dOyrPMypnOtx4ThtTImKstKZLSmMYU145wufx6kMBxYPdKp/tAimz77zFZJiatXX3VVUZF56tCjR6gf/9jT00976tuXcVAAAKB1IbhAs0nXbSExJgoAAABoXXzZ9snvdUd8qyC4QfH4I3XeMxL5vQoKXslqNbZ9UEHwozqOcBQEAxSJfFFzSxj2vGJ/iUvhxGCF4UCFYW9J+W1L8H1p3bqISkpcbd3asNP2oUMDLVqU0Ny5vmKxHBUIAACQYwQXaDYEFwAAAEBLZmRZZ64Y03RMtv3tVaObkl8fl2WFKfeOx2fXG1wk93nILsc5UE9wIV28+B8l2dWdEwNkTKes15ENp09bevFFV0uXujp8OPNxUNGo0dy5voqLExo6NPX/GwAAgNaG4ALNorxc2ro1dUzUnXcGuvZa2pYBAACA5lZY+HeKRD65qnMi03FK6dj20XqPyWZwEYadqvevSD3P+L5EYm7WHjcX9u61tWRJVG+8EVFVVebdHtdeG+rppz39+MeeevbkvAoAALQdBBdoFps2RZRIpL4AnzaNbgsAAACg8Sqv6I643BVRVfVwvV0I0eg6ue6erFVi28fqPSYIMg8uwrCrwvDamo8gGHDFeKfBMqa78j3SqSkSCenNNyNasiSq3bvrD1+uNGqUr8WLPU2b5st1c1QgAABAHhFcoFmsWcOYKAAAACC9sHpE03eyrLOyrLOy7as/137bhbQrBsEN9QYX2R7blAwuQkm1jzhKbpRdqCC4VmHYV2HYpzqY6FMdTly6rY+kDlmtr6U4ftzS88+7ev55V8ePZz4OqkMHowULPC1a5OnWWxkHBQAA2jaCC+Sc70sbNqQ+1fr3D3XLLbzgBgC0fpZ1XsZ0zncZAPIqXh0knJNlfXdVuFBVtVh1jTOyrNPq0eO6rFbT3GObqh9VlvVddSdEesZ016lTR9WaOyUawxhpzx5bJSVRrVwZkedl/vv37x9q0aKEHnvMU7duOSwSAACgBSG4QM7t2uXou+9SX5hPnerLal/nKwCANspxvpLv31XnMYWFf7SRuRQAACAASURBVKNodJOMKbrio6OM6VT9ueh7XxcpDK88pkjJq4/5xxPIJcs6V73Xw9maDoj6ux7OyrIqa10zHl9Qz5v5XbP+e2RzbJMxtsKw9xXdEVeOb+pT0zlhzDWq/29U+/obVlUlLVsWUUlJVB9+2LBxUOPG+Vq8OKGJEwM5DbsrAABAq0dwgZyrbUwU+1sAANoTx/lCrru7SWsYY9cEHmH4Q509u6HO4y3rtKLRDd8LS64MTYrEy0G0DUaSJ8uqklQly6qSZZVfES4kOyCC4IdKJObUuVJBQamKiv4iq9VZ1tk6gwvJlTEdZVkXs/aYtv1tvcckw4fuNaOaLo9puvaK8U19FYY9lckG2Ljs8GFLzz3n6oUXXJ0+nfk4qKIio0cf9bRoUUJDhrDZNgAAaL84U0VOGZM+uOjc2eiee4I8VAQAQC7UfwVxbXPoG/QoVijLOi/pvKRYvcc7zufq3PkndR5jTEHaQONS90cYFkkqkjGFMiameHyewrB/PY/7iZJz7qMyxpUUkzFRJd+cjVbXnvkbeWhNjJIjk6q+FyKkfu37IxSG/epcrWPHv5DjfFbnWpe/r38EaTw+rd7gIjfdD2cV1lNeGHaV42QvuLCsc/UeE48/pnj88aw9ZntnjLR9u6OSElerV0cUhpl3lwwZEqi42NPDD3vq1CmHRQIAALQSBBfIqc8/t3XwYOobE5Mm+XLdPBQEAECeZPNKakkypmMGj1mewTGX3vg9ldHj+v6d9QYXnTs/rkhkf53HGOMoGWzEdDnQcKu/vxR4JH/ueSNVUfGzOteLRH4n191UfZ+o6gpNrlw79XZLyTffJWO6qe6AxVSP4zE197n8dX3fS5Z15e3Jn4XhNTKmR52/q20flm2fTlmv/se9JJRlVcqy4rKsShnjKJGYW+djOs7n6tjxZzX3SYYTlbWECJk5d+45JRIP1HmM625rcqfSlWz7bL3HhGH2gwvLqv9xk4HJkTp+Xqgw7CJjusqYrgrDS5+v+V53RB8FQR9JRZlUlvHvgNpdvCi99pqr0lJXn36aeWeKZRlNmRKouDihsWMDxugCAABcgeACObV2LWOiAACQMgsRGiI55ql5HzP5uPV3eliWl8ExgaTKOvcFuPyY9V9+HIm8q6Kiv6z3uIY4depAPeN9qtS9+41ZfcyLF/9MFRX/sc5jCgv/QR06lGbtMYOgt86cqTu4sKxyxWJrsvaYyTXrDzmMKcjyY2YaIGRXJoFJRcUfy7LKvxdMdKv+3EWZdFmheR04YKm0NKqXX3Z1/nzmqUPXrkaPP+5p4cKEBgxgHBQAAEA6BBfIqdWrU59irms0YQLBBQCg7QiCQfUe4/u3yhhXlnVRllVe/flC9Rv4DZdZx0V2uzyS6m+ZtKx4Vh8x2RFR32PWH5a0BskujOZ+zEwChA55etyWF1yEYac0XQ9dv3dbl6vChyDoW+/jxuNPZPx7IH/CUHr7bUclJVFt2ODImMwDi1tuCbR4sacHH/RUWJjDIgEAANoAggvkzIkTlt5/P3W8wr33BurcOQ8FAQCQI8mroet24cK/prunkiN3ymv5uBRuXJRtl0sql20nb/f92+p9zNx0XNQfIkiJLD9qPh5Tunq8Ujq5mOuSSXCR3cfNLEDI/tX+mY2Vym5wkUnnQxAM1IUL//S9QKKLwrBb9X/rnEK1R+fPS6+84qq0NKr9+zPfo8dxjGbO9LV4saeRIxkHBQAAkCledSNnNm5MfwUSY6IAALjEklRQvUF23fsaNEY8vkC+P/yKLo+6w5H0Pyv/XhdAI7of3pbUS9Itjfs9Muu4yG6XR2baxjuQyf/tQtW9n0f2Oy6k+oOL5H4NA2VMrLrrI1b930uBLv+3c+X3Vx5XmLYroj7GdFNVVXFTfzm0EZ99Zqu01NWvf+2qoiLz/+Z79Aj11FOennrKU9++jIMCAABoKIIL5MyGDemfXlOmEFwAANAcjOkh329qIBIquRdFhSwroTDsVe89Llz4X0p2kiQkJdRx8X+VP+dGeX89pua25Gev+k3zRHXYkaj+3rvquDDsV+9j5mZUVD7ebGz+joukuOoKJ4zpUB0gFFwRDHT4XlDQobozo7bbC666TxgOqLeq8vL/np1fD2iAIEju1VdS4mrr1oadMg8dmtxse84cXzG2JQEAAGg0yxiTszOykycv5GpptHC+L910U1HKJnU33hho69aKPFUFAACaXTyuHgN6q/y//ZOqnlqYwweqqO4OuRyEXB2KxGsJS75/u5QMBixVVPyhpLr2EgnUocPPr7rPZVd+b1V3oVppf3bl975/u3x/RJ2/aSSyS47zRa1r1Pb95U5YW5cDhWSnQnL0mFPn4wJt3Zkz0osvRrV0qatDhzIfBxWNGs2d66u4OKGhQ8McVggAANA29OzZqd5j6LhATuzZ46SEFpI0cWLjNiAFAACtk3PwgKwwVHD9DTl+pMLq0UA5fpirOKqs/NPmfEBJku/fLd+/u9kfF2ir9u61VVLi6re/dVVVlXlHU58+oZ55xtOTT3rq1YtxUAAAANlEcIGcKCtLf8XexImMiQIAoD1xvvhckuRfd32eKwGAyzxPevPNiJYscbVrV8NOi0eN8lVc7Gn6dF+um6MCAQAA2jmCC+REuv0tOnY0GjmSjotMRN7brcJ/+Dtd+JdSmc5d8l1Ofhgj+9hROfu/krP/K1kXLii44QYlJk6RrLaxGSoAtAeRLz9X2KWrTM+e+S4FAHT8uKVf/crVc8+5On4883FQHToYzZ/vadEiT7fdxjgoAACAXCO4QNYdPWrp979P7bgYO9ZXNJqHgloZd/tWdX7yEQW33ibTsSjf5eSW78s+cljOwQNyvj6Y/HzwQDKsOLhfVkXqfiiVj/9Y5f/j52kWAwC0RM6XXygYcn39obMxBNMAcsIY6b33bC1ZEtXKlRF5XuZ/a/r3D7VwYUKPP+6pW7ccFgkAAICrEFwg6zZuTP+0Yn+L+kXL1qnzwifljRylc0tfkpw2sElmVVUylDiwv/rjq+TngwdkHz4kK2jY86LDS79S5f/xhwpuuTVHBQMAssn58nMF199Y+wGep4IXn1fhP/ydqn78jCr+3b9vvuIAtGlVVdKyZRGVlkb1wQcNe109dqyvxYsTmjQpaBMvyQEAAFobggtk3YYN7G/RGNGVy9X5DxYpMXGyzv9iidwPfyd362bZZ07nu7QkY6QgkJVISIm4rIRX/TkhJRKyEnEp4VV/TshKJGTFq2SdPi0ryzul2mdOixgMAFoBY+R88YXiM2an/iwMFVv+W3X827+W/fVBxRc8oqqnFzV/jQDanCNHLC1d6uqFF1ydPp35OKiOHY0efTQ5Dur66xkHBQAAkE8EF8gqz5M2b059Wt18c6C+fbP75nVbEnv1ZXX6038rb/jdMoUd1X3oLbLPns13WS1S2KOn/Ftvy3cZAIAM2Af3y75wXiZWcPlGY+RuKlPH//xXcvd+qPiUabq49CU66QA0iTHSjh2OSkpcrV4dURBkPg7quutCFRcn9Mgjnjp1ymGRAAAAyBjBBbJq1y5H5eWpJwmTJtFtkY797RF1/Kv/oII3XpOxbUV3vSPteiffZbVY3rDhKv+rv5Xpdk2+SwEA1MP5eK+6PPqgJKnTf/h/5O5+V5V/8Efq+F/+k6Lbtsi7+x59t2Kt/HtG5blSAK3ZxYvSa6+5Ki119emnmc90siyjyZMDFRcnNHZsIDvzxgwAAAA0A4ILZFVZWW1johjsIyk5MuPjvYqtfUvRNW/J/eiDmh9ZIe3okhR26qxg0GAFgwcrGHydgkHXJT8PHiLTvXu+ywMAZMA6dUpdnnhI1okTNbcVrHhDBSvekH/zLTr3wq+VmDyNzbgBNNqBA5aefTaql192de5c5n9LunQxevxxTwsXJjRwIB3hAAAALRXBBbKqrCz1KdWpk9GIEe04uEjEZW/brg7r3lJs3Wo5hw/lu6K8C/r2UzBwkIKBgxQOHKRgwMDk9wMGJrspeCMLAFotE4QqnbNO/3D0A/2N/r1+oiWyZGRJik+drvNLXxI73QJojDCU3n7bUUlJVBs2ODIm89eMN98caPFiT/PneyoszGGRAAAAyAqCC2TNkSNW2vbssWN9uW4eCsqbUJWVn+jw4a2KhmtVXhVo/KNva6y66H9ro65v4GrGcVrOGzyRiIwblaJRmeqP5NcxKeomP7tRmVi05rPp0jXZNTFocPKj/wCpQ4d8/yYAgBx58W826y8PPyVHgR7Rq6pSgTZpvGbqLVUu/EnL+TcNQKtx/rz0yiuuSkuj2r8/85lOjmM0Y4avxYs93XNPwLUxAAAArQjBBbImXbeF1D72t7Dtr1Ve/rYuXtyiPn02q3//E+rfP/mzILDVpctZbT43Tk/pee3QvarvnCn4YX/Fp89UYuoMeffcq3aW/AAAWqmNG21N/oP/T0/91UKt/svp8n9u616zW111TpPHVsobNyHfJQJoRT77zFZJiatXX3VVUZF56tCjR6gf/9jT00976tuXcVAAAACtkWWMydkruZMnL+RqabRATz9doNWrU99g/+ijcvXp07ZOGCzrlFx3i8rL31Ystlk9ehyo8/i5c5dpxYq5kqQKdVAHVaUcY2y7Zp+LsKiTghtvlH/jzQpuvFn+zbfIGzNO7BoIAGipvvtO+rM/26MVKy6HE6EnrV43Q9v+frx++osHZXr2zGOFAFqDIJDWro2opMTV1q0Nu87urruSm23PnesrFstRgQAAAGiynj071XsMHRfIikRC2rIl9el0221BGwktyhWN7pBtb5bvv61u3fZKkrp0yezekyZt0IoVc9VTJ+Qoud+HicWUGD1WiakzlJg6XWGv3rIPfaPIZ5/K2bdPkc8+VeTjvSp44zVZlZU6t/QlJWbMytUvCABAkyxdGtXDD5dcdZvtSjNnvqX+kXsILQDU6cwZ6YUXonruOVeHDmV+sY7rGs2d62vx4oSGDg1zWCEAAACaE8EFsuLddx1dvJjavj1xYmsdE+UrEnlf0egm2fYmRaO75DiN/10mTiyTq4T+vuNfKJz1kM5NnaHEuAlSUdFVx4UDBioxYKA0ZfrlG4NA9skTCnv3afTjAwCQa2fOWLrnnndSbr9Y3l19hv7bPFQEoDXYu9fWkiVRvfFGRFVVmY+D6tMn1DPPeHrySU+9erWFC6UAAABwJYILZMWGDemfShMnBs1cSdPZ9mF16TJKkci5Jq8VBLY++mCYTuz7kbb9804NmvtfdCHSwP/sHEdhn2ubXAsAALk0fryvTp1Sx4Q6kbGSmNkC4DLPk1atimjJkqh273YadN977klutj19us82cAAAAG0YwQWyoqws9YSjSxej4cNbR3ARBNL779tauzaitWuv16ZNHXTttY0LLn7/+1u0d+8EBcFYXXfdKA0e3Fk/6J/lggEAaGEmTAjUuXOaPZxMYR6qAdASHT9u6fnnXT3/vKvjxzMfB9Whg9H8+Z4WLfJ0222MgwIAAGgPCC7QZN98Y+nzz1ODi3HjfDW0uSC3quS67yoIblAYXquLF6XNmyNauzai9esdnTp1+eRpw4ZJ+vGPX8ho1UOHfqC3356ob78dr27dRuvee3tp4kTa1QEA7U80Gk9zK90WQHtmjLRnj62SkqhWrozI8zIfB9W/f6iFCxN6/HFP3brlsEgAAAC0OC3qbWW0TmVltY2Jyvf+FlVy3T1y3W1y3e1y3V2yrEqVlf2D/u7v/k9t3eooHk9/4rR+/eRag4szZ7pp06bxeuedCfL9cbrzzkEaOzZQx46XjiC0AAC0V+n+7W/YGBgAbUNVlbRsWUQlJVF9+GHD/g6MHZvcbHvSpEAOf0IAAADaJYILNNnGjemfRuPHN/eYqIty3V3VIcV2ue4eWVbqlZ8VFW9rw4af1rnShg2Tar6uqopp69bR2rBhkvbtm6Af/vA2TZ1q9NOfXjqRah3jsAAAyL3U8N6YzK+uBtD6HT5saelSVy+84OrMmczHQXXsaPToo8lxUNdfzzgoAACA9o7gAk1SVSVt3Zp6GdSPfhSod+/cdh5Y1gVFIu8oGt0u192mSOR9WVb9XR7jxr2tSMST79e+m9/Ro33153/+3/TRR3coHh+lsWNdzZvna8gQo/RXkwIAgPRdhwQXQFtnjLR9u6OSElerV0cUhpn/dz9kSKDiYk8PP+ypU6ccFgkAAIBWheACTfLOO44qKlJPTCZNyv6b+7Z9TJHI+3LdHdVBxYeyrIZ3O3TqVK577nlH27aNTvvzjh2Nxo/3NWDAH6u4OFD37kaS18TqAQBo64wsi+ACaE/Ky6XXXnNVWupq377MZzpZltGUKYGKixMaMyaQnXljBgAAANoJggs0SXPsb1FQ8K8qLPxHOc63WVtzwoSNVwUXffuGmjrV19Spvu67L1CMfUQBAGgQyzqX9nZjipq5EgC5tn+/pWefjerll12dP595ONm1q9Hjj3tauDChAQPYFw4AAAC1I7hAk5SVpV5Z1a2b0dCh2ZxL6zQ5tKisLNDOnaO0efNYrV8/Wbt23a1bbw00Y4avadN83XZbKIsLQgEAaDTLOpP2dmO6N3MlAHIhDKVNmxyVlERVVuY0aP+aW24JtHixpwcf9FRYmMMiAQAA0GYQXKDRDh609OWXqcHF+PF+9abV6VxUJLJPkcjvFIm8Lymq8vL/Uefj+P7QBtdmTEd53kidPXu/Hn54knbuvFuJxOU2ij59Qq1ff1ER/gsAACArbPt02tvD8JpmrgRANp0/L738sqvS0qgOHMh8ppPjGM2c6WvxYk8jRwZcJAQAAIAG4W1bNFptY6ImTPAlVSgS+UyO86kikX1XfP76qmPDsKvKy/9Jdc2/9v1bZUxUlpWo9Zgw7CzPu0eed7887z75/p2SXP3yl642by5IOf6xxzxCCwAAssi2T6W9PQzpuABao337bJWWunr1VTftnna16dEj1FNPeXrqKU99+zIOCgAAAI3DW7dotHTBhWWFevDB0erR4/1aNui8mm2flW3vVxheV8dRUfn+7XLd92puCcOu8rz7qj/ul+/fLunqNg9jpBdecNOu+NhjbLYNAEA2Oc5XaW8Pwz7NXAmAxvJ9ae3aiEpLXW3d2rBTxaFDk5ttz5njs18cAAAAmozgAg3iOJ+qoOAlJRJfa9u2l/X9p9Dw4Xt07bXvpb9zLVz3fcXjdQUXUjw+X74/VJ43VL4/TEFwg6S6W9V37XL0xRepM6tGj/Y1cCBXfwEAkE2O82XKbcZYCoK6/40HkH+nT1t68UVXS5e6Onw483FQ0ajR3Lm+iosTWd7jDgAAAO0dwQUkhbLt47KsMwqCW+s80nEOqbDwf2rLlqmqqkodwTRjxlsNfvRI5H3F4w/VeUxl5R83eN0XX0zfbfHkk3RbAACQbY7zecptYfhDSezEC7RUH31ka8mSqN54I6J4PPNxUNdeG+qZZzw9+aSnnj25IAgAAADZR3DR5hlZ1hnZ9nHZ9rHqjxNynEOy7a/lOAflON/IsqoUBD/QmTOf1LlaEAySJL311oy0P58+fXWDqvP9wTKma4Puk4nz56UVK1Kf3t26GU2f7mf98QAAaO8ikdTgIgiG5KESAHVJJKRVqyJasiSqPXtSu5PrMmqUr+JiT9On+3LTXyMEAAAAZAXBRStmWaflOAerQ4lLwcSVn49Xd1Jk1mFg20ckxSXVPpQ2CH4oSVq9enrKz3r0OKnhw/ekvV8YdlUQ3CTfv7nms+/fIWO6ZVRbQ73xRvpNBB96yFNBaqMIAABoAtv+VrZ9IuV2378hD9UASOfYMUvPP+/q+eddnTiR+TioDh2MFizwtHChp9tuYxwUAAAAmgfBRV75sqxzsqyzsu2zsqxzNZ/DsJcSiZl13rtDh1+qY8f/mrVqLMvIcb5REFxfx1EF2rfvPn35ZeoxU6eulWUVyfOuDiiC4ObqjTkzbz9vqtrGRD3xBGOiAADINmMcXbz4f8t19ygSeV+2fVaS5Pt35rkyoH0zJrnvW2mpq5UrI/L9zF+P9+8fauHChB5/3FO33FxrBAAAANSK4KKZWdZpdes2ujqsKK/1uERifL3BRTIMyC7b/rqe4EJavXp+2ttHj56g06cPqTkDinT27rX1wQepbe/DhgW6+WauEgMAINuM6a2Kip9d+k6O86UikffkeWPyWhfQXlVWSsuWJcdB7d3bsHFQ48b5Wrw4oYkTAzkNuysAAACQNQQXzcyYjnKcw/UeZ1ln6z0mF8GF4xyUV09TwsqVf5Rym2UZjR3bWVL+N+djU24AAPLJUhBcX++FEACy79AhS0uXunrxRVdnzmQ+DqqoyOjRRz0tWpTQkCH5fz0PAAAAEFw0uwIZUyDLqqrzKMs6V+9KYdirSZUEQR+F4UAFwQAFwUAFwUB53qg671NRIe3YkRoMDB0aqnv3/J/kVFZKr72WWl/HjkZz5xJcAAAAoG0xRtq61VFJiau1ayMKw8y7n6+/PtCiRZ4eecRTUVEOiwQAAAAaiOAiD8KwqxznWJ3HXJoNXfc6qR0XxjgKw14Kw97VH32qv+/zva97S2r4LtXbtzuKx1NPhiZO9Bu8Vi6sWhXR+fOp9T3wACdjAAAAaDvKy6VXX3VVWurq888zn+lkWUZTp/oqLvY0ZkwgK79TXgEAAIC0CC7ywJgukuoOLpIdF0Z17RcRhn10/vwvrgopjOkuKXfDaDdsSP+UmTSpZQQXbMoNAACAtuyrryyVlkb1yiuuLlzIPHXo2tXoiSc8LVyYUP/++e+UBgAAAOpCcJEHicQM+f5whWFXGdOl5rMxXau/Tn7Uz1U8/mTO673EGKmsLPUp06NHqB/9KP+bXn/1laUdO1Lru/nmQEOH5r8+AAAAoDHCUCorc7RkSVSbNjXsFO7WWwMtXuzpgQc8FRbmqEAAAAAgywgu8uDixb/KdwmN8uWXtr75JnWTvwkTAtmZ7/2XMy+9VPum3LTAAwAAoLU5e1Z6+WVXpaVRff115i+4IxGjWbN8LVrkaeRIxkEBAACg9SG4QMbKytKPoGoJ+1t4nvTKK6nBRSxmtGABY6IAAMgFyzovYwrFS0oguz75xFZJiavXX3dVUZF56tCzZ6innvL09NOe+vRhHBQAAABaL84ykbF0+1vYttG4cfkPLtati+jkydSr0GbO9NWtWx4KAgCgHSgs/HsVFCyV541VIjFRicQEheGAfJcFtEq+L61eHVFJiZt2/Gldhg0LtHhxQrNn+4pGc1QgAAAA0IwILpCR8nLpnXdSOy6GDw9aRDDAptwAADS/aLRMtn1OsdgKxWIrJEmeN0xnz26UxGwaIBMnT1p64QVXzz3n6ttvMx8HFYsZzZvnq7g4oTvvZD83AAAAtC0EF8jIrl2OEonUNyAmTgzyUM3VjhyxtHFjaqgyYECo++7Lf30AALRFlnVckcjHKbeHYT8RWgD1+93vbC1ZEtXy5ZG0r7Nr069fqIULPT3+uKcePRgHBQAAgLaJ4AIZ2b07/f4WLWFM1CuvuArD1JO9J57wWsSm4QAAtEXG9NKZM+8oGt2oaHSDXHeHLKtKicTEfJcGtFjxuLRiRUQlJVG9/37619e1uf9+X8XFnqZO9RXhLA4AAABtHC95kZFdu1JPrAoLjW6/Pb9t6WEovfRS6pgoxzF69FHGRAEAkDuWguAWVVbeosrKP5ZUKdfdId+/Pd+FAS3Ot99aev55V88/7+rUqcyvrCksNHroIU/FxZ5uuolxUAAAADWMkeJxWVWVsuJxqTL52aqqlKrisuJVya/jcVnVP1O8SlZlVfXPqpLfV1Xfp/o2q6pKqkoeY4o6KzFpiir/zR+Kq6ObH8EF6uX70nvvpQYXQ4cGeb/aa8sWR4cOpf7hmDzZV58+tM4DANB8Osjz6LYALjEmuUdcSYmrN9+MKAgyHwc1aFCoRYsSevRRT1265LBIAACApvL96jf6L4UIVdKV4cAVP7scIlRdFSjU/KzqykDh6hDBqopLVZVXPE68WX696Na3ZZ84rot/8dfN8ni4jOAC9frkE1sVFaknWnffnf/9I9iUGwAAAC1JRYX0+uuuSkpcffJJw8ZBTZqU3Gx7/PiAi/oAAECLYH13Rs6B/XIOHkh+VH9tHzwg+/QpWX7+x8jnWsFLz+viz/5Schr22g5NQ3CBeqUbEyXlP7g4dcrSW2+lPoV79w5bxKbhAAAAaD8OHrT07LNRvfSSq3PnMu+u6NzZ6LHHPC1cmNDgwXQMAwCAZhaGso8fqwkjksFEdVBx4IDsc2fzXWH+RVxGReUBwQXqlW5jbssyGj48v+HAb34TkeelnhQ+9piX9xFWAAAAaPvCUNq82VFJSVTr1zsyJvPA4qabAhUXe5o/31NRUQ6LBAAA8H3Zh765qmOiJpz4+qCsysp8V9iiVS76iWRl/joP2cHbu6hXuo6Lm24K1blzHoqpZkztY6Iee4wxUQAAAMidCxekX//aVUlJVF99lfnVd7ZtNH26r8WLPd17b8D5LwAAyJ7KSjlfH7wcTBz4qma8k33oG1kB00nSMQUFMrECmVhMKuggUxCTKeggxWIKe/RUfPpMxR95PN9ltksEF6jTkSOWjhxJPRkbMSK/f+x277b1+eepgcro0b4GDaLFHgAAANn3+ee2Sktd/frXri5ezDx16N491JNPenr6aU8/+AGvVQEAQONYZ7+7aq8J+8p9J44dzXd5jWZs+6rQ4KoQIVYgFRQkA4aCAilWkDymIFb9dXXw0KH6Z7GYTIdk8JBcq0DqcEU40SG5vinoIEWjjIBqwQguUKeWur/Fiy9G097+5JN0WwAAACB7gkBaty6ikhJXW7Y07PTpjjsCFRcnNG+er4KCHBUIAADaDmNknzgu+8ClUU77r94Q+7vv8l2hjOsqGDBQwcBBCvv9UKaw8HJoUB061AQHVwYK1QFDTQhxRaAgN/1UFbRvrN4s5wAAIABJREFUBBeoU0sMLi5ckJYvT33qduuWbL0HAAAAmurMmeTFMkuXujp0KPMr8VzXaM4cX8XFCQ0bFjIOCgAAXM33ZR85fMVeE1fsO/H1AVkVFfmuUKawo4JBgxUMHHT5c/XXYd9+kpP+/UIgmwguUKd0G3P36hVqwID8tbi/8YariorUM8CHHvK4kg0AAABNsnevrZISV7/9rauqqsxThz59Qj39tKcnn/TUuzfjoAAAaNeqqpL7TVzaBPtSx8SB/XIOfSPLz/+Ft2H37tWBxJXBxHUKBg6S6dmTzaiRdwQXqFV5ufT736deXXb33fndSPCFF9K3jz3+OGOiAAAA0HCeJ735ZkRLlrjatathp0gjRyY3254xw2fKAQAA7VUYKvLRB4qWrVd0wzpFfveerDDMd1UK+va7umti0GCF1SGF6dwl3+UBdSK4QK3ef99REKQmFPkcE7V3r60PPkjtAhk2LNAtt+T/HwQAAAC0HsePW/rVr1w995yr48czHwdVUGA0f76nRYs83X47r0EBAGiPrO/OKPr2xmRYsXGD7FMnm70GE4ko+GF/hVeNdar+uv8AqUOHZq8JyBaCC9Sqtv0tRozIX3Dx0kvpL2N74gm6LQAAAFA/Y6Q9e2yVlES1cmVEnpd5K3H//qGeeSahJ57w1K1bDosEAAAtTxgq8vFHim5Yp2jZekXe290sXRWmQ4fvjXO6onui3w+kCG/vom3imY1apQsuCgpM3q4qq6yUXnstNbjo2NFo3jyCCwAAANSuqkpatiyikpKoPvywYRtKjh2b3Gx78uSAvSgBAGhHrLPfKbp5UzKs2LhB9skTOXmcsFu37wUTyY9w0CCFvXqz3wTaJYILpBUE0nvvpZ6V3XVXoGg0DwUpOXf43LnUP9QPPOCpqCgPBQEAAKDFO3zY0tKlrl54wdWZM5mPg+rY0ejRR5PjoK6/nnFQAAC0C8YkuyrK1ie7KvbskhVkZ/JI0OfalH0mLnVPmK60cgLfR3CBtPbts3XhQsva3+LFFxkTBQAAgPoZI23f7mjJEldr1kQUhplfpThkSKDiYk8PP+ypU6ccFgkAAFoE69xZuZs31exV4Rw/1qT1TCwm7977lbh/rIIh1ycDigEDpcLC7BQMtBMEF0irtv0t8hVc7N9vafv21KfrzTcHGjqUK+AAAAAglZcnR4uWlrraty/zmU6WZTRlSqDi4oTGjAlkZ96YAQAAWhtj5Pz+Y0U3rld0wzq5u99tcldF0H+gEpMmKzFxshL3jSGkALKA4AJp1RZcDB+en+Di1Vdr77ZgzB8AAED7tn+/pWefjerll12dP5/5i8OuXY0ef9zTwoUJDRhgclghAADIJ+v8Obmb306GFWXr5Rw72qT1TDQqb9R9SkyaosTEKQquG8I+FECWEVwgrd27U4OLG24I1C0PI/eMkV5/PTW4iEaNFixgTBQAAEB7FIbSxo2OSkqiKitr2GnNLbcEWrzY04MPelwQCQBAW2SMnE8/qd5Ue73cXe/I8v0mLRn0H6DEhEnJsOK+MVLHjlkqFkA6BBdIceyYpW++Se2Pz9eYqD17bH39dWo9kyf7uuaaPBQEAACAvDl3Tnr5ZVelpVEdPJj5TCfHMZo509fixZ5Gjgy4KBIAgDbGunBe7pbNipatS+5V8e2RJq1nXFfeqPuT458mTlZw/Q10VQDNiOACKdJ1W0j5Cy5eey39mKgFC5qWlAMAAKD1+PRTWyUlrl57zVVFReZvGvToEeqppzw9/bSna69lHBQAAG2GMXL2fZrcVLtsndx3dza9q+IHP1Ri4pRkWHH/GKmoKEvFAmgoggukaEkbcycS0vLlqU/TLl2MJk0iuAAAAGjLfF9asyaikhJX27c37NRl2LBAixYlNGeOr1gsRwUCAIBmZZVfqO6qWK/oxvVyjhxu0nrGdeXdc68SEyYrMWmKghtupKsCaCEILpAiXXDRo0eoQYOa/wq1TZscnTmTOgJgzhyPE1AAAIA26tQpSy++6GrpUldHjmQ+DioaNZo3z1dxcUJ33RXmsEIAANAsjJHz+WeXuyre2SHLa9p+p0G/HySDiomT5Y0ZK1PUKUvFAsgmggtcpaJC2rs39eRw+PD8zAFOtym3xJgoAACAtuiDD2yVlES1bFlE8XjmLz779g31zDOennjCU8+ejIMCAKBVKy9XdNuWmrDCOXyoScuZSORyV8XEyQpuupmuCqAVILjAVT74wJHvp/7xzseYqAsXkqMBvu8HPwg1cmR+9tsAAABAdiUS0ooVEZWURPXee+lHltbm3nt9FRd7mj7dV4QzGwAAWidj5Hz5haIb1ilatl7uO9tlJRJNWjK4tm/1ptpTkl0VnTpnqVgAzYWX97hKS9rf4s03I6qqSg1R5s/3ZGc+MQAAAAAt0LFjlpYudfWrX7k6eTLzF3eFhUbz53sqLvZ0yy2MgwIAoFW6eFHR7VuSYcXGDXK++bpJyxnHkTdy1OW9Km6+ha4KoJUjuMBV0gUXsZjRHXc0/0nhb36TfkzU/PmMiQIAAGiNjJHefddRSYmrN9+MpO30rc2AAaEWLUroscc8de2awyIBAED2GSPnqy8VLavuqti5XVY83qQlg959lJg0RYkJk+WNHSfTuUuWigXQEhBcoEYYSrt3pwYXd9wRNPtG2EePWtq2LbWW224LdNNNXFkHAADQmlRUSG+84aqkxNXHHzdsHNT48b4WL05o4sSArlsAAFqTigpFd2ytGQHlfH2wScsZx5E3YmRNWBHcehtdFUAbRnCBGp9/buvcuZaxv8Ubb0RkTGotCxZ4zV4LAAAAGmf/fku/+lVUL73k6rvvMn9joajI6LHHPC1alNB117HZNgAArYW9/yvFLnVV7Ngmq6qqSesFvXpX71UxWd7Y8TJdaLsE2guCC9RI120hSSNGNH+Hw2uvpY6JsiyjBx9kTBQAAEBLFQTSe+/ZWrs2onXrIvrss4Z1V9xwQ6BFizw9/LCnoqIcFQkAALKnqkrujm3JEVAb1ilyYH+TljO2LX/43cmuiomT5d96u2i5BNonggvUqG1j7hEjmrfj4tNP7bQjBO6/P1CfPlxxBwAA0JKUl0tvv50MKtavd3T6dMPeXLBto6lTfRUXexo9OmDiAwAALZz99cHqTbXXK7pti6zKyiatF/bspcSEScmwYux4ma7dslQpgNaM4AI10gUX110XqkeP5g0LXn89/dPyoYcYEwUAANASHDli1XRVbNvmKJFoeNrQrZvRk08m9PTTnvr35+IUAABarHhc7s7tipatV7RsnSJfftGk5Yxtyx82omYElH/7HXRVAEhBcAFJ0okTlg4cSP1Horn3twhD6fXXU8dEFRQYzZzJmCgAAIB8CEPpo49srVmTDCsausH2lW6/PdDixQnNm+erQ4csFgkAALLGPvRNTVAR3bpFVsXFJq0X9uihxPhJybBi/ESZbtdkqVIAbRXBBSTVvr9FcwcX777r6MiR1ABl2jRfnTo1aykAAADtWmWltHWrU9NZcfx446+EjESMZs/2VVyc0IgRIeOgAABoaRIJue/uvNxV8dm+Ji1nLEv+0GFKTKzeq+KOu+iqANAgBBeQVNfG3M0bXLz2Wvqn5IIFjIkCAADItePHLa1fH9G6dY42b46osrLxCUPHjkbjxvmaOtXX5MmBundnHBQAAC2J/e2RZFCxYZ3cLW/LvljepPXCa665oqtikkz37lmqFEB7RHABSdJ776Wm3t26GQ0ZEjZbDVVV0vLlqWOirrkm1PjxzRugAAAAtAfGSJ98Ytd0Vbz/fuNHQElSv36hpkxJhhX33RcoFstSoQAAoOk8T+7ud5Mba5etV+TT3zd9yTvvSnZVTJoi/86hktO01xIAcAnBBSQp7dV0I0YEzdrFt2FDROfPp9bx/7N37/FV1Xe+/99r7bV3riRACKAGRAURvMs9gNwF1FawHe2MfZzRsdgzjzlTO+c3M4/2nM5xZs60fXTOr9PT6Tm/nqHqqbUdbW3FWlFErgUBuSjeQNCqCCiXBAgJuey9Lr8/VkIS9k72be29k/B6Ph55JFl77bW+2N0ke73X5/O56y5b4fg8AwAAABloa5O2betsAXXkSHZ/8N18s3M+rLj2WtpAAQDQl5jHPmtv//SKwps3ymw8m9Xx3MGDFZ23QNH57VUVw4cHtFIA6I7gApKkGTMcvfVW91T8vvvy256JNlEAAAC5UV9vaN06P6zYuNHSuXOZpwvFxZ7mzPHDittuszViBC2gAADoM2xb1u5dKlq/VpF1a2W9+3bWh4zdcJOiCxYqumCx7FsmSRaXEwHkHj9pIEn6279t0/Hjhp57Lqxw2NPDD0e1ZImdt/OfOeNXXFzo8stdTZ6cv3ZVAAAAA4HnSR98YGrNGn9exa5dIblu5mHF8OGuFi/2g4rZsx2Vlga4WAAAkBXj+HFFNq7zKys2bZDZcCar47kVlYrOna/ogkWKzV8od8TIYBYKAGkguIAkadAgaeXKVv3gB62KRJT31ky/+11Y0Wj8m+kvfCFGuwEAAIAUxGLSzp2h9rDC0kcfZdcC6tprHS1e7LeAuvFGN68tRAEAQC8cR9ae3YpsWKvIulcUfmtv1oe0r73eH6q98DbFJk3J/4UhALgAwQW6KSsrzHlpEwUAAJC+hgZpwwZLL79saf16Sw0Nmd/xEYl4mjmzc15FTQ0toAAA6CuMkyfbqyrWKrJpg8zTp7M6nls+SLE58xRdeJui8xfKveTSYBYKAAEhuEDBHT5saPv2+JfizTc7GjuWN8wAAABdffSRobVr/aqK7dtDsu3Mw4qqKlcLF/phxbx5tsrLA1woAADInOPI2vu6IuvWKrLhFVl735DhZXeNxJ4wUdEFt/ktoKZMkyKRgBYLAMEjuEDBPfts4vJDqi0AAAAkx5F27w5p7dqQ1q61dOBAKKvjjR/fMVjb0eTJjkLZHQ4AAATEqK9XZNN6P6zYtF5mfX1Wx/NKyxS9da5fVbFgkdzLagJZJwDkA8EFCsrzEreJCoU83XVX/oaDAwAA9BWe11GRGtLWrZbWrQupvj7zAROhkKcZM5zzw7WvuIKKVgAA+gTXlfXWXj+oWP+KrNd3Z19VcfX4zqqKaTOkoqKAFgsA+UVwgYJ65x0z4V2Dc+Y4Gj6cN9UAAGDgc13p4EFT27eH9NprIe3YEdKnn2Y3Cbuy0tOCBf6sivnzbVVWBrRYAACQFfPTowpv3qjI5g2K/H6TzLq6rI7nlZYqOnuOovMX+VUVoy8PaKUAUFgEFyioX/+aNlEAAODiEotJb79tascOP6R47TVLp09nPqeiw5gxrhYvtrVkia2pUx2FE/+ZBQAA8shoalT41a0Kb96gyOaNst4/mPUx7avGtg/VXqTYjJlScXEAKwWAvoXgAgXjONKzz8a/BEtLPS1dSpsoAAAwMDQ3S6+/7ocU27eHtGdPSM3N2QcVpulpyhRHt93mt4EaN86Vkf1hAQBANmxb1ht7FNm80Q8q9uySYWd3jcMrLlZ01q2KLlik6PxFcq+4MqDFAkDfRXCBgtm6NaTjx+PbICxdaqusrAALAgAACMCZM9LOnaH2igpLb75pKhYLJlEoK/M0f74/q2LhQkdVVbTWBACgoDxPoY/+oPAmP6gIv7pF5tmGrA/rjLlCbQtvU3ThbYrNmCWVlASwWADoPwguUDA9tYn6oz+iTRQAAOg/jh0zzrd92rEjpP37TXlecKUPo0e7WrjQn1dRW+swYxMAgAIzTtUrsmVz+6yKjQod/iTrY3pFRYrVzvKrKhbeJufKsQGsFAD6L4ILFERzs7R6dfzLb9gwV7fe6hRgRQAAIFWuK/2v/xXRE0+EVV9v6NJLXY0a5WnUKFejR3saPdrV6NH+tmHDvAHVvsjzpI8+Ms5XU+zYEdLHH2c3SPtC11zjaPr0zo9LL6WqAgCAgmprU3jnDr+iYvNGWW/tleFl//vZHjtOsTnzFJ23QNFZc6TS0gAWCwADA8EFCmLtWktNTfFXMe6+25bFqxIAgD7tl7+09E//1Hnb/wcfhPTBB4n3LS31A43OYKMz3Bg1ytWQIerTwYbjSPv3m90qKk6cCC6oCIU83Xijq2nTHM2Y4Q/VHjo0sMMDAIBMeJ5C777TPqdig8KvbZfR0pL1Yd1hwxS9da6ic+YrdutcuZfVBLBYABiYuESMguipTdQXv0ibKAAA+rrVqxP/Hk+kudnQgQMhHTiQ+PHy8u6VGh0hR0fVRmVlQItOUTQq7d1rnq+m2LkzpLNng0tWios9TZ7saNo0v5pi0iRH5eWBHR4AAGTI/OxTv/XTpg2K/H6TzLqTWR/TKy5WbNoMRefMV3TOPDnXXieZwVZqAsBARXCBvKurM7RhQyhu+1VXubrxRrcAKwIAAOkYMSK439dNTYb27w9p//7Ej1dWdlRsxLehGj3azfqif1OTtHt3ZzXF66+H1NoaXFBRWelp2rSOoMLWjTe6ikQCOzwAAMhUU5Mi27eeDyusgz3cZZGm2PU3+u2f5sxTbOp0hmoDQIYILpB3v/2tJduOvyDwxS/G+nSrCAAA4Hv44aheeCGs06dz/4u7ocFQQ0NI77wTf9ODJA0d2hlidLSjuvxy/+uaGldlZd33r6839NprnUHF22+bcpzg/h0jRriaMaOzomLCBJcbKwEA6AscR9be18/PqQjv3ikjln3XB+eyGj+kmDNP0dlz5Q0bFsBiAQCG5wUwTagHJ0825urQ6Mduv71Uu3fHX3zYubNJY8YwfBIAgP6grs7QM89YevfdkD75xNDhw6Y+/dSQ5/WtuxCGDfMrNS65xNUHH5g6cCBxAJKpK65wNX26P59i2jRHY8YMrGHkAAD0Z+ZHH7bPqdio8Nbfy2w4k/Ux3fJBis2a3R5WzJdz1di+PbALAPqg6upBSfchuEBeffSRoWnT4ns6TJniaPXq5gKsCAAABCUalY4e9UOMTz4xdfiwoUOHTB0+7H997Fj/Lj0wDE8TJ/pBRcfHiBHcdAEAQF9hnD6l8JbN7WHFJoU++TjrY3qhkOxbJis6Z56ic+bLvmWSFE593hcAIF4qwQWtopBXv/lN4l/uX/gCQ7kBAOjvIhHpiis8XXGFI8mJe7y11Q82uoYZfsBh6tAhQ3V1fSvYCIc93XSTq+nTbU2f7mjqVCfvw8IBAEAv2toU3vVae/unDbLe3CsjgPtz7avGts+pmK/YzFnyKvgDAADyjYoL5I3nSTNmlOnDD7tflLAsT2+/fU5VVdyxCADAxay5WTpyxNQnn/iBRkfVhl/BYejUqdwGG6WlniZPdjRjhl9NcfPNjkpLc3pKAACQDs9TaP++9oqKDQrv2CajOfvuDW5VlaKz5yg2Z76ic+bJrRkVwGIBAD2h4gJ9yhtvmHGhhSQtWOAQWgAAAJWWSldf7erqq6VEFRtNTeoWZviVG51VGw0N6fWXHjrU1dSpTvuMCkfXXefS+QEAgD7GPH5M4U0b/KqK329S6MTxrI/pFRUpNnWGP6di7jzZ190gmX2r8hMALnYEF8ibntpEffGLtIkCAADJlZdLEye6mjhRShRsNDTofIjRMTDcr9zw52tUVHiaNKkzqBg3zuUaBQAAfc25c4ps36pw+1Bt6739gRw2dt0Nit061w8rptdKJSWBHBcAkBu0ikJe2LZ0ww1lcb2ry8s9vftuE38vAAAAAABwMWptVfiNPQpv26rwls0K73pNRiz7GxydSy/zQ4o58xSdPVdedXUAiwUABIFWUegz9u83Ew7cvPNOm9ACAAAAAICLRXOzwnt2+UHF9lcV3rNLRltb1od1y8oVmzW7PayYL2fsOMlIr40kAKDvILhAXnz8ceI+DHfcQZsoAAAAAAAGrKYmhXe9pvD2VxXZtlXWG3sCqajwQiHZN09SdM48RefMlz1pshhWBQADB8EF8uLw4cR3OYwd6+Z5JQAAAAAAIFeMxrMKv7Zd4W2vKrx9q6w398qw7UCObV95ld/6ac58xWbNlldRGchxAQB9D8EF8uLw4cQVF5ddlrMRKwAAAAAAIMeMM6cV3rH9fOsn6+03ZbjB3KToDh2q6Oy57WHFPLmjRgdyXABA30dwgbw4ciQ+uBg+3FVxcQEWAwAAAAAAMmLU1yu8Y5vC27cq8upWhfa9I8ML5qZEr7hYsSnTzg/Vtq+/UTIT3wgJABjYCC6QF598Et8qatQoqi0AAAAAAOjLjBMnFN7hz6cIb39V1v59gR3bKy1VbMo0xWpnKTpjluybb5GKigI7PgCg/yK4QM55XuKKi1GjmG8BAAAAAEBfYh77zG/71DGj4v2DgR3bLSuXPW26orWzFJsxU/ZNtzBQGwCQEMEFcq6hQWpsjK+4qKkhuAAAAAAAoJDMI4fPz6cIb9sq66MPAzu2W1Gp2PQZis2YpVjtTL/1k8WlKABAcvy2QM71NJibVlEAAAAAAOSR58k89LHC2ztbP4U+ORTY4d0hQxSbPlOx2pmK1c6SPfE6KRQK7PgAgIsHwQVyLlGbKIlWUQAAAAAA5JTnKfThB37bp46g4tOjgR3eHTZMsRmzFK2dqdiMWXKumcAwbQBAIAgukHOHD8e3iZKouAAAAAAAIFCep9DBA+0hhT+nInTieGCHd0aM9KspZsxSrHaWnHFXS0bi9/wAAGSD4AI511OrKGZcAAAAAACQBddVaP8+hbdvVWTbqwrveFVmXV1gh3cuq1Fsht/2KVY7U84VVxFUAADyguACOZeo4mLoUFdlZQVYDAAAAAAA/ZXjyHr3bb+iYturCr+2Tebp08EdfvQYxWpnKlo7S7EZM+WOvpygAgBQEGkHF+PHj1c4HJbR5RfXPffco7/7u78LdGEYOBLNuKBNFAAAAAAASdi2rLf2+iHF9q0Kv7ZD5tmG4A5/5VV+NUV7VYV7WU1gxwYAIBsZVVysWbNGNTX8MkNqErWKok0UAAAAAAAXiMVk7X1d4W1bFdm2VdbO12Seawrs8PbV49vnU8z0KypGXhLYsQEACBKtopBTTU3S6dPxZaVUXAAAAAAALnqtrQq/saez9dOenTKamwM7vD3h2s7WT9NnyquuDuzYAADkUkbBxfe//3298cYbampq0tKlS/WNb3xDZQwsQAI9DeYeNYqKCwAAAADARaa5WeE9u/ygYvurCu/ZJaOtLZBDe4Yh+9rr26spZik2vVZeVVUgxwYAIN/SDi5uuukm1dbW6nvf+54OHz6sr3/96/qHf/gH/fM//3Mu1od+7siRxEO8CC4AAAAAAANeU5PCO3cosv1VhbdtlbX3dRmxWCCH9kxT9g03trd+mqXYtOnyBg8J5NgAABSa4XleVj17Nm/erD//8z/X3r17FYlEuj128mRjVotD//f442F94xvFcds3bDin664jvAAAAAAADBzG2QaFX9t+fpi29eZeGY4TyLE9y5J9481+SFE7U7Gp0+UNqgjk2AAA5FN19aCk+2Q946KmpkaO46i+vl6XXMJQJ3RHqygAAAAAwEBlnKpXeMd2hbf7Myqsd9+W4QbzfteLRGTfPEnRjtZPU6ZJtOkGAFwk0gou9u3bp+eff17f+MY3zm/7wx/+oEgkouHDhwe+OPR/iVpFVVR4qqwswGIAAAAAAMiCcfKkwjteVaR9mLa1/93Aju0VFys2aYpiM2b6VRWTpkglJYEdHwCA/iSt4KKqqkq//OUvNXToUN1///06evSofvjDH+ree+9VKBTK1RrRjyWquKDaAgAAAADQH5jHPvMHaW97VeEdr8o6eCCwY3ulpYpNmeaHFDNmKnbzJKmoKLDjAwDQn6UVXIwYMUIrV67U97//ff34xz9WJBLR8uXL9Vd/9Ve5Wh/6ucOH4ysuCC4AAAAAAH2ReeSwH1R0DNP+6MPAju2WD1Js2vT2YdozZd94sxQOB3Z8AAAGkrRnXEyZMkVPP/10LtaCAaalRTp5Mr7ioqYmq3nwAAAAAADEsfa+rqJnnta5f/iOZKVwucPzZH78kSLtIUV4+6sKHf4ksPW4gwcrNr3WDypm1Mq+7obU1gUAALIfzg305OjR+GoLiYoLAAAAAECwIi88r4q/WCH7hpuknlpZe55Cf/igvfVTe1Dx2aeBrcGtqlJs+kzFamcqOmOWnInXSmb8zXwAACA5ggvkzCefJP4DjYoLAAAAAEAgPE8lP/qfKv+nR9S67G41/vDHktF+E53rKnTgPT+k2LFNkW1bZZ48EdipneEjFKud2V5RMVPO+Gs6zw0AALJCcIGcOXIkcXAxejQVFwAAAACALEWjKv/bv1LJvz+pc//5b9T8199UaP8+RbZ3DtM2T50K7HTOpZf5Q7Rr/RkVzpVjCSoAAMgRggvkzJEjif+Ao+ICAAAAAJAN48xpVTzwZYVf267WZV+Q9e47qppwpcyGM4Gdwxk9pr3t00zFZsyUe/kYggoAAPKE4AI5k6hVVGmpp6FDCS4AAAOHaR6RYZyS646U5w2TRC9rAAByIhaTtfd1RVY/r9KfPiY1t8iQp+LnfhPI4e0rr/KrKdqrKtzLagI5LgAASB/BBXImUcXFqFEuN6gAAAaU4uInVFb2PUnS6dOvyLan9bq/aX4q1x0qqTgPqwMAoB9ra1P49d3tg7S3Kbz7NRnNzYEd3h5/zflh2rEZM+WOvCSwYwMAgOwQXCBnDh+Ov+N01CiqLQAAA4tpHj//teuOSLr/kCFTZZpn5bqD5boj5boj2j9Gtn8M7/a151VKIvUHAAxknkzzU5nm+zpx4n2d+mCXNqy8WadXW/ob53sarOwHanuGIWfCtYp2DNOeXiuvujqAtQMAgFwguEBORKPSsWPxF1lqahjMDQAYWEzz2PmvkwcXzTLNs+3POyPTPCPpvV6f4XnFFwQc3UMO254g1x2d5b8CAIB8OCfL+kCh0PvnPwzjfZnmBwqHz0mShgyRNF5as/Maff/5R/QrfVFAxd8GAAAgAElEQVT7NFHlOpfWmTzTlH39jX7bpxkzFZs+Q96QoTn4NwEAgFwguEBOHD1qyPMStYqi4gIAMLB0VFy4bqWkkiT7Huv18UQMo1Wh0McKhT5O+Pi5c3+t5ub/1usxQqF3ZRhN50MP2lQBAHLHlWkePR9MWNb7XYKKIykfZfz4A5KkwxqtX+pePajHe93fM03ZN9/iV1PUzlRs6nR5FZVZ/UsAAEDhEFwgJ44cSTyYdNQoKi4AAANLZ3CRvE1U17ZSQUnlvKWl31dx8a+7PGdwl5ZUIxK0rPK/9rzBok0VACA5T4MGfVWh0D5Z1gcyjOznUHQEF5IUUzj+jKYpr7RMRkuzDMeRIhF5kSLJNCXHlWJ21msAAACFQ3CBnDh8OPFFDlpFAQAGmqamH8o0P5PnxV9UuVBugouRaZ+3s03VwV6f53lFXeZuDJfrDpPnVcm2x6qt7cvZLBsA0C+4Ms0j8rwh8rxBvexnyLL2yLLeD+zMfnDhabDO6B79Sl5xsWKTpvhtn2pnKTZpilRSIrW1yXr7TYV37VR412sqevoXKv3Xf5EkNT/8/+jcf30ksDUBAID8IbhATiQazC3RKgoAMPBEo4tT3tdxJqqp6b/LNI+1fxzv8nE2o/OnVumRfosqSTKMNoVChxQKHeq2PRabmjS4sKztKi39/+S6VXLdofK8qvavq7p9LZWJqg4AKCzDaOw2dyIU+kCWdVCh0B9kGC1qaPi5otHP93qMWGxcoMFFY+Mg/cn4l/Q3cw7KvPMp1d08SSoqit+xqEj25KmyJ09Vy5//J8nzZB7+ROFdr8kZd3Vg6wEAAPlFcIGcSNQqqqjIU3U1wQUA4OLlOFerpaWniyjN7WHGiS7Bhv91KNQZchjGSRlG5+/TQrSo8gOH3lnWQRUV/Tbpfn5VR9cwI3HI4XlDZdvjxXwOAMiUI9M83D534qBCoa5Dsj/r9ZmWdVDRaPz248cNrV8f0rp1lhYsmKivf/3FtFbU2lqkgwev1oED43XgwHgdP361hg4dqwkTrtC0aeX6n1skabZi6RzUMOSOvlxtoy9Pay0AAKBvIbhATiRqFVVT48lMXIgBAABUKte9Uq57ZZL9bJnmyfMVG657WZL9mzOu5uhJKsGFYdSndCy/quNTSZ8m3ffUqT1ynHG97lNc/IRct6JL4OGHIVIkpfUAQP9ny7L2JhiO/QcZRltGRwyF/EoKx5HeeMPUunWW1q2z9NZbofP7VFdP6PH5R49eqgMHxuu99645H1IcODBeR4+O0qRJ0sKFjhYutDVhgiuDIjwAACCCC+RIoooL5lsAABAES657iVz3khT3D+vMmecTVHN0bVPVkNYKPC95cGGaqQUX6fADiN7ENGjQX/bw3Ap53tCE7aq6VnW4rt/H3fMq5HnlkkIJjwcAfZetwYMXdKvOy1ZDwwf6i78o1saNIZ06lfhutHffvVZvvnlDXDhx8ODVamysOL/fsGGu5s939F/+i625c1s0eHBgywQAAAMIwQUCZ9vS0aPxt8mMHk1wAQBA/oUVi81Nsk9ze4CRKNjo+Lpeplknw2hLqeIi6ODC80x5Xu9XtwzjdC/rOSvprEKhj9M6b1PTP6ql5eu97hMOb5Bpftol8Bgkz6uU5w2S61ZIKhFzPACkx5PU1j574qP2ygm/tVNT07flur21QSqW616e9s+73kQi7+s3v7HU28+ynTun6aab3kz42E03+RUVCxfauukml0p8AACQFMEFAnfsmCHHSdwqCgAA9EWlct0r5LpXJNnPk9Sc0hE9r1SOM0KmWS/DsLNeoecNUbLqh1xUeXheSdJ9SkoeV1HR870cw+oSalTIdbsGHB3bOr933WrFYguC/GcAKJg2RSJrZRiNMoymLh+NMs3OrxN/Tvyzs7X1PkWjvc9vsO1xWQUX586VdquaeO+9a2QYnjwvtRC2osLTvHm2FiywNX++o+HDeS8IAADSQ3CBwB0+nPj2mVGjqLgAACBTL75o6cknwyou9nTrrY7uuSemsrJ8r8KQlNpJm5r+RdK/SPJkGGdlGPXtVRv17V+f6vJ1vQzjVJfHT8kwuv/dUIgqD0nyvIqk+xhG7zNEDMNurwbpuSKkK9u+UqdP7+11H8t6U2Vl3+oSdnSGIF1DEdetvKASZJAkbnUGfJ6klguChMaEIUPir5t05szLkkp7PINhtKiy8r5AV+3Pm1ja6z7+PKBXkh7rzJlRev/98dq5c7z27ZvQZfbEZfK89H5WTJjgaMECW4sWOZo82VE4nNbTAQAAuiG4QOASDeaWqLgAACBTL78c0v33d975v3p1WN/5TpG+/OWY/uzPoho1qi//jjXa2yZVpjB4vIMrwzjTLdBIpdVSqgPB0xFEcJGLc5rmp4pENmd0fD/kKJdUJM8rkecVSypSY+MP5Tg9D9eVpOLin0mKtT+nWJ5XLM8rklQizyu6YHtJ+2PF4m0HguFJshNWJ3jeUNn2zb0+u7j4Zyop+dEFIUR2N1cZRqM8r+fgwg8Lg9UxKLs3jnN1lzWUybbHKRodqw8/vEbbtl2j3/52gjZvHq/m5swT8NJST7Nn+2HFwoU27/cAAECgeAeBwPVUccGMCwAAMvP00/G3rTY0GPrf/zuiH/84rNtvt/XQQzFNm+bIGBCjFEx53lA5TrJh3N1Fowt16tTObpUcXSs8um871T73onepXHQMPrjI7TlNs1FSY4JjtiV9blnZ38s069I+p98uyw9IOgONErW1LVFz83/r9bmW9ZrC4e1dQpGi9hZe3YOXrkGJH5z4+zNfJBWOpKgMIyop1v45KsOIddl+4fc97RdTW9tdct0xvZ6xvPw/t7cyslM6Zuf2xBfHW1uXq7HxiV7PaRhnZVkHUvtPkiLTbJTjjOhlj5A8r1SGkVqbvVSkElxEo4t15szzOnx4vF56aZTWrw9ry5aQWlqy+//DmDGuFi3yW0DV1joqLs7qcAAAAD0iuEDgjhyJ/2PYsjyNGMEdOAAAZMLtJft3XUMvvBDWCy+EdcMNjlasiGrZMltFRflbX99RJse5Ro6T6v7RboGG/7mh/S7sszKMs3Kc3vvIS/4d10FKrcoj2HP6503lCmTycCMRv11Wk6Smbttt+4akz41ENqus7J8yOm8Hvy+/KT/EMFRX95mkSI/7G8ZJDR06TX6I1vW5Zrfj+BVFXR/rvk/Xx1paHlJbW+8tg0pL/1+Fw1uSHLvzc+fjhvxKpe4X/V13pBobf9rrOcPh9Ro8eHmv+6TLcSYoGh2T5LzbZFn7AjunH8j1LhfVD/7rOtl5ywMLLlx3kHprTRWLSTt3hrRu3ZVav36c3nuv99lAyYTDnmbMcLRokV9VcdVVvKcDAAD5QXCBwCWquLj0Uk+h7P5mBgDgovXggzG98ool2+79Ttm33grpL/+yRP/4j67uvz+mP/3TGANRexWR646UNDKNsCPemTPrZBhnZZpnzwceHeGHaTbKMLqGIY0J9u0+gDe1iotcBBfJ0y7DaA34nMmHn0vZn9O/S7/r/8i99+43DCejypLetLWdTLpPKPSuIpGNgZ3Tca5IYa+eA5zMxZLu4XnBnjfVACFoqZzXdctlmicuWIshzyu/4GNQwq9dt1qOM1aOc7Vcd4QurCI6ftzQhg0hrVtnadMmS42N2VVVXHKJq4ULbS1c6Gj2bFvlwf9nAwAASIrgAoFLFFzQJgoAgMzdequjZ59t0d//fZFefz35nQAnT5r6H/+jSD/8YUTLltl66KGobriB38W54rp+VUZm4YcnqbV9MLAfZKQSXHhehWx7wgWBSLYhVbKKC6f9Tv7gpBaWZFblkeSoSR7Pxf9fUhl0HHTQmP8AwRdNYZ9gJzfnI7jwW5BdGCwkr1RqbHxcfoWM/zzXLZdfNZHe8OsOjiPt3Wtq3TpL69ZZevPN7O4QM01PU6Y4WrjQ0cKFtiZOdAdI20EAANCfEVwgUK4rHT0a/1cug9oAAMjO9OmO1qxp1u7dpn7yk4ief96S4/R+ZSkaNfSrX4X1q1+FNX26rRUrYlq61JbFX4B9iCF/sHWJHGd4ys9qbX1Qra0Pdtnidhk23FnN4Ych8dukFhlG6/kPqbXXAcPtZ03/n5dU8ou+htGSg/Mmu2Cci79dU7kSHOx5/dZRyQQbIKR63kJUXDjOpYpG5yasbHDdRBUPXb8vV6b/rWz7loye11VDg7Rhgx9UbNgQUn19ZqFHh6oqV/Pn+0HF3Lm2hgzJeokAAACB4m0rAnXihKFoNP5N2ahR3OUJAEAQJk92NXlyqx55xND//b9hPflkWKdOJb+AtWOHpR07LNXUuHrwwajuuy+mwYPzsGDkiSnPq2ifj3FZjs5Rovr6d84HHd2DjzYZRkt7dUT3QKT7Pl23t8lxrkrhvAOl4iJ5cGEYQZ83/wGCL3mlh+uOkm2PkxRpX0P4gs8ReV74gsc7vi+LCxVcN/mVd8e5Xg0Nz2f1L8uno0cNrVlj6aWXLG3bFkraLjCZm25ytGCBP6vipptcWvkCAIA+zfA8L2e3wp88GXzvXfRtu3aZuuOOsrjt//qvLfrSl+wEzwAAANloaZF+85uwVq4MpzWEtbTU0z33xLRiRUzjxnGDAfouv2KkSfEhSEuvoUnHY34I4bWHAp4kT01N/5LknPUqL//b9v3d9m1ul++7fu1/9lt1dZ7jwn1aWx9SW9vdvZ63rOybikQ2JHx+1/V3f8yVYbjyPEsXXuz3vAo1NLyQ5N96QqWlP4x7bu8BQu/bXXewpFTml6Arz5Pee8/USy/5YUW2LaAGDfI0d66tRYtszZvnaMQIquABAEDfUF2dwlw/ggsE6dlnLf3H/xj/JmXVqmbNnJnF1EsAANArz5O2bAnpJz+JaO3akDwv9Ttz583z52DMm+fIzK77CAAgDY4j7doV0osv+mHFoUPZ/RC+5hpHCxY4WrTI1pQpjsLBdwIDAADIWirBBa2iEKgjRxL/oV1Tw52cAADkkmH4Q7xvvbVFH35o6LHHInrqqbCampIHGBs3Wtq40dLYsY6+8pWY7rknpvLsZtgCAHrQ0iJt3hzSSy+FtXZtdvMqSko8zZ7d2QJq1CiqKgAAwMBAxQUC9dd/XaSf/ax7n1zT9HT4cBN3+wAAkGeNjdJTT4X16KMRffxx6hfGKio83XdfTA8+GNXo0VwEA4BsnTolrV3rV1Vs3mypuTnzeRWXX+5q0SI/qKitdVScfMY9AABAn0KrKOTdH/9xidav717Ic9llrt5441yBVgQAABxHeuUVv43Uli2pF9yapqelS2099FBM06c7MrKbCwsAF5VDhzqHa+/YEZLrZv5DdNIkR0uX2lqyxNa4cS4/jwEAQL9GcIG8mzu3VPv2dR8iN2WKo9Wrmwu0IgAA0NW+faYefTSsX/86rNbW1K98XX+9oxUrolq+3FZRUQ4XCAD9lOdJ77xj6sUXLa1ZY+nddzMfrh2J+C2gli61tXixzWBtAAAwoBBcIO8mTCiL69H6+c/H9OijrQVaEQAASKS+3tCTT4b1+ONhHTuWehupYcNc/emfxnT//TEupAG46MVi0o4dofOVFT3N/EtFRYWnhQttLV1qa/58W4OSv58HAADolwgukFfRqFRTE/+iW7Eiqm9/u60AKwIAAMnEYtILL1hauTKiPXtSvzs4HPa0bJmthx6K6sYb3RyuEAD6lqYmaeNGv6rilVcsnTmTed+mSy5xtWSJH1bU1jqKRJI/BwAAoL8juEBeHTli6JZbyuO2f+tbbfra16IFWBEAAEjHnj2mfvKTiJ5/3pJtp34hbupUW1/9akxLl9qyUh+hAQD9xokThtau9cOKzZtDamvLPKyYMME5H1bceCPzKgAAwMUnleCCt5YIzLFjif/iHjGCuzABAOgPJk1yNWlSqx55xNBPfxrWE0+EdepU8rYnO3da2rnTUk2NqwceiOnLX45qyJA8LBgAcujDDw299JLfAmrXrpA8L7OEwTA8TZvmhxVLlti68kra7AEAACRDxQUCs3q1pQceKInb/swzzZozxynAigAAQDZaWqRnnw1r5cqw9u9PvY1UaamnP/qjmFasiOnqq7mBAUD/4LrS3r3m+XkVBw5kPly7uNjT3Ll+ULFokaPqasIKAACADrSKQl499lhY3/xmcdz2LVvOafx4LloAANBfeZ706qshrVwZ1ssvW2nddTx3rq2vfjWqefMcmZnPrAWAnIhG/Z9vL73kt4E6dizzH1RDhnhatMhvATV3rq2ysgAXCgAAMIDQKgp5deIEraIAABiIDEOaNcvRrFmOPvrI0OOPR/SLX4TV1JQ8wNi0ydKmTZauusrVV74S1b33xlQePxILAPKmsVFav96vqli3zlJjY+ZDJkaNcrV0qR9WTJvmMOcHAAAgIFRcIDAPP1ysp54Kd9tWXOzp0KEmBs4BADDANDZKTz8d1k9+EtHHH6d+h3JFhac/+ZOYHnwwqssvp3UKgPw4dsw43wJq69aQYrHM36Bcd51zPqy49lqGawMAAKSLVlHIq3vvLdHGjd1vMRo92tXu3ecKtCIAAJBrriutWxfSv/1bRFu2pH6rsWl6WrLE1ooVMdXWOlz4AxAoz5Pef988P1z79dczn1cRCnmaMcMPKxYvtjV6NKErAABANggukFdz55Zq377ubwimTrX1wgstBVoRAADIp/37TT36aFjPPBNWa2vqScSoUa6WLYtp+XLuXgaQOceR9uwx9dJLYb30kqUPP8x8XkVpqad58/yqikWLbA0ZEuBCAQAALnIEF8irCRPKVF/f/c3B5z8f06OPthZoRQAAoBDq6w39/OdhPf54WJ99lt6Fw/HjHS1fbmvZspiuvJK7mgH0rrVV2rKlc7h2XV3mYcWwYa4WL/bDitmzHZWUBLhQAAAAnEdwgbyJRqWamvgX3IoVUX37220FWBEAACi0WExavdrSypUR7d6dfpuWm292tHx5TMuW2Ro5khADgO/MGemVV/wWUBs2WGpuzrxMa8wYV7ff7ocVkyc7CmXeUQoAAAApIrhA3hw5YuiWW8rjtn/rW2362teiBVgRAADoS15/3dTKlRE9/7wl207vIqNheKqt9Ssx7rwzpqFDc7RIAH3WkSOdw7W3bQvJcTIPK26+2Z9XsWSJrfHjaU8HAACQbwQXyJs9e0wtXVoWt/1HP2rRvffaBVgRAADoi44dM/TTn4b1xBPhuBaTqbAsT/Pm+ZUYS5bYKo+/bwLAAOB50r59ncO1334781IIy/I0a5ajJUv8sOLSS6ngAgAAKCSCC+TN6tWWHnggvgnsM880a84cpwArAgAAfVlbm7R+vaVVqyytXWuppSX9W55LSjwtXmxr+XJb8+fbKirKwUIB5I1tSzt3hs6HFZ98kvm8ivJyTwsX+kHFggW2KisDXCgAAACykkpwYeVhHbgIHDuW+GLDiBHczQQAAOIVFUm3327r9tttNTVJa9ZYevbZsDZtCqXcSqqlxdBzz4X13HNhVVZ6uuOOmJYvtzVrFn3qgf6iuVnatMkPKl55JaRTpzIPK0aMcLVkiT+vYuZMhzATAACgH6PiAoH47ncj+sEP4t8ZHDzYqMGDC7AgAADQL506Jf3ud2GtWmVp+/aQPC/9Sozqald33WVr+fKYJk+mfz3Q19TVGXrlFb+yYtMmS62tmf+f9OqrO1tA3XKLKzPz3AMAAAB5Qqso5M3DDxfrqafC3bYVF3s6dKiJiwUAACAjn31m6LnnLK1aFdbevZmVUIwe7WrZspjuvtvWxIluwCsEkKqPPuocrr1zZ0ium9mbBMPwNHlyR2VFTGPHUuENAADQ3xBcIG++9KUSbdjQvfPY6NGudu8+V6AVAQCAgeTDDw2tWuVXYhw8mFmIcc01jpYvt7VsWUxXXMHFTiCXPE96663O4dr792fev62oyNOtt/qVFbfdZtOOFgAAoJ8juEDezJ1bqn37ur8ZmTrV1gsvtBRoRQAAYCDyPOndd02tWuVXYhw5kllfmFtucbR8eUx33WVr5EguggJBiMWkbdv8FlBr1lj69NPM+zZVVnpatMifVzFvnq3y8gAXCgAAgIIiuEDeTJhQpvr67m9MPve5mB57rLVAKwIAAAOd60q7doW0apWl55+3VFeX/kVSw/A0c6ZfiXHnnTENGZKDhQIDWFOTtGGDpRdftLRunaWzZzPvE3vZZZ3DtWfMcBQOJ38OAAAA+h+CC+RFNCrV1MS/2FasiOrb324rwIoAAMDFxralLVtCWrUqrNWrLTU2pn/xNBz2NG+eX4mxeDF3eAM9OX7c0Msv+y2gtmwJKRrNPKyYONFvAXX77bauv95lPh4AAMBFgOACeXHkiKFbbol/Z/+tb7Xpa1+LFmBFAADgYtbaKq1fb2nVKktr11pqbU3/SmhpqafFi20tXx7TvHmOiopysFCgH3n//c55FXv2ZD6vwjQ9TZ/uhxVLltgaM4ZWbQAAABebVIILK+keQBLHjye+GDBihJvnlQAAAEjFxdIdd9i64w5bTU3Siy/68zA2bw7JtlMLMZqbO4aBh1VZ6enOO2NavtzWzJmOQplfswX6DdeV9uwxtWaNH1Z88EHmL/ySEk9z5/otoBYtclRVRVgBAACA3lFxgaytXm3pgQdK4rY/80yz5sxxCrAiAACAePX1hn73O78SY/v2zO7fGT7c1V13+ZUYkybR1gYDS2urtHWrP1z75ZctnTiR+XDtoUNdLV7sV1bMmWOrtDTAhQIAAKBfo1UU8uKxx8L65jeL47b//vfndM01VF0AAIC+59NPDT33nF+J8eabmd1JPnq0q+XLY7r7blsTJvA3D/qnM2ekdessrVljaf16S+fOZZ7GXX65e35exZQpjizq+wEAAJAAwQXy4rvfjegHP4hv/HzwYKMGDy7AggAAANLwhz90tIWy9P77mYUYEyY4Wr7c1rJlMXr2o887etQ43wJq27bUW6glcuONflXF0qV+gEcVEgAAAJIhuEBePPxwsZ56KtxtW1GRp08+aeKNCwAA6Dc8T3rnHVOrVvmVGEePZtYm5/rrHdXUuBoyxFNlpdo/exoyxNPgwd0/KiokM/NuPEBKPE/av98frr1mjZVxlZEkWZan2lpHS5faWrzYVk0NQR0AAADSQ3CBvPjSl0q0YUP3OvDRo13t3n2uQCsCAADIjutKO3eGtGqVpd/9zlJdXW7SBdP0w42ego3Bg72EAUhlpaeS+BFjwHmO47+GX3zRDysOHcr8NVxW5mnBAltLlthauNCmqhoAAABZIbhAXsydW6p9+7rftTV1qq0XXmgp0IoAAACCY9vS738f0qpVYb34oqXGxr5RUlpcnCjoUILQo/vnigoplPkN98iS6/pDsNvapNZWQ62t/ufu30ttbYZaWvzPHd93fazjed337TzW8eOmzpzJ/LVaXe2ebwE1a5aj4viRdgAAAEBGCC6QFxMmlKm+vvsdXJ/7XEyPPdZaoBUBAADkRmurP8h41SpLr7xiqbW1b4QY6TAMP7xIFnBcGIKUlnoDsg2obXeEBomCAON8yNDScmG4kPh5Fz524bGi0b77H/Gqq1wtXRrT0qW2Jk1yaWMGAACAnEgluLCS7gH0IhpVXGghSSNH0usWAAAMPMXF0p132rrzTluNjdKLL/rzMDZvDslx+u4F6a48z1BDg9TQYOjQoUKvBoU2aZI/r2LpUlvjxrmFXg4AAAAgieACWTpxIvEb9BEjCC4AAMDANmiQdO+9tu6911ZdnaHf/c7SunWWjhwxdOaMoYYGQ83N/SPMwMUjEvE0e7ajJUv8mRX83Q4AAIC+iOACWTl+vKfggru1AADAxWPYME8PPBDTAw/Eum1va5POnPGDjNOn/UoH/7P/fcdjHUFH131cl9ADwaio8LRwoV9VMX++rUHJK/MBAACAgiK4QFaOHUvc+JY7twAAAKSiIv/vonT/NnJdqalJ3YKNzvCj9xDk3DkCj4HOMDyVlPivr+JiT0VFUkmJ1+374mJpzBhXCxbYqq11FIkUetUAAABA6ggukJWeKi6YcQEAAJA505QqKvw75UePTu/vqmjUn1/hBx3qEnQYPVR7dAYktk3okQ7T9FRc3DU0kIqKOkIF74LvE4cM/j49P9ZxDP9r/3M4rAE5KB0AAADoQHCBrPQcXNAqCgAAoBAiEam62lN1dXqBh+dJ584pQWWHoVOnDEWjOVpwgZlm15CgM0i4sIKh4/uuX4fDhV49AAAAMDARXCAriVpFFRV5qqwswGIAAACQMcOQysul8nJPNTVUzwIAAAAonMQDCoAUJaq4GDHCo3QdAAAAAAAAAJARggtk5dixxMEFAAAAAAAAAACZILhAVk6ciA8umG8BAAAAAAAAAMgUwQUyFo1KdXXxL6GRI6m4AAAAAAAAAABkhuACGUtUbSHRKgoAAAAAAAAAkDmCC2Qs0WBuSRoxglZRAAAAAAAAAIDMEFwgY8eOJX75UHEBAAAAAAAAAMgUwQUy1lPFBTMuAAAAAAAAAACZIrhAxmgVBQAAAAAAAAAIGsEFMpaoVVRRkafBgwuwGAAAAAAAAADAgEBwgYwlqrgYMcKTkbgQAwAAAAAAAACApAgukLFjxxIHFwAAAAAAAAAAZIrgAhk7cSI+uBg5kvkWAAAAAAAAAIDMEVwgI9GoVFcX//Kh4gIAAAAAAAAAkA2CC2Skri7xIAuCCwAAAAAAAABANggukJGegovhw2kVBQAAAAAAAADIHMEFMtJTcFFVRcUFAAAAAAAAACBzBBfIyMmTiYOLYcMILgAAAAAAAAAAmSO4QEbq6wkuAAAAAAAAAADBI7hARmgVBQAAAAAAAADIBYILZKSuLv6lU1rqqaysAIsBAAAAAAAAAAwYBBfISKKKC9pEAQAAAAAAAACyRXCBjCSacUFwAQAAAAAAAADIFsEFMkLFBQAAAAAAAAAgFwgukDbP6ym4cKE1vkMAACAASURBVAuwGgAAAAAAAADAQEJwgbSdOye1tMQHF1VVVFwAAAAAAAAAALJDcIG0Jaq2kGgVBQAAAAAAAADIHsEF0pZoMLdEcAEAAAAAAAAAyB7BBdJGxQUAAAAAAAAAIFcILpC2urrELxuCCwAAAAAAAABAtggukDYqLgAAAAAAAAAAuUJwgbT1FFxUVRFcAAAAAAAAAACyQ3CBtCUKLiorPUUiBVgMAAAAAAAAAGBAIbhA2hIFF7SJAgAAAAAAAAAEgeACaUsUXFRVuQVYCQAAAAAAAABgoCG4QNqouAAAAAAAAAAA5ArBBdLieVJ9PcEFAAAAAAAAACA3CC6QloYGybYJLgAAAAAAAAAAuUFwgbQkahMlEVwAAAAAAAAAAIJBcIG01NUlfskQXAAAAAAAAAAAgkBwgbRQcQEAAAAAAAAAyCWCC6SF4AIAAAAAAAAAkEsEF0gLwQUAAAAAAAAAIJcILpCWRMGFYXgaMoTgAgAAAAAAAACQPYILpCVRcFFV5SkUKsBiAAAAAAAAAAADDsEF0lJfHx9c0CYKAAAAAAAAABAUggukJVHFBcEFAAAAAAAAACAoBBdIS0+togAAAAAAAAAACALBBVLmONKpU1RcAAAAAAAAAAByh+ACKTt1ypDnEVwAAAAAAAAAAHKH4AIpS9QmSiK4AAAAAAAAAAAEh+ACKSO4AAAAAAAAAADkGsEFUtZTcMFwbgAAAAAAAABAUAgukLKegovqajfPKwEAAAAAAAAADFQEF0hZfT2togAAAAAAAAAAuUVwgZSdPBkfXITDnioqCrAYAAAAAAAAAMCARHCBlCVqFVVV5clIXIgBAAAAAAAAAEDaCC6Qsrq6+JcLbaIAAAAAAAAAAEEiuEDKEs24ILgAAAAAAAAAAASJ4AIpS9QqiuACAAAAAAAAABAkggukpK1NOnuW4AIAAAAAAAAAkFsEF0hJojZREsEFAAAAAAAAACBYBBdISaI2UZI0bJib55UAAAAAAAAAAAYyggukpKfgoqqKigsAAAAAAAAAQHAILpCSnoKL6mqCCwAAAAAAAABAcAgukJKeW0URXAAAAAAAAAAAgkNwgZTQKgoAAAAAAAAAkA8EF0hJXV38S6W01FNZWQEWAwAAAAAAAAAYsAgukJJEFRe0iQIAAAAAAAAABI3gAikhuAAAAAAAAAAA5APBBVJSX09wAQAAAAAAAADIPYILJOV5PVVcuAVYDQAAAAAAAABgICO4QFLnzkktLVRcAAAAAAAAAAByj+ACSSWqtpAILgAAAAAAAAAAwSO4QFI9BRdVVQQXAAAAAAAAAIBgEVwgKSouAAAAAAAAAAD5QnCBpOrqEr9MCC4AAAAAAAAAAEEjuEBS9fWJKy6qqwkuAAAAAAAAAADBIrhAUj21iho6lOACAAAAAAAAABAsggskdfJkfHAxeLCnSKQAiwEAAAAAAAAADGgEF0gqUcXFsGFuAVYCAAAAAAAAABjoCC6QVOLggjZRAAAAAAAAAIDgEVwgqUTBRVUVwQUAAAAAAAAAIHgEF+iV60r19VRcAAAAAAAAAADyg+ACvTpzRnIcggsAAAAAAAAAQH4QXKBX9fWJXyIEFwAAAAAAAACAXCC4QK8SzbeQpOpqggsAAAAAAAAAQPAILtCrnoILKi4AAAAAAAAAALlAcIFenTxJcAEAAAAAAAAAyB+CC/Sq54oLN88rAQAAAAAAAABcDAgu0KtEwUUo5Gnw4AIsBgAAAAAAAAAw4BFcoFeJgouhQz2ZvHIAAAAAAAAAADlgFXoB6NsSBRfMt0C/4rqydu+SImHZE6+TIpFCrwgAAAAAAABALwgu0Kv6eoIL9F/G2QZVLrtD4XfekiTFJk9Vw8+eljdsWIFXBgAAAAAAAKAnNPxBr+rq4l8i1dUEF+gfyh75r+dDC0kK796pkkf/TwFXBAAAAAAAACAZggv0KBaTTp+m4gL9k3HypIqfeTpuu7XvnQKsBgAAAAAAAECqCC7Qo1On4kMLieAC/UPJz38qIxqN2+6Mn1CA1QAAAAAAAABIFcEFenTyZOLgoqqK4AJ9XCym4p8+lvCh1j++L8+LAQAAAAAAAJAOggv0qK6Oigv0T5GXXlDos0/jtrctWCTnyrEFWBEAAAAAAACAVBFcoEc9BxdunlcCpKfk0X9LuL31K1/N80oAAAAAAAAApIvgAj2qr6fiAv1P6J23FdmxLW67feVVis5bWIAVAQAAAAAAAEgHwQV61FPFRXU1wQX6rpLHeqi2+LMVksmPPAAAAAAAAKCv4yoeepQouCgu9lRWVoDFACkwTp9S8W9+FbfdKy1T65cYyg0AAAAAAAD0BwQX6FFdXfzLY9gwT0biQgyg4Ip/8aSM1ta47a33/rG8isoCrAgAAAAAAABAuggu0KNEFRfMt0Cf5Tgq+emjCR9qeZCh3AAAAAAAAEB/QXCBHp08GR9cVFURXKBviqxdo9Anh+K2R2+dJ+fq8QVYEQAAAAAAAIBMEFygR1RcoD8peTTxUO6Wr1BtAQAAAAAAAPQnBBdIqLlZam4muED/EDrwniJbNsVtd0ZfruiixflfEAAAAAAAAICMEVwgofr6xBO4hw1z87wSILkeqy0eWCGFQnleDQAAAAAAAIBsEFwgoURtoiQqLtD3GA1nVPzMU3HbvZIStf7JlwuwIgAAAAAAAADZILhAQj0FF9XVBBfoW4r//ecympvjtrd+8UvyhgwtwIoAAAAAAAAAZIPgAgkNHZo4oBgzhlZR6EMcRyWPr0z4UMuDD+V5MQAAAAAAAACCQHCBhCZOdDVunNNt27Rptq68kooL9B2R9WsVOvRx3PbozNlyJl6b/wUBAAAAAAAAyBrBBRIqKZH+/d9bdM89MU2Y4Oi++6L6xS9aCr0soJuSn/yfhNtbHvxqnlcCAAAAAAAAICiG53kZ3UL/ne98R0888YQOHDjQ4z4nTzZmvDAA6E3o4AENnTUlbrtTM0qndr4pWVYBVgUAAAAAAACgN9XVg5Luk1HFxf79+/Xb3/42k6cCQCBKHvu3hNtb7v8KoQUAAAAAAADQj6UdXLiuq0ceeUT3339/DpYDAMkZZxtU/Mun4rZ7xcVq/fJ/KMCKAAAAAAAAAAQl7eDi6aefVlFRkT73uc/lYj0AkFTx07+Q0XwubnvrF+6RN7SqACsCAAAAAAAAEJS0+qnU1dXpRz/6kZ588slcrQcAeue6Kn5sZcKHGMoNAAAAAAAA9H9pVVx897vf1d13362xY8fmaj0A0KvIxnWyPvowbnt0eq2c664vwIoAAAAAAAAABCnliovt27frjTfe0AsvvJDL9QBAr4of7WEo91eotgAAAAAA/P/t3XuYXGWBJvC377l0dwi3RBHxgrAEUGAIGZGLDMyCIAECA+6CGEUlLDeBIAG56SqXQRydyBAHBC+wiGgYQkRkMSgwohB0JTAB0RGRDIGQ0CTd6XR3dZ39g4EBE5qEdHVVmt/vv/rOdypvnqe6nqrz1nc+AIaDtS4u5syZk6VLl2afffZJkhRFkSSZNGlSzj///Bx00EGVSQjwnxr+/fdp+en/XW28/y1vTe+HPlyFRAAAAADAYFvr4mLGjBk59dRTX368ePHiHHXUUbnlllsyZsyYioQDeKUR11y1xvFVU49LmpqGOA0AAAAAUAlrXVyMGTPmVQVFqVRKkowfP37wUwH8pc7OjLjh+tWGi+bmdB8zdejzAAAAAAAVsU6bc7/S2972tjz22GODmQXgNY34/g2pX7F8tfGeQw9PsdlmVUgEAAAAAFTCGy4uAIZMUWTkNf+8xkM25QYAAACA4UVxAdS8prt/lsbfrb7Cq++vJqa00y5VSAQAAAAAVIriAqh5I7/5jTWOW20BAAAAAMOP4gKoafX//oc0/+THq433bz4uPQcfWoVEAAAAAEAlKS6AmlW3YnnGfPyY1BXFasdWHfvxpLm5CqkAAAAAgEpSXAC1qVRK+6empnHhI6sdKhobs+pjn6hCKAAAAACg0hQXQO0pirSefWaa5925xsOrPnJ0yuPGD3EoAAAAAGAoKC6AmjNy1hUZ+e1vrvFYabsJ6fr8l4Y4EQAAAAAwVBQXQE1pvm1uRl/4uTUe6998XF64/qYUbe1DnAoAAAAAGCqKC6BmNP6/X6f9hOPWuBl3MXJkll93Y8pv27IKyQAAAACAoaK4AGpC/Z+fTPsxR6Wuu3u1Y0VdXZZf+c2UdtqlCskAAAAAgKGkuACqrvGBX2WjKR9Ow7PPrPF414VfSu+BHx7iVAAAAABANTRWOwDwJtbbm1GXX5JRX/tK6srlNU7p/thx6Z524hAHAwAAAACqRXEBVEXDY4+m7X99Kk0Lfvuac3r/Zr90XnxZUlc3hMkAAAAAgGpyqyhgaJXLGTnr6xm7354Dlhal7bbP8qu+lTTqVwEAAADgzcQVQWDI1D/157SdckKa7717wHl9u+6W5ddel6KtfYiSAQAAAAC1wooLqKKenuT+++vz4IP16eurdprB0fSzeRl9zpmvHiyKtNz4fzJ27/cPWFoUjY3pOuf8dMy5PeVx4yucFAAAAACoRVZcQBU89lh9rr++KTfd1JilS1/sDzfeuJzJk0uZMqWU3XbrT/2GWCv29KRt+qkp7fDel4fqnnsubWd+Ji0/mjPgqaVt/1tW/NNVKe34vkqnBAAAAABqWF1RFEWlnnzJkhWVemrY4HR1JXPmNOa665rzwAMNA87dYotyDjusL1OmlLL99uUNZm/qkbO+ntGfPy/P//yX6d9m2zTf8eO0nXZy6pc8+5rnFHV16T7+xHSdc34yYsQQpgUAAAAAhtpmm7W97hzFBVRQUSS//W19rruuKbNnN6Wzc90biG226c+UKaUcdlhf3vnOiv25rre6juez8W7vS8/kKem68H9n9PnnZOR13x7wnP63bZkVM2el7wN7DlFKAAAAAKCaFBdQJR0dyQ9/2JTrr2/Kww8PvLpiXeyyS3+mTOnLIYeUMm5cbZUYoz9/XkZee3WWX3lVWs87Jw1PPjHg/FUfOTqdX7wkRfuYoQkIAAAAAFSd4gKGUFEkv/xlQ7773abMnduYVasqd3+n+voie+zRn8MP78uBB5YypsrX/uv//GQ23v2vUnrvTmmcf3/qBnhbKW+ySVZ8+R/Te9DBQ5gQAAAAAKgFigsYAj09yezZjZk1qzkLF67b6ooRI4pMnlxKS0uRW29tSkfHupcdzc1F9tuvlMMPL2W//UoZOXKdn2K9tR99ZJrn3Zm6/tKA83r2/1BWXD4zxeabD1EyAAAAAKCWKC6ggpYtS7797eZ885tNefbZ+nU6d4cd+nPMMX05/PC+l1dL9PYmd93VkJtvbsrttzdm5cp1LzFaW4sceGApU6b0Za+9+tPYuM5PsW76+zP6vHMy8uorM1Da8ujWdH3p0qz6H8dkg9lpHAAAAAAYdIoLqIA//KEu3/hGc268sSnd3Wt/Eb6trciUKX356Ef78t73lgec29mZ/OQnjZk9uyl33dWQUmndL/Zvumk5kye/WGJMnFge9L6g/k9PpO2k49P8q/sGnNf717tnxcxZKW/1jsENAAAAAABscBQXMEiKIrnvvobMmtWUn/ykMUWx9i3AbruVcswxfTn44FJGj173f3vZsuTWW5sye3Zj7rvvjS2h2HLLcg47rC9TppQyYcLApcnrKoqMuOG6jP7cWanv6nztaU1NWXnSZ9L3gT3T8MQf0/DHf0/dCx3pOv8LKTYau34ZAAAAAIANkuIC1lNfX3LrrY258srm/Pa3a79/xSablHPkkaUcfXRfttlmPYuCV1i0qC7/8i8vrsRYsGDd9tN4yXbb9WfKlFIOPbQvW221bn/+dUuWpO2Mk9Ny+20DzitaWl6c39Pz4uP6+pTf9vaUJmyfFV/9eoqNN3lD2QEAAACADZviAt6g5cuT7363KVdf3ZxFi9Z+/4oJE/pzwgm9OfTQUv7z2n3F/O539Zk9+8US44kn1m2PjZfsumt/Dj+8L5Mnl7LZZqu/FRRF8txzdfn97+vzp1seygvfm5d3rnwkR+XGNKZ/9flJym/fKr377Jv+rd+T/ne9O/3vfHf6375V0tz8hjICAAAAAMOH4gLW0Z/+VJerr27Oddc1patr7W8Hte++pZxwQm/23LN/yPeeLorkN7+pz803N+XmmxvXeaPwJGloKLLXXv054IBSli+vy+OP1+cPf6jP739fn8bGpfnqVz+Tjo6NcvLJX0+S7JWfZ14+mFeu+eh/+1ZZfsVVKU3660H6nwEAAAAAw43iAtbS/Pn1mTWrOXPnNqZcXrvmoaWlyN/9XV+OP74v2247eLeDWh/9/cm//mtDbr65Mbfe2pTly9enRSlyxBE/yBVXnJjNN1+SJNlzz7tz7717Jkn+JYfkkMxJknR/dGq6Pv+lFK2v/6YDAAAAALx5KS5gAP39yW23vbh/xfz567Z/xcc/3pepU/uy+eYV+/NZbz09yU9/2pjZsxtzxx2NWbVq7UuM8eOfzhVXnJgpU25+1fjvfveevO99v82qVSNzTT6ej236o6z4h6+nd/8PDXZ8AAAAAGAYUlzAGnR2Jjfc0JRvfKM5Tz659rdVes97+jNtWl+OOKIvI0dWMGAFrFiR/PjHL+6H8fOfN6S//7VKjCLHHvudfPWrn8nYsR1rnPH3f39mPn/WBXlgr9Oy+ayzU2y6aeWCAwAAAADDiuICXuE//qMuV1/dlO98p3mdbqG0556lTJvWm3337U/9G9sDu6YsWVKXOXNeLDEeeOC/VppsueWT+cY3js+HPnT7gOd3LN0od1/0z3n/WftnyDf0AAAAAAA2aIoLSPLQQ/X5p39qzpw5jSmV1u5Ce2NjkcMOe7Gw2HHH2ti/ohKefLIut9zSkIaGa3L66TPS1tY54PwVKw5Mb+8/pFx+yxAlBAAAAACGE8UFb2pFkVx6aXO+8pWWtT5nzJgiH/tYb447ri9veUvt7l8xWOrqnk17+6fS3HzXgPPK5U3S2XlZenoOT2KVBQAAAADwxqxNcdE4BDmgKh56qH6tS4t3vKOc44/vzVFH9aW1tcLBakRT0z1pa/tEGhqeGXDeqlWHp7PzshSFvSwAAAAAgMpTXDBs/frXDa87Z9KkUqZN68sBB5TS8PrTh4lyRo36ckaNuih1da99G6z+/vHp7PyH9PYeNITZAAAAAIA3O8UFw9aOO/avcbyhocjBB7+4f8Uuuwzf/SvWpK7uubS3fzLNzfMGnNfd/dF0dX0xRTF2iJIBAAAAALxIccGwteuu5Xz2sz35yleaUyrVpbW1yDHH9OVTn+rNllsO//0r/lJj431pb/94Ghr+4zXn9Pe/LStWzExf375DmAwAAAAA4L/YnJthb8mSujz7bF3e/e5yRoyodprqGDHiqrS2fjZ1dWtehZIkPT0HZMWKWSmKjYcwGQAAAADwZmJzbkiy2WZFNtvszbfC4pX6+9+VZM23xSqKhnR1XZDu7lOS1A9pLgAAAACAv+QqJbwJ9PXtm5Urz1xtvL//renouC3d3Z+JtwMAAAAAoBa4UglvEitXnp3e3r1eftzbu2+ef/7elErvr2IqAAAAAIBXU1zAm0ZDli//Zvr735KurvPywgs/TFFsWu1QAAAAAACvYo8LeBMpinFZtuzBJK3VjgIAAAAAsEZWXMAGrz+jRl2cESO+s5bzlRYAAAAAQO2y4gI2YPX1T6at7YQ0N9+TohiRvr6/Sn//9tWOBQAAAADwhllxARukIiNGfDdjx74/zc33JEnq6lalvf1jSTqrGw0AAAAAYD0oLmADU1+/OO3tR6at7cTU16941bHGxt+lre2MKiUDAAAAAFh/igvYYBRpaflBxo7dLS0tP3nNWS0tN6WhYeEQ5gIAAAAAGDz2uIANQF3d0rS2np4RI24ecF5//5ZZvvya9PdvN0TJAAAAAAAGl+ICalxz84/S1nZK6uuXDDivu/uYdHVdnKIYM0TJAAAAAAAGn+ICalR9/dMZPfqcjBjxwwHnlcubZ8WKment/dAQJQMAAAAAqBzFBdScUkaO/OeMGvWl1Tbf/kurVk1JZ+flKYpNhigbAAAAAEBlKS6ghjQ23p/W1tPT1PTQgPPK5bHp7PxKenoOH6JkAAAAAABDQ3EBNaCubmlGj/58Ro781uvO7en5UFas+McUxbjKBwMAAAAAGGKKC6gBra2fzYgRNw04p1wek87OS9LT8z+T1A1NMAAAAACAIVZf7QBA0tV1bopixGseX7XqqCxbNj89PUdHaQEAAAAADGeKC6gB5fI7s3LlGauNl0rbpqPjR1mx4iq3hgIAAAAA3hQUF1AjVq48NaXSu5MkRTEynZ0X5vnn/zV9fXtWORkAAAAAwNBRXEDF9aaxcf5azBuRzs7L09NzYJYtuz/d3acnaa50OAAAAACAmlJXFEVRqSdfsmRFpZ4aNgBFWlpmZ/Toz6eu7rksW/bbFMVm1Q4FAAAAAFA1m23W9rpzrLiACmhqujcbbfQ3aW//eBoankh9fWdGj7642rEAAAAAAGqe4gIGUVPTvRkz5sPZaKMD09T04KuOjRhxbRoaHq9SMgAAAACADYPiAgZBU9M9GTPmoGy00YFpbr57jXPq6vozevSFQxsMAAAAAGAD01jtALDhKtLUdE9Gjbokzc33rtUZ9fV/TtKZpLWiyQAAAAAANlSKC1hnRZqa7s6oURenufkXa3VGf/+W6eo6Lz09R8ZCJwAAAACA16a4gLVWpKnppxk9+rI0Nd23VmeUy2OzcuXp6e4+PsmIysYDAAAAABgGFBfwunrT0vKDjBo1M42Nj6zVGeXy2HR3n5zu7k+nKNornA8AAAAAYPhQXMAAWlpmZ/Tos9PQ8PRazS+XN87Kladk1apPpSjaKpwOAAAAAGD4UVzAAIpi1FqVFuXyJlm58pR0d38qNt4GAAAAAHjjFBcwgN7e/55Sads0Nj62xuPl8qZZufLUdHcfF4UFAAAAAMD6q692AKht9enuPnm10f7+8ens/GKWLl2Q7u5To7QAAAAAABgcdUVRFJV68iVLVlTqqWEIrcomm+yQ+vpnUypNyMqVJ6en5++SNFc7GAAAAADABmWzzV5/b2C3ioLXNSKdnZekXB6Tvr79ktRVOxAAAAAAwLCluIC10NNzRLUjAAAAAAC8KdjjAgAAAAAAqBmKCwAAAAAAoGYoLgAAAAAAgJqhuAAAAAAAAGqG4gIAAAAAAKgZigsAAAAAAKBmKC4AAAAAAICaobgAAAAAAABqhuICAAAAAACoGYoLAAAAAACgZiguAAAAAACAmqG4AAAAAAAAaobiAgAAAAAAqBmKCwAAAAAAoGYoLgAAAAAAgJqhuAAAAAAAAGqG4gIAAAAAAKgZigsAAAAAAKBmKC4AAAAAAICaobgAAAAAAABqhuICAAAAAACoGYoLAAAAAACgZiguAAAAAACAmqG4AAAAAAAAaobiAgAAAAAAqBmKCwAAAAAAoGYoLgAAAAAAgJqhuAAAAAAAAGqG4gIAAAAAAKgZigsAAAAAAKBmKC4AAAAAAICaobgAAAAAAABqhuICAAAAAACoGYoLAAAAAACgZiguAAAAAACAmqG4AAAAAAAAaobiAgAAAAAAqBmKCwAAAAAAoGYoLgAAAAAAgJqhuAAAAAAAAGqG4gIAAAAAAKgZigsAAAAAAKBmKC4AAAAAAICaobgAAAAAAABqhuICAAAAAACoGYoLAAAAAACgZiguAAAAAACAmqG4AAAAAAAAaobiAgAAAAAAqBmKCwAAAAAAoGbUFUVRVDsEAAAAAABAYsUFAAAAAABQQxQXAAAAAABAzVBcAAAAAAAANUNxAQAAAAAA1AzFBQAAAAAAUDMUF8PUokWL8ulPfzqTJk3KPvvsk8suuyzlcrnasaAiFi1alBNPPDGTJk3K7rvvnhkzZmT58uXVjgUVddFFF2XbbbetdgyoqCuvvDJ77LFHdtppp0ydOjVPPfVUtSNBRfzbv/1bjj322Oy66675wAc+kOnTp2fZsmXVjgWD4p577snuu++e0047bbVjt912Ww4++ODsvPPOmTJlSu69994qJITBM9Dr/Y477sjkyZOz8847Z//998/3v//9KiSEwTPQ6/0lXV1d+eAHP5gZM2YMYTKGC8XFMHXyySdn3LhxufPOO3PttdfmzjvvzLe//e1qx4KKmDZtWtrb2zNv3rzMnj07jz/+eC699NJqx4KKWbhwYW655ZZqx4CKuv766zNnzpx85zvfyb333putt9463/rWt6odCwZdqVTKpz/96ey00075xS9+kblz52bZsmW58MILqx0N1ttVV12VL37xi9lqq61WO7Zw4cKcddZZmT59en75y19m6tSpOemkk7J48eIqJIX1N9Dr/aGHHsr06dNzyimn5IEHHsg555yTL3zhC5k/f34VksL6G+j1/kozZ85MZ2fnEKViuFFcDEMLFizIo48+munTp6etrS3veMc7MnXq1Nx4443VjgaDbvny5dlhhx1yxhlnZPTo0Rk/fnwOO+wwHwAZtsrlci644IJMnTq12lGgoq655pqcdtppede73pXW1tace+65Offcc6sdCwbdkiVLsmTJkhxyyCFpbm7O2LFj87d/+7dZuHBhtaPBemtpackPfvCDNV7Yuummm7L33ntn7733TktLSyZPnpxtttkmc+bMqUJSWH8Dvd47Ojpy/PHHZ7/99ktjY2P23nvvbLPNNr63ssEa6PX+kkcffTRz587NYYcdNoTJGE4UF8PQI488ki222CJjxox5eWz77bfPH//4Ry0nw057e3suvvjibLrppi+PPf3009l8882rmAoq53vf+15aWlpy8MEHVzsKVMwzzzyTp556Ki+88EIOPPDATJo0Kaeccopb5zAsjRs3Ltttt11uvPHGdHV1ZenSpbnjjjvywQ9+3PH6EAAABUpJREFUsNrRYL0de+yxaWtrW+OxRx55JBMmTHjV2IQJE7JgwYKhiAaDbqDX+1577ZUTTzzx5celUilLlizJuHHjhioeDKqBXu9JUhRFLrzwwpx22mlpb28fwmQMJ4qLYaijo2O1N4WXSoznn3++GpFgyCxYsCDXXXddTjjhhGpHgUH33HPPZebMmbnggguqHQUq6qXbhNx+++259tprc8stt2Tx4sVWXDAs1dfXZ+bMmfnpT3+aXXbZJbvvvntKpVLOOOOMakeDiuro6HjVj+2SF7+3+s7Km8GXv/zljBo1KgceeGC1o0BF3Hjjjamrq8uUKVOqHYUNmOJimCqKotoRYMg9+OCDOe6443LGGWdk9913r3YcGHQXX3xxpkyZkq233rraUaCiXvoc88lPfjLjxo3L+PHjc/LJJ2fevHnp6empcjoYXL29vZk2bVoOOOCAzJ8/P3fffXfa2toyffr0akeDivO9lTeboihy2WWXZe7cubnyyivT0tJS7Ugw6JYuXZqvfe1rufDCC1NXV1ftOGzAGqsdgMG38cYbp6Oj41VjHR0dqaury8Ybb1ylVFBZ8+bNy5lnnpnzzjsvhx56aLXjwKC777778pvf/CZz586tdhSouJdu//fKFaRbbLFFiqLI0qVL89a3vrVa0WDQ3XfffXnqqady+umnp6GhIW1tbTnllFNyyCGHpKOjIxtttFG1I0JFjB07do3fW31nZbgql8s5++yz89BDD+WGG27IlltuWe1IUBGXXHJJDj300Gy77bbVjsIGTnExDO2www55+umns2zZspc/9C1YsCBbb711Ro8eXeV0MPh+/etf56yzzsrXvva17LHHHtWOAxUxZ86cLF26NPvss0+S//qF4qRJk3L++efnoIMOqmY8GFTjx49Pa2trFi5cmO233z5JsmjRojQ1NdnDiGGnv78/5XL5Vb887+3trWIiGBo77LBDHn744VeNLViwwGcahq2LLroojz/+eG644QalNMPanDlz0t7entmzZydJVq1alXK5nLvuuiu/+tWvqpyODYniYhiaMGFCdtxxx1x++eU5++yz88wzz+Taa6/NJz7xiWpHg0FXKpVy7rnnZvr06UoLhrUZM2bk1FNPffnx4sWLc9RRR+WWW25Z7f7QsKFrbGzMEUcckVmzZmXixIlpbW3NFVdckYMPPjiNjT6+MrzsvPPOGTVqVGbOnJlp06Zl1apVufLKKzNx4kQXthjWjjzyyBxxxBH52c9+lve///259dZb88QTT2Ty5MnVjgaD7sEHH8ycOXNy2223eW9n2Pv5z3/+qsfXXnttFi9enLPPPrtKidhQ1RVuKjksLV68OOedd17uv//+tLa25iMf+UhOOukk95Zj2Jk/f36OPvroNDc3r3bs9ttvzxZbbFGFVFB5Tz31VPbdd9889thj1Y4CFdHb25uLL744P/rRj9LX15f9998/5513ntWjDEsPP/xwLr300jz66KNpbm7ObrvtlhkzZmTcuHHVjgbrZccdd0zy4o+NkrxcPi9YsCBJcscdd+Tyyy/PokWLsvXWW+dzn/tcJk6cWJ2wsJ4Ger2fc845ufnmm1f7AcbEiRNzzTXXDG1QGASv9/7+SjNnzsyiRYtyySWXDF1AhgXFBQAAAAAAUDPqqx0AAAAAAADgJYoLAAAAAACgZiguAAAAAACAmqG4AAAAAAAAaobiAgAAAAAAqBmKCwAAAAAAoGYoLgAAAAAAgJqhuAAAAAAAAGqG4gIAAAAAAKgZigsAAAAAAKBmKC4AAAAAAICaobgAAAAAAABqxv8HmgxGwwYZWyYAAAAASUVORK5CYII=\n","text/plain":["<Figure size 2000x1500 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"p8ajji68jAZK","colab_type":"text"},"source":["## Attention Multiply Example"]},{"cell_type":"code","metadata":{"id":"Gnsr89s0jFaH","colab_type":"code","colab":{}},"source":["import torch\n","\n","w = torch.Tensor([\n","                [6,3],\n","                [5,2],\n","                [4,1]\n","                ])\n","print('w:',w)\n","A = torch.Tensor([1,2,3,4])\n","print('a^T:',A)\n","def cal(h_src, h_dst):\n"," \n","  Wh_front = torch.matmul(h_src, w)\n","  Wh_back = torch.matmul(h_dst, w)\n","  Concat = torch.cat([Wh_front, Wh_back], dim=0)\n","  print('Wh_front:',Wh_front,', Wh_back:',Wh_back,', Concat:', Concat)\n","  return torch.matmul(Concat, A)\n","\n","h = torch.Tensor([[1,2,3],\n","                  [4,5,6],\n","                  [7,8,9]\n","                  ])\n","print(h)\n","print(h.size())\n","\n","a11 = cal(h[0], h[0])\n","print('a11:',a11)\n","\n","a12 = cal(h[0], h[1])\n","print('a12:',a12)\n","\n","a21 = cal(h[1], h[0])\n","print('a21:',a21)\n","print('----------')\n","\n","n = h.size()[1]  \n","h_prime = torch.matmul(h, w)  \n","print('h_prime:',h_prime)\n","\n","# F_out x 1\n","a_src = torch.Tensor([[1],\n","                      [2]\n","                      ])\n","a_dst = torch.Tensor([[3],\n","                      [4]\n","                      ])\n","\n","attn_src = torch.matmul(h_prime, a_src)    # bs x n_head x n x 1\n","attn_dst = torch.matmul(h_prime, a_dst)    # bs x n_head x n x 1\n","print('attn_src:',attn_src)\n","print('attn_dst:',attn_dst)\n","\n","print('attn_src.expand:',attn_src.expand(-1, n))\n","print('attn_dst.expand:',attn_dst.expand(-1, n))\n","print('permute', attn_dst.expand(-1, n).permute(1,0) )\n","attn = attn_src.expand(-1, n) + attn_dst.expand(-1, n).permute(\n","            1,0\n","        ) # bs x n_head x n x n\n","print('attn:',attn )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UuHheWTM0ShK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1599310422630,"user_tz":-480,"elapsed":1211,"user":{"displayName":"CHUNG-YI LIN","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh85SFzskAgADT_7pcMQIn9n4C0vxreOc7WT-7I=s64","userId":"10270653500695949916"}},"outputId":"78b477bf-1148-458c-8a4e-63562fc418be"},"source":["import torch \n","import numpy as np\n","\n","A = torch.tensor([\n","    [0., 1., 0., 0.],\n","    [0., 0., 1., 1.], \n","    [0., 1., 0., 0.],\n","    [1., 0., 1., 0.]]\n",")\n","print(A)\n","\n","D = torch.tensor([\n","    [1., 0., 0., 0.],\n","    [0., 2., 0., 0.], \n","    [0., 0., 2., 0.],\n","    [0., 0., 0., 1.]]\n",")\n","\n","print(D**-1)\n","\n","print(torch.matmul(A, D**-1, ))\n","\n","\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([[0., 1., 0., 0.],\n","        [0., 0., 1., 1.],\n","        [0., 1., 0., 0.],\n","        [1., 0., 1., 0.]])\n","tensor([[1.0000,    inf,    inf,    inf],\n","        [   inf, 0.5000,    inf,    inf],\n","        [   inf,    inf, 0.5000,    inf],\n","        [   inf,    inf,    inf, 1.0000]])\n","tensor([[nan, nan, nan, nan],\n","        [nan, nan, nan, nan],\n","        [nan, nan, nan, nan],\n","        [nan, nan, nan, nan]])\n"],"name":"stdout"}]}]}