{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Colab_Train.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wm_JdO1Vu4nR","colab_type":"text"},"source":["## Colab & Drive環境設定"]},{"cell_type":"markdown","metadata":{"id":"9tGaekNkUp8_","colab_type":"text"},"source":["### Drive連結"]},{"cell_type":"code","metadata":{"id":"qnHuSwLjt8yG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1597972468483,"user_tz":-480,"elapsed":20053,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}},"outputId":"89345ee3-85ec-4072-a40b-9a46710c16ca"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eGynxt4w_yNB","colab_type":"text"},"source":["### 切換路徑"]},{"cell_type":"code","metadata":{"id":"ZFXiA5d01lx6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597973120552,"user_tz":-480,"elapsed":965,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}},"outputId":"73d1264f-842f-4132-984b-021aaaf88bb1"},"source":["cd drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT "],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"agU_GCXInYfF","colab_type":"text"},"source":["## 主程式"]},{"cell_type":"markdown","metadata":{"id":"NyywXcMesc0b","colab_type":"text"},"source":["### Library import & Parameters"]},{"cell_type":"code","metadata":{"id":"GbmAuoo6sjcn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597973121348,"user_tz":-480,"elapsed":1748,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}}},"source":["\"\"\" \n","# 先從STGAT引用package # \n","\"\"\"\n","import sys \n","sys.path.append('/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT')\n","\n","from STGAT import __init__\n","from STGAT import trajectories\n","from STGAT import loader\n","from STGAT import draw_trajectory\n","from STGAT import evaluate_model\n","\n","from STGAT import models\n","from STGAT import train\n","from STGAT import utils\n","\n","import argparse\n","import logging\n","import os\n","import random\n","import shutil\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import STGAT.utils\n","from STGAT.loader import data_loader\n","from STGAT.models import TrajectoryGenerator\n","from STGAT.utils import (\n","    displacement_error,\n","    final_displacement_error,\n","    get_dset_path,\n","    int_tuple,\n","    l2_loss,\n","    relative_to_abs,\n",")\n","\n","import easydict\n","args = easydict.EasyDict({\n","        \"log_dir\": \"./\",\n","        \"dataset_name\": \"zara2\",\n","        \"delim\": \"\\t\",\n","        \"loader_num_workers\": 1,  #原:4\n","        \"obs_len\": 8,\n","        \"pred_len\": 12,\n","        \"skip\": 1,\n","        \"seed\": 72,\n","        \"batch_size\":64,\n","        \n","        \"noise_dim\":(16,),\n","        \"noise_type\":\"gaussian\",\n","        \"traj_lstm_input_size\":2,\n","        \"traj_lstm_hidden_size\":32,\n","        \"heads\":\"4,1\",\n","        \"hidden_units\":\"16\",\n","        \"graph_network_out_dims\":32,\n","        \"graph_lstm_hidden_size\":32,\n","        \"dropout\":0,\n","        \"alpha\": 0.2,\n","        \"lr\":1e-3,\n","        \"start_epoch\":0,\n","        \"best_k\":20,\n","        \"print_every\":10,\n","        \"use_gpu\":1,\n","        \"gpu_num\":\"0\",\n","        \"resume\":\"checkpoint/test0809_1\",\n","\n","        \"num_epochs\":1,\n","\n","        \"min_ped_in_scene\" :1  # control the minimum number of pedestrain \n","})\n","\n","best_ade = 100"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N9OZs5yDslAu","colab_type":"text"},"source":["## Main Run"]},{"cell_type":"code","metadata":{"id":"lYIqdaAlgnln","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1597973128721,"user_tz":-480,"elapsed":6095,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}},"outputId":"22897f65-7ed4-4290-9c73-4130e00fa712"},"source":["import sys\n","def main(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_num\n","    train_path = get_dset_path(args.dataset_name, \"train\")\n","    val_path = get_dset_path(args.dataset_name, \"test\")\n","\n","    print(\"$Colad_Train.ipynb\",\"call data_loader()\")\n","    train_dset, train_loader = data_loader(args, train_path)\n","    \n","    '''\n","    _, val_loader = data_loader(args, val_path)\n","    '''\n","    writer = SummaryWriter()\n","    \n","    # n_units = [32, 16, 32]\n","    n_units = (\n","        [args.traj_lstm_hidden_size]      #traj_lstm_hidden_size=32\n","        + [int(x) for x in args.hidden_units.strip().split(\",\")]  #hidden_units=16\n","        + [args.graph_lstm_hidden_size]   #graph_lstm_hidden_size=32\n","    )\n","    print(\"$Colad_Train.ipynb\",\"-n_units:\",n_units)\n","   \n","    n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n","    print(\"$Colad_Train.ipynb\",\"-n_heads:\",n_heads)\n","    \n","    model = TrajectoryGenerator(\n","        obs_len=args.obs_len,\n","        pred_len=args.pred_len,\n","        traj_lstm_input_size=args.traj_lstm_input_size, #2\n","        traj_lstm_hidden_size=args.traj_lstm_hidden_size, #32\n","        n_units=n_units, #[32, 16, 32]\n","        n_heads=n_heads, #[4,1]\n","        graph_network_out_dims=args.graph_network_out_dims,  #32\n","        dropout=args.dropout,\n","        alpha=args.alpha,\n","        graph_lstm_hidden_size=args.graph_lstm_hidden_size,   #32\n","        noise_dim=args.noise_dim,\n","        noise_type=args.noise_type,\n","    )\n","    \n","    print(\"$Colad_Train.ipynb\",\"Model.summary:\\n\",model)\n","    \n","    model.cuda()  # cuda()函數能實現從CPU到GPU的内存遷移\n","    optimizer = optim.Adam(\n","        [\n","            {\"params\": model.traj_lstm_model.parameters(), \"lr\": 1e-2},\n","            {\"params\": model.traj_hidden2pos.parameters()},\n","            {\"params\": model.gatencoder.parameters(), \"lr\": 3e-2},\n","            {\"params\": model.graph_lstm_model.parameters(), \"lr\": 1e-2},\n","            {\"params\": model.traj_gat_hidden2pos.parameters()},\n","            {\"params\": model.pred_lstm_model.parameters()},\n","            {\"params\": model.pred_hidden2pos.parameters()},\n","        ],\n","        lr=args.lr,\n","    )\n","    global best_ade\n","    if args.resume:\n","        if os.path.isfile(args.resume):\n","            logging.info(\"Restoring from checkpoint {}\".format(args.resume))\n","            checkpoint = torch.load(args.resume)\n","            args.start_epoch = checkpoint[\"epoch\"]\n","            model.load_state_dict(checkpoint[\"state_dict\"])\n","            logging.info(\n","                \"=> loaded checkpoint '{}' (epoch {})\".format(\n","                    args.resume, checkpoint[\"epoch\"]\n","                )\n","            )\n","        else:\n","            logging.info(\"=> no checkpoint found at '{}'\".format(args.resume))\n","\n","    training_step = 1\n","    for epoch in range(args.start_epoch, args.num_epochs + 1):\n","\n","        if epoch < 150:\n","            training_step = 1\n","\n","        elif epoch < 250:\n","            training_step = 2\n","\n","        else:\n","            if epoch == 250:\n","                for param_group in optimizer.param_groups:\n","                    param_group[\"lr\"] = 5e-3\n","            training_step = 3\n","\n","        if epoch >1:\n","            training_step = 3\n","\n","        train(args, model, train_loader, optimizer, epoch, training_step, writer)\n","        \n","\n","        if training_step == 3:\n","\n","            print(\"@GN\",\"training_step=3\")\n","            ade = validate(args, model, val_loader, epoch, writer)\n","            is_best = ade < best_ade\n","            best_ade = min(ade, best_ade)\n","\n","            print(\"@GN\",\"save_checkpoint:\")\n","            save_checkpoint(\n","                {\n","                    \"epoch\": epoch + 1,\n","                    \"state_dict\": model.state_dict(),\n","                    \"best_ade\": best_ade,\n","                    \"optimizer\": optimizer.state_dict(),\n","                },\n","                is_best,\n","                f\"./checkpoint/checkpoint{epoch}.pth.tar\",\n","            )        \n","    writer.close()\n","\n","def train(args, model, train_loader, optimizer, epoch, training_step, writer):\n","    \n","    print(\"$Colad_Train.ipynb\",\"call train()\")\n","    losses = utils.AverageMeter(\"Loss\", \":.6f\")\n","    progress = utils.ProgressMeter(\n","        len(train_loader), [losses], prefix=\"Epoch: [{}]\".format(epoch)\n","    )\n","    model.train()\n","    print(\"$Colad_Train.ipynb\",\"model.train()\")\n","\n","    \"\"\"\n","    $GN:\n","    - len(train_loader) == equals number of batches\n","    - ex: self.seq_start_end = \n","        [(0, 2), (2, 4), (4, 7), (7, 10) ... (25499, 25501), (25501, 25503), (25503, 25505), (25505, 25507)]\n","        - length : 2112\n","        - each batch will take batch_size\n","        - ex: batch_1: [(0, 2), (2, 4), (4, 7), (7, 10)...(161, 164)] => 64個\n","              ...\n","              batch_n: [...(25503, 25505), (25505, 25507)]\n","        - so, train_loader.length = len(self.seq_start_end)/batch_size = 33\n","    \"\"\"\n","    print(\"$Colad_Train.ipynb\",\"train_loader.length\", len(train_loader))\n","    for batch_idx, batch in enumerate(train_loader):\n","        print(\"$Colad_Train.ipynb\",\"\\nbatch_idx:\",batch_idx, \"\\nbatch[0].shape:\",batch[0].size())\n","\n","        batch = [tensor.cuda() for tensor in batch]\n","        (\n","            obs_traj,\n","            pred_traj_gt,\n","            obs_traj_rel,\n","            pred_traj_gt_rel,\n","            non_linear_ped,\n","            loss_mask,\n","            seq_start_end,\n","        ) = batch\n","\n","        print(\"$Colad_Train.ipynb\",\"\\nobs_traj.size():\",obs_traj.size(), \"\\nobs_traj[0].shape:\",obs_traj[0].size())\n","\n","        optimizer.zero_grad()\n","        loss = torch.zeros(1).to(pred_traj_gt)\n","        l2_loss_rel = []\n","        loss_mask = loss_mask[:, args.obs_len :]\n","\n","        if training_step == 1 or training_step == 2:\n","            model_input = obs_traj_rel\n","            print(\"$Colad_Train.ipynb\",\"obs_traj_rel.size():\",obs_traj_rel.size())\n","            \n","            pred_traj_fake_rel = model(\n","                model_input, obs_traj, seq_start_end, 1, training_step\n","            )\n","            l2_loss_rel.append(\n","                l2_loss(pred_traj_fake_rel, model_input, loss_mask, mode=\"raw\")\n","            )\n","\n","            \n","            print(\"$Colad_Train.ipynb\",\"pred_traj_fake_rel:\",pred_traj_fake_rel)\n","            \n","            \n","        else:\n","            print(\"@GN\", \"Training-step=3, ouput model\")\n","\n","            model_input = torch.cat((obs_traj_rel, pred_traj_gt_rel), dim=0)\n","            for _ in range(args.best_k):\n","                pred_traj_fake_rel = model(model_input, obs_traj, seq_start_end, 0)\n","                l2_loss_rel.append(\n","                    l2_loss(\n","                        pred_traj_fake_rel,\n","                        model_input[-args.pred_len :],\n","                        loss_mask,\n","                        mode=\"raw\",\n","                    )\n","                )\n","\n","        l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n","        l2_loss_rel = torch.stack(l2_loss_rel, dim=1)\n","        for start, end in seq_start_end.data:\n","            _l2_loss_rel = torch.narrow(l2_loss_rel, 0, start, end - start)\n","            _l2_loss_rel = torch.sum(_l2_loss_rel, dim=0)  # [20]\n","            _l2_loss_rel = torch.min(_l2_loss_rel) / (\n","                (pred_traj_fake_rel.shape[0]) * (end - start)\n","            )\n","            l2_loss_sum_rel += _l2_loss_rel\n","\n","        loss += l2_loss_sum_rel\n","        losses.update(loss.item(), obs_traj.shape[1])\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % args.print_every == 0:\n","            progress.display(batch_idx)\n","\n","    writer.add_scalar(\"train_loss\", losses.avg, epoch)\n","\n","def validate(args, model, val_loader, epoch, writer):\n","    ade = utils.AverageMeter(\"ADE\", \":.6f\")\n","    fde = utils.AverageMeter(\"FDE\", \":.6f\")\n","    progress = utils.ProgressMeter(len(val_loader), [ade, fde], prefix=\"Test: \")\n","\n","    model.eval()\n","    with torch.no_grad():\n","\n","        \"\"\"\n","        $GN:\n","        - 1.執行for batch_idx, batch in enumerate(train_loader)\n","        - 2.DataLoader會依序抽出batch_size個dataset\n","            => 每次抽出會呼叫dataset內的__getitem__()得到out\n","        - 3.抽取完batch_size個dataset後, 呼叫自定義的方法\n","            => 傳入 [out_1,out_2, ... out_batch_size]\n","            \n","        \"\"\"\n","        for i, batch in enumerate(val_loader):\n","            batch = [tensor.cuda() for tensor in batch]\n","            (\n","                obs_traj,\n","                pred_traj_gt,\n","                obs_traj_rel,\n","                pred_traj_gt_rel,\n","                non_linear_ped,\n","                loss_mask,\n","                seq_start_end,\n","            ) = batch\n","            loss_mask = loss_mask[:, args.obs_len :]\n","            pred_traj_fake_rel = model(obs_traj_rel, obs_traj, seq_start_end)\n","\n","            pred_traj_fake_rel_predpart = pred_traj_fake_rel[-args.pred_len :]\n","            pred_traj_fake = relative_to_abs(pred_traj_fake_rel_predpart, obs_traj[-1])\n","            ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n","            ade_ = ade_ / (obs_traj.shape[1] * args.pred_len)\n","\n","            fde_ = fde_ / (obs_traj.shape[1])\n","            ade.update(ade_, obs_traj.shape[1])\n","            fde.update(fde_, obs_traj.shape[1])\n","\n","            if i % args.print_every == 0:\n","                progress.display(i)\n","\n","        logging.info(\n","            \" * ADE  {ade.avg:.3f} FDE  {fde.avg:.3f}\".format(ade=ade, fde=fde)\n","        )\n","        writer.add_scalar(\"val_ade\", ade.avg, epoch)\n","    return ade.avg\n","\n","def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n","    ade = displacement_error(pred_traj_fake, pred_traj_gt)\n","    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1])\n","    return ade, fde\n","\n","def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n","    if is_best:\n","        torch.save(state, filename)\n","        logging.info(\"-------------- lower ade ----------------\")\n","        shutil.copyfile(filename, \"model_best.pth.tar\")\n","\n","if __name__ == \"__main__\":\n","    #args = parser.parse_args()\n","    utils.set_logger(os.path.join(args.log_dir, \"train.log\"))\n","    checkpoint_dir = \"./checkpoint\"\n","    if os.path.exists(checkpoint_dir) is False:\n","        os.mkdir(checkpoint_dir)\n","    main(args)\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["$Colad_Train.ipynb call data_loader()\n","$loader.py call TrajectoryDataset()\n","$trajectories.py ----min_ped: 1\n","$trajectories.py #STEP-1 讀取檔案:  File_Path: /content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/datasets/zara2/train/biwi_eth_train.txt\n","$trajectories.py #STEP-2 unique time-frame數量: 700\n","$trajectories.py #Step-3 相同time_frame的element合併\n","ex: data[]: (3666, 4) ->frame_data[] (700,)\n","$trajectories.py #Step-4 扣除obs_len+pre_len,剩餘可處理長度: 681\n","$trajectories.py 更新seq_list數量: 40\n","$trajectories.py #STEP-1 讀取檔案:  File_Path: /content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/datasets/zara2/train/biwi_hotel_train.txt\n","$trajectories.py #STEP-2 unique time-frame數量: 934\n","$trajectories.py #Step-3 相同time_frame的element合併\n","ex: data[]: (4946, 4) ->frame_data[] (934,)\n","$trajectories.py #Step-4 扣除obs_len+pre_len,剩餘可處理長度: 915\n","$trajectories.py 更新seq_list數量: 271\n","$trajectories.py #STEP-1 讀取檔案:  File_Path: /content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/datasets/zara2/train/crowds_zara01_train.txt\n","$trajectories.py #STEP-2 unique time-frame數量: 697\n","$trajectories.py #Step-3 相同time_frame的element合併\n","ex: data[]: (4307, 4) ->frame_data[] (697,)\n","$trajectories.py #Step-4 扣除obs_len+pre_len,剩餘可處理長度: 678\n","$trajectories.py 更新seq_list數量: 774\n","$trajectories.py #STEP-1 讀取檔案:  File_Path: /content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/datasets/zara2/train/crowds_zara03_train.txt\n","$trajectories.py #STEP-2 unique time-frame數量: 603\n","$trajectories.py #Step-3 相同time_frame的element合併\n","ex: data[]: (3708, 4) ->frame_data[] (603,)\n","$trajectories.py #Step-4 扣除obs_len+pre_len,剩餘可處理長度: 584\n","$trajectories.py 更新seq_list數量: 1204\n","$trajectories.py #STEP-1 讀取檔案:  File_Path: /content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/datasets/zara2/train/students001_train.txt\n","$trajectories.py #STEP-2 unique time-frame數量: 355\n","$trajectories.py #Step-3 相同time_frame的element合併\n","ex: data[]: (18353, 4) ->frame_data[] (355,)\n","$trajectories.py #Step-4 扣除obs_len+pre_len,剩餘可處理長度: 336\n","$trajectories.py 更新seq_list數量: 1540\n","$trajectories.py #STEP-1 讀取檔案:  File_Path: /content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/datasets/zara2/train/students003_train.txt\n","$trajectories.py #STEP-2 unique time-frame數量: 432\n","$trajectories.py #Step-3 相同time_frame的element合併\n","ex: data[]: (15641, 4) ->frame_data[] (432,)\n","$trajectories.py #Step-4 扣除obs_len+pre_len,剩餘可處理長度: 413\n","$trajectories.py 更新seq_list數量: 1953\n","$trajectories.py #STEP-1 讀取檔案:  File_Path: /content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/datasets/zara2/train/uni_examples_train.txt\n","$trajectories.py #STEP-2 unique time-frame數量: 587\n","$trajectories.py #Step-3 相同time_frame的element合併\n","ex: data[]: (2266, 4) ->frame_data[] (587,)\n","$trajectories.py #Step-4 扣除obs_len+pre_len,剩餘可處理長度: 568\n","$trajectories.py 更新seq_list數量: 2112\n","$trajectories.py #STEP-5~13 含有可用軌跡(數量>min_ped)的time-frame數量: 2112 \n","*NOTE:一個time-frame array內含多個軌跡\n","$trajectories.py #STEP-14 將各time-frame軌跡資料,融合成各自獨立的軌跡資料,shape: (25507, 2, 20)\n","$trajectories.py obs_traj.shape: (25507, 2, 8)\n","$trajectories.py obs_traj[:5]:\n"," [[[10.31  9.57  8.73  7.94  7.17  6.47  5.86  5.24]\n","  [ 5.97  6.24  6.34  6.5   6.62  6.68  6.82  6.98]]\n","\n"," [[12.49 11.94 11.03 10.21  9.36  8.59  7.78  6.96]\n","  [ 6.6   6.77  6.84  6.81  6.85  6.85  6.84  6.84]]\n","\n"," [[12.51 11.54 10.96 10.29  9.88  9.54  8.87  8.04]\n","  [ 6.19  6.03  5.97  6.12  6.21  6.09  5.99  5.66]]\n","\n"," [[12.09 11.4  10.7  10.07  9.45  8.9   8.21  7.49]\n","  [ 6.95  6.93  6.87  6.73  6.51  6.33  6.23  6.06]]\n","\n"," [[ 7.05  7.05  7.05  7.05  7.05  7.05  7.05  7.05]\n","  [ 8.44  8.44  8.44  8.44  8.44  8.44  8.44  8.44]]]\n","$trajectories.py obs_traj[-5:]:\n"," [[[ 2.694   3.2201  3.7463  4.2958  4.8805  5.4651  6.0088  6.5349]\n","  [10.5934 10.4659 10.3387 10.2094 10.0767  9.9442  9.8051  9.6636]]\n","\n"," [[ 3.4937  4.05    4.5951  5.133   5.6708  6.1723  6.6698  7.1348]\n","  [11.1812 11.0363 10.9146 10.8087 10.7025 10.5552 10.4034 10.2027]]\n","\n"," [[ 3.2201  3.7463  4.2958  4.8805  5.4651  6.0088  6.5349  7.0611]\n","  [10.4659 10.3387 10.2094 10.0767  9.9442  9.8051  9.6636  9.5218]]\n","\n"," [[ 4.05    4.5951  5.133   5.6708  6.1723  6.6698  7.1348  7.5858]\n","  [11.0363 10.9146 10.8087 10.7025 10.5552 10.4034 10.2027  9.981 ]]\n","\n"," [[ 3.7463  4.2958  4.8805  5.4651  6.0088  6.5349  7.0611  7.5502]\n","  [10.3387 10.2094 10.0767  9.9442  9.8051  9.6636  9.5218  9.3538]]]\n","$trajectories.py pred_traj[:5]:\n"," [[[ 4.87  4.51  4.2   3.95  3.47  2.82  2.01  1.28  0.54 -0.18 -0.83\n","   -1.52]\n","  [ 7.16  7.58  7.3   7.71  7.86  8.    8.    7.82  7.4   7.06  6.43\n","    6.05]]\n","\n"," [[ 6.29  5.62  5.06  4.69  4.35  3.76  3.19  2.62  1.78  1.01  0.07\n","   -0.72]\n","  [ 7.    7.1   7.04  7.    7.01  6.99  6.89  7.13  7.15  6.96  6.91\n","    6.66]]\n","\n"," [[ 7.17  6.43  5.67  4.94  4.26  3.54  2.82  2.16  1.39  0.71  0.01\n","   -0.63]\n","  [ 5.45  5.23  5.16  4.95  4.71  4.54  4.35  4.19  3.97  3.72  3.41\n","    3.08]]\n","\n"," [[ 6.73  5.98  5.21  4.45  3.76  3.03  2.28  1.57  0.83  0.11 -0.65\n","   -1.48]\n","  [ 5.97  5.8   5.74  5.61  5.6   5.39  5.24  5.06  4.87  4.68  4.3\n","    3.9 ]]\n","\n"," [[ 7.05  7.05  7.05  7.05  7.05  7.05  7.05  6.93  6.87  7.02  7.07\n","    7.1 ]\n","  [ 8.44  8.44  8.44  8.44  8.44  8.44  8.44  8.26  8.09  7.91  7.78\n","    7.82]]]\n","$trajectories.py pred_traj[-5:]:\n"," [[[ 7.0611  7.5502  8.0023  8.4544  8.9692  9.4996 10.0386 10.5973\n","   11.1561 11.737  12.3507 12.9647]\n","  [ 9.5218  9.3538  9.1593  8.9648  8.7426  8.5135  8.2913  8.0856\n","    7.8798  7.677   7.4779  7.2791]]\n","\n"," [[ 7.5858  8.0368  8.559   9.0889  9.6191 10.149  10.6792 11.2456\n","   11.8481 12.4444 13.0253 13.6061]\n","  [ 9.981   9.7595  9.5941  9.4349  9.2653  9.0531  8.8409  8.6915\n","    8.6049  8.4753  8.2462  8.0171]]\n","\n"," [[ 7.5502  8.0023  8.4544  8.9692  9.4996 10.0386 10.5973 11.1561\n","   11.737  12.3507 12.9647 13.5407]\n","  [ 9.3538  9.1593  8.9648  8.7426  8.5135  8.2913  8.0856  7.8798\n","    7.677   7.4779  7.2791  7.1094]]\n","\n"," [[ 8.0368  8.559   9.0889  9.6191 10.149  10.6792 11.2456 11.8481\n","   12.4444 13.0253 13.6061 14.1433]\n","  [ 9.7595  9.5941  9.4349  9.2653  9.0531  8.8409  8.6915  8.6049\n","    8.4753  8.2462  8.0171  7.8023]]\n","\n"," [[ 8.0023  8.4544  8.9692  9.4996 10.0386 10.5973 11.1561 11.737\n","   12.3507 12.9647 13.5407 14.1167]\n","  [ 9.1593  8.9648  8.7426  8.5135  8.2913  8.0856  7.8798  7.677\n","    7.4779  7.2791  7.1094  6.94  ]]]\n","$trajectories.py obs_traj_rel[:5]:\n"," [[[ 0.   -0.74 -0.84 -0.79 -0.77 -0.7  -0.61 -0.62]\n","  [ 0.    0.27  0.1   0.16  0.12  0.06  0.14  0.16]]\n","\n"," [[ 0.   -0.55 -0.91 -0.82 -0.85 -0.77 -0.81 -0.82]\n","  [ 0.    0.17  0.07 -0.03  0.04  0.   -0.01  0.  ]]\n","\n"," [[ 0.   -0.97 -0.58 -0.67 -0.41 -0.34 -0.67 -0.83]\n","  [ 0.   -0.16 -0.06  0.15  0.09 -0.12 -0.1  -0.33]]\n","\n"," [[ 0.   -0.69 -0.7  -0.63 -0.62 -0.55 -0.69 -0.72]\n","  [ 0.   -0.02 -0.06 -0.14 -0.22 -0.18 -0.1  -0.17]]\n","\n"," [[ 0.    0.    0.    0.    0.    0.    0.    0.  ]\n","  [ 0.    0.    0.    0.    0.    0.    0.    0.  ]]]\n","$trajectories.py obs_traj_rel[-5:]:\n"," [[[ 0.      0.5261  0.5262  0.5495  0.5847  0.5846  0.5437  0.5261]\n","  [ 0.     -0.1275 -0.1272 -0.1293 -0.1327 -0.1325 -0.1391 -0.1415]]\n","\n"," [[ 0.      0.5563  0.5451  0.5379  0.5378  0.5015  0.4975  0.465 ]\n","  [ 0.     -0.1449 -0.1217 -0.1059 -0.1062 -0.1473 -0.1518 -0.2007]]\n","\n"," [[ 0.      0.5262  0.5495  0.5847  0.5846  0.5437  0.5261  0.5262]\n","  [ 0.     -0.1272 -0.1293 -0.1327 -0.1325 -0.1391 -0.1415 -0.1418]]\n","\n"," [[ 0.      0.5451  0.5379  0.5378  0.5015  0.4975  0.465   0.451 ]\n","  [ 0.     -0.1217 -0.1059 -0.1062 -0.1473 -0.1518 -0.2007 -0.2217]]\n","\n"," [[ 0.      0.5495  0.5847  0.5846  0.5437  0.5261  0.5262  0.4891]\n","  [ 0.     -0.1293 -0.1327 -0.1325 -0.1391 -0.1415 -0.1418 -0.168 ]]]\n","$trajectories.py pred_traj_rel[:5]:\n"," [[[-0.37 -0.36 -0.31 -0.25 -0.48 -0.65 -0.81 -0.73 -0.74 -0.72 -0.65\n","   -0.69]\n","  [ 0.18  0.42 -0.28  0.41  0.15  0.14  0.   -0.18 -0.42 -0.34 -0.63\n","   -0.38]]\n","\n"," [[-0.67 -0.67 -0.56 -0.37 -0.34 -0.59 -0.57 -0.57 -0.84 -0.77 -0.94\n","   -0.79]\n","  [ 0.16  0.1  -0.06 -0.04  0.01 -0.02 -0.1   0.24  0.02 -0.19 -0.05\n","   -0.25]]\n","\n"," [[-0.87 -0.74 -0.76 -0.73 -0.68 -0.72 -0.72 -0.66 -0.77 -0.68 -0.7\n","   -0.64]\n","  [-0.21 -0.22 -0.07 -0.21 -0.24 -0.17 -0.19 -0.16 -0.22 -0.25 -0.31\n","   -0.33]]\n","\n"," [[-0.76 -0.75 -0.77 -0.76 -0.69 -0.73 -0.75 -0.71 -0.74 -0.72 -0.76\n","   -0.83]\n","  [-0.09 -0.17 -0.06 -0.13 -0.01 -0.21 -0.15 -0.18 -0.19 -0.19 -0.38\n","   -0.4 ]]\n","\n"," [[ 0.    0.    0.    0.    0.    0.    0.   -0.12 -0.06  0.15  0.05\n","    0.03]\n","  [ 0.    0.    0.    0.    0.    0.    0.   -0.18 -0.17 -0.18 -0.13\n","    0.04]]]\n","$trajectories.py pred_traj_rel[-5:]:\n"," [[[ 0.5262  0.4891  0.4521  0.4521  0.5148  0.5304  0.539   0.5587\n","    0.5588  0.5809  0.6137  0.614 ]\n","  [-0.1418 -0.168  -0.1945 -0.1945 -0.2222 -0.2291 -0.2222 -0.2057\n","   -0.2058 -0.2028 -0.1991 -0.1988]]\n","\n"," [[ 0.451   0.451   0.5222  0.5299  0.5302  0.5299  0.5302  0.5664\n","    0.6025  0.5963  0.5809  0.5808]\n","  [-0.2217 -0.2215 -0.1654 -0.1592 -0.1696 -0.2122 -0.2122 -0.1494\n","   -0.0866 -0.1296 -0.2291 -0.2291]]\n","\n"," [[ 0.4891  0.4521  0.4521  0.5148  0.5304  0.539   0.5587  0.5588\n","    0.5809  0.6137  0.614   0.576 ]\n","  [-0.168  -0.1945 -0.1945 -0.2222 -0.2291 -0.2222 -0.2057 -0.2058\n","   -0.2028 -0.1991 -0.1988 -0.1697]]\n","\n"," [[ 0.451   0.5222  0.5299  0.5302  0.5299  0.5302  0.5664  0.6025\n","    0.5963  0.5809  0.5808  0.5372]\n","  [-0.2215 -0.1654 -0.1592 -0.1696 -0.2122 -0.2122 -0.1494 -0.0866\n","   -0.1296 -0.2291 -0.2291 -0.2148]]\n","\n"," [[ 0.4521  0.4521  0.5148  0.5304  0.539   0.5587  0.5588  0.5809\n","    0.6137  0.614   0.576   0.576 ]\n","  [-0.1945 -0.1945 -0.2222 -0.2291 -0.2222 -0.2057 -0.2058 -0.2028\n","   -0.1991 -0.1988 -0.1697 -0.1694]]]\n","$trajectories.py num_peds_in_seq: [2, 2, 3, 3, 3] ... [2, 2, 2, 2, 2]\n","$trajectories.py cum_start_idx: [0, 2, 4, 7, 10] ... [25499, 25501, 25503, 25505, 25507]\n","$trajectories.py self.seq_start_end.length: 2112 length of Batch: 33\n","$trajectories.py self.seq_start_end: [(0, 2), (2, 4), (4, 7), (7, 10), (10, 13), (13, 16), (16, 19), (19, 22), (22, 25), (25, 28), (28, 31), (31, 34), (34, 37), (37, 40), (40, 43), (43, 45), (45, 47), (47, 49), (49, 51), (51, 53), (53, 55), (55, 57), (57, 59), (59, 61), (61, 64), (64, 68), (68, 71), (71, 74), (74, 77), (77, 80), (80, 83), (83, 85), (85, 87), (87, 89), (89, 91), (91, 93), (93, 95), (95, 97), (97, 99), (99, 101), (101, 104), (104, 107), (107, 110), (110, 113), (113, 116), (116, 119), (119, 122), (122, 124), (124, 126), (126, 128), (128, 130), (130, 132), (132, 134), (134, 136), (136, 138), (138, 140), (140, 143), (143, 146), (146, 149), (149, 152), (152, 155), (155, 158), (158, 161), (161, 164)] \n","length: 64\n","$loader.py dset.obs_traj: torch.Size([25507, 2, 8])\n","$loader.py dset.pred_traj: torch.Size([25507, 2, 12])\n","$loader.py dset.obs_traj_rel: torch.Size([25507, 2, 8])\n","$loader.py dset.pred_traj_rel: torch.Size([25507, 2, 12])\n","$loader.py call DataLoader()\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'notf'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ce3619caa995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-ce3619caa995>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     '''\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# n_units = [32, 16, 32]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, comment, purge_step, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;31m# and recreated later as needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;31m# Create default bins for histograms, see generate_testdata.py in tensorflow/tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m_get_file_writer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             self.file_writer = FileWriter(self.log_dir, self.max_queue,\n\u001b[0;32m--> 256\u001b[0;31m                                           self.flush_secs, self.filename_suffix)\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_writers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_writer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpurge_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, log_dir, max_queue, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         self.event_writer = EventFileWriter(\n\u001b[0;32m---> 66\u001b[0;31m             log_dir, max_queue, flush_secs, filename_suffix)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_logdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/summary/writer/event_file_writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, max_queue_size, flush_secs, filename_suffix)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         self._file_name = (\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mLazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                     \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mload_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;31m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pywrap_tensorflow_internal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0;31m# This try catch logic is because there is no bazel equivalent for py_extension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Externally in opensource we must enable exceptions to load the shared object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"M96Ef-zq35QI","colab_type":"text"},"source":["# 程式碼範例"]},{"cell_type":"markdown","metadata":{"id":"zJRP9WnR38A6","colab_type":"text"},"source":["## init用法"]},{"cell_type":"code","metadata":{"id":"qBdhYEPQ2hbD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1596953708710,"user_tz":-480,"elapsed":1004,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}},"outputId":"b8c8062c-8025-48ee-9b76-e53ce8098ab3"},"source":["class A():\n","    def __init__(self, init_age):\n","        super().__init__()\n","        print('@__init__() => 我年龄是:',init_age)\n","        self.age = init_age\n"," \n","    def __call__(self, added_age):\n","        print('@__call__() => :',added_age)\n"," \n","        res = self.forward(added_age)\n","        return res\n"," \n","    def forward(self, input_):\n","        print('@forward() =>  函数被调用了')\n","        \n","        return input_ + self.age\n","print('对象初始化。。。。')\n","a = A(10)\n"," \n"," \n","input_param = a(2)\n","print(\"我现在的年龄是：\", input_param)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["对象初始化。。。。\n","@__init__() => 我年龄是: 10\n","@__call__() => : 2\n","@forward() =>  函数被调用了\n","我现在的年龄是： 12\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0f1TYEqrAV_h","colab_type":"text"},"source":["## Super.init()用法\n","\n","https://zhuanlan.zhihu.com/p/29763421\n"]},{"cell_type":"code","metadata":{"id":"ESY46VnaAYoE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"status":"ok","timestamp":1596973159333,"user_tz":-480,"elapsed":2135,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}},"outputId":"c13467ae-7f51-425b-c6b7-d0f63bc3deeb"},"source":["__metaclass__ = type  # 想用super就先加上\n","class A:\n","\n","    # 帶有兩個下劃線開頭的函數是聲明該屬性為專有，不能在類地外部被使用或直接訪問\n","    def __init__(self,name='from init',age=0):\n","        print(\"#屬於A的_init_()..., name:\",name)\n","        self.name =name\n","        self.age =age\n","\n","    def Me1(self,name_Me1='from Me1',age_Me1=1):\n","        print(self.name,self.age)\n","        print(name_Me1,age_Me1)\n","\n","class B(A):\n","\n","    def __init__(self,name_b='默认的name_b',age_b=5):\n","        print(\"#屬於B的_init_()..., name_b:\",name_b)\n","        '''\n","        這是對繼承自父類的屬性進行初始化。而且是用父類的初始化方法來初始化繼承的屬性。\n","        也就是說，子類繼承了父類的所有屬性和方法，父類屬性自然會用父類方法來進行初始化。\n","        '''\n","        super(B, self).__init__(name='在B类初始化时已修改',age=4)\n","        self.name_b = name_b\n","        self.age_b = age_b\n","\n","    def Me2(self,name_Me2='默认的name_Me2',age_Me2=7):\n","        print(self.name,self.age)\n","        print(self.name_b,self.age_b)\n","        print(name_Me2,age_Me2)\n","\n","\n","\n","print ('---------------1')\n","b = B('修改默认值',6)\n","print ('---------------2')\n","b.Me1()\n","print ('---------------3')\n","b.Me1('修改Me1',2)\n","print ('---------------4')\n","b.Me2()\n","print ('---------------5')\n","b.Me2('修改Me2',8)\n","print ('---------------6')\n","a = A('修改A中init',10)\n","a.Me1()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["---------------1\n","#屬於B的_init_()..., name_b: 修改默认值\n","#屬於A的_init_()..., name: 在B类初始化时已修改\n","---------------2\n","在B类初始化时已修改 4\n","from Me1 1\n","---------------3\n","在B类初始化时已修改 4\n","修改Me1 2\n","---------------4\n","在B类初始化时已修改 4\n","修改默认值 6\n","默认的name_Me2 7\n","---------------5\n","在B类初始化时已修改 4\n","修改默认值 6\n","修改Me2 8\n","---------------6\n","#屬於A的_init_()..., name: 修改A中init\n","修改A中init 10\n","from Me1 1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FkixogA6Eyo3","colab_type":"text"},"source":["## Dataloader範例\n","\n","https://morvanzhou.github.io/tutorials/machine-learning/torch/3-05-train-on-batch/"]}]}