{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Colab_Train.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"wm_JdO1Vu4nR","colab_type":"text"},"source":["## Colab & Drive環境設定"]},{"cell_type":"markdown","metadata":{"id":"9tGaekNkUp8_","colab_type":"text"},"source":["### Drive連結"]},{"cell_type":"code","metadata":{"id":"qnHuSwLjt8yG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596901601771,"user_tz":-480,"elapsed":23588,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}},"outputId":"d4c89827-ea6e-47b9-9135-e9558327a46a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eGynxt4w_yNB","colab_type":"text"},"source":["### 切換路徑"]},{"cell_type":"code","metadata":{"id":"ZFXiA5d01lx6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596901602583,"user_tz":-480,"elapsed":5818,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}},"outputId":"9e281964-88d5-4735-95fd-c34a803ffb64"},"source":["cd drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ErNUjf07nOun","colab_type":"text"},"source":["# 程式"]},{"cell_type":"markdown","metadata":{"id":"wgv0C_PPnP7i","colab_type":"text"},"source":["## 先從STGAT引用package"]},{"cell_type":"code","metadata":{"id":"rVGurTlra8jj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596901612276,"user_tz":-480,"elapsed":7961,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}}},"source":["import sys\n","sys.path.append('/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT')\n","\n","from STGAT import __init__\n","from STGAT import trajectories\n","from STGAT import loader\n","from STGAT import draw_trajectory\n","from STGAT import evaluate_model\n","\n","from STGAT import models\n","from STGAT import train\n","\n","from STGAT import utils"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"agU_GCXInYfF","colab_type":"text"},"source":["## 主程式"]},{"cell_type":"code","metadata":{"id":"lYIqdaAlgnln","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1596902659050,"user_tz":-480,"elapsed":167932,"user":{"displayName":"林忠毅","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghzb_sFyjB8Dre0pgGS3wRKu17cr6MsylwrdiyEtQ=s64","userId":"15173358958104466270"}},"outputId":"07b1611d-b249-476c-8256-95341f7baf6a"},"source":["import argparse\n","import logging\n","import os\n","import random\n","import shutil\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import STGAT.utils\n","from STGAT.loader import data_loader\n","from STGAT.models import TrajectoryGenerator\n","from STGAT.utils import (\n","    displacement_error,\n","    final_displacement_error,\n","    get_dset_path,\n","    int_tuple,\n","    l2_loss,\n","    relative_to_abs,\n",")\n","\n","import easydict\n","args = easydict.EasyDict({\n","        \"log_dir\": \"./\",\n","        \"dataset_name\": \"zara2\",\n","        \"delim\": \"\\t\",\n","        \"loader_num_workers\": 4,\n","        \"obs_len\": 8,\n","        \"pred_len\": 12,\n","        \"skip\": 1,\n","        \"seed\": 72,\n","        \"batch_size\":64,\n","        \"num_epochs\":400,\n","        \"noise_dim\":(16,),\n","        \"noise_type\":\"gaussian\",\n","        \"traj_lstm_input_size\":2,\n","        \"traj_lstm_hidden_size\":32,\n","        \"heads\":\"4,1\",\n","        \"hidden_units\":\"16\",\n","        \"graph_network_out_dims\":32,\n","        \"graph_lstm_hidden_size\":32,\n","        \"dropout\":0,\n","        \"alpha\": 0.2,\n","        \"lr\":1e-3,\n","        \"start_epoch\":0,\n","        \"best_k\":20,\n","        \"print_every\":10,\n","        \"use_gpu\":1,\n","        \"gpu_num\":\"0\",\n","        \"resume\":\"\"\n","})\n","\n","best_ade = 100\n","\n","\n","def main(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_num\n","    train_path = get_dset_path(args.dataset_name, \"train\")\n","    val_path = get_dset_path(args.dataset_name, \"test\")\n","\n","    logging.info(\"Initializing train dataset\")\n","    train_dset, train_loader = data_loader(args, train_path)\n","    logging.info(\"Initializing val dataset\")\n","    _, val_loader = data_loader(args, val_path)\n","\n","    writer = SummaryWriter()\n","\n","    n_units = (\n","        [args.traj_lstm_hidden_size]\n","        + [int(x) for x in args.hidden_units.strip().split(\",\")]\n","        + [args.graph_lstm_hidden_size]\n","    )\n","    n_heads = [int(x) for x in args.heads.strip().split(\",\")]\n","\n","    model = TrajectoryGenerator(\n","        obs_len=args.obs_len,\n","        pred_len=args.pred_len,\n","        traj_lstm_input_size=args.traj_lstm_input_size,\n","        traj_lstm_hidden_size=args.traj_lstm_hidden_size,\n","        n_units=n_units,\n","        n_heads=n_heads,\n","        graph_network_out_dims=args.graph_network_out_dims,\n","        dropout=args.dropout,\n","        alpha=args.alpha,\n","        graph_lstm_hidden_size=args.graph_lstm_hidden_size,\n","        noise_dim=args.noise_dim,\n","        noise_type=args.noise_type,\n","    )\n","    model.cuda()\n","    optimizer = optim.Adam(\n","        [\n","            {\"params\": model.traj_lstm_model.parameters(), \"lr\": 1e-2},\n","            {\"params\": model.traj_hidden2pos.parameters()},\n","            {\"params\": model.gatencoder.parameters(), \"lr\": 3e-2},\n","            {\"params\": model.graph_lstm_model.parameters(), \"lr\": 1e-2},\n","            {\"params\": model.traj_gat_hidden2pos.parameters()},\n","            {\"params\": model.pred_lstm_model.parameters()},\n","            {\"params\": model.pred_hidden2pos.parameters()},\n","        ],\n","        lr=args.lr,\n","    )\n","    global best_ade\n","    if args.resume:\n","        if os.path.isfile(args.resume):\n","            logging.info(\"Restoring from checkpoint {}\".format(args.resume))\n","            checkpoint = torch.load(args.resume)\n","            args.start_epoch = checkpoint[\"epoch\"]\n","            model.load_state_dict(checkpoint[\"state_dict\"])\n","            logging.info(\n","                \"=> loaded checkpoint '{}' (epoch {})\".format(\n","                    args.resume, checkpoint[\"epoch\"]\n","                )\n","            )\n","        else:\n","            logging.info(\"=> no checkpoint found at '{}'\".format(args.resume))\n","\n","    training_step = 1\n","    for epoch in range(args.start_epoch, args.num_epochs + 1):\n","        if epoch < 150:\n","            training_step = 1\n","        elif epoch < 250:\n","            training_step = 2\n","        else:\n","            if epoch == 250:\n","                for param_group in optimizer.param_groups:\n","                    param_group[\"lr\"] = 5e-3\n","            training_step = 3\n","        train(args, model, train_loader, optimizer, epoch, training_step, writer)\n","        if training_step == 3:\n","            ade = validate(args, model, val_loader, epoch, writer)\n","            is_best = ade < best_ade\n","            best_ade = min(ade, best_ade)\n","\n","            save_checkpoint(\n","                {\n","                    \"epoch\": epoch + 1,\n","                    \"state_dict\": model.state_dict(),\n","                    \"best_ade\": best_ade,\n","                    \"optimizer\": optimizer.state_dict(),\n","                },\n","                is_best,\n","                f\"./checkpoint/checkpoint{epoch}.pth.tar\",\n","            )\n","    writer.close()\n","\n","\n","def train(args, model, train_loader, optimizer, epoch, training_step, writer):\n","    losses = utils.AverageMeter(\"Loss\", \":.6f\")\n","    progress = utils.ProgressMeter(\n","        len(train_loader), [losses], prefix=\"Epoch: [{}]\".format(epoch)\n","    )\n","    model.train()\n","    for batch_idx, batch in enumerate(train_loader):\n","        batch = [tensor.cuda() for tensor in batch]\n","        (\n","            obs_traj,\n","            pred_traj_gt,\n","            obs_traj_rel,\n","            pred_traj_gt_rel,\n","            non_linear_ped,\n","            loss_mask,\n","            seq_start_end,\n","        ) = batch\n","        optimizer.zero_grad()\n","        loss = torch.zeros(1).to(pred_traj_gt)\n","        l2_loss_rel = []\n","        loss_mask = loss_mask[:, args.obs_len :]\n","\n","        if training_step == 1 or training_step == 2:\n","            model_input = obs_traj_rel\n","            pred_traj_fake_rel = model(\n","                model_input, obs_traj, seq_start_end, 1, training_step\n","            )\n","            l2_loss_rel.append(\n","                l2_loss(pred_traj_fake_rel, model_input, loss_mask, mode=\"raw\")\n","            )\n","        else:\n","            model_input = torch.cat((obs_traj_rel, pred_traj_gt_rel), dim=0)\n","            for _ in range(args.best_k):\n","                pred_traj_fake_rel = model(model_input, obs_traj, seq_start_end, 0)\n","                l2_loss_rel.append(\n","                    l2_loss(\n","                        pred_traj_fake_rel,\n","                        model_input[-args.pred_len :],\n","                        loss_mask,\n","                        mode=\"raw\",\n","                    )\n","                )\n","\n","        l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n","        l2_loss_rel = torch.stack(l2_loss_rel, dim=1)\n","        for start, end in seq_start_end.data:\n","            _l2_loss_rel = torch.narrow(l2_loss_rel, 0, start, end - start)\n","            _l2_loss_rel = torch.sum(_l2_loss_rel, dim=0)  # [20]\n","            _l2_loss_rel = torch.min(_l2_loss_rel) / (\n","                (pred_traj_fake_rel.shape[0]) * (end - start)\n","            )\n","            l2_loss_sum_rel += _l2_loss_rel\n","\n","        loss += l2_loss_sum_rel\n","        losses.update(loss.item(), obs_traj.shape[1])\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx % args.print_every == 0:\n","            progress.display(batch_idx)\n","    writer.add_scalar(\"train_loss\", losses.avg, epoch)\n","\n","\n","def validate(args, model, val_loader, epoch, writer):\n","    ade = utils.AverageMeter(\"ADE\", \":.6f\")\n","    fde = utils.AverageMeter(\"FDE\", \":.6f\")\n","    progress = utils.ProgressMeter(len(val_loader), [ade, fde], prefix=\"Test: \")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for i, batch in enumerate(val_loader):\n","            batch = [tensor.cuda() for tensor in batch]\n","            (\n","                obs_traj,\n","                pred_traj_gt,\n","                obs_traj_rel,\n","                pred_traj_gt_rel,\n","                non_linear_ped,\n","                loss_mask,\n","                seq_start_end,\n","            ) = batch\n","            loss_mask = loss_mask[:, args.obs_len :]\n","            pred_traj_fake_rel = model(obs_traj_rel, obs_traj, seq_start_end)\n","\n","            pred_traj_fake_rel_predpart = pred_traj_fake_rel[-args.pred_len :]\n","            pred_traj_fake = relative_to_abs(pred_traj_fake_rel_predpart, obs_traj[-1])\n","            ade_, fde_ = cal_ade_fde(pred_traj_gt, pred_traj_fake)\n","            ade_ = ade_ / (obs_traj.shape[1] * args.pred_len)\n","\n","            fde_ = fde_ / (obs_traj.shape[1])\n","            ade.update(ade_, obs_traj.shape[1])\n","            fde.update(fde_, obs_traj.shape[1])\n","\n","            if i % args.print_every == 0:\n","                progress.display(i)\n","\n","        logging.info(\n","            \" * ADE  {ade.avg:.3f} FDE  {fde.avg:.3f}\".format(ade=ade, fde=fde)\n","        )\n","        writer.add_scalar(\"val_ade\", ade.avg, epoch)\n","    return ade.avg\n","\n","\n","def cal_ade_fde(pred_traj_gt, pred_traj_fake):\n","    ade = displacement_error(pred_traj_fake, pred_traj_gt)\n","    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1])\n","    return ade, fde\n","\n","\n","def save_checkpoint(state, is_best, filename=\"checkpoint.pth.tar\"):\n","    if is_best:\n","        torch.save(state, filename)\n","        logging.info(\"-------------- lower ade ----------------\")\n","        shutil.copyfile(filename, \"model_best.pth.tar\")\n","\n","\n","if __name__ == \"__main__\":\n","    #args = parser.parse_args()\n","    utils.set_logger(os.path.join(args.log_dir, \"train.log\"))\n","    checkpoint_dir = \"./checkpoint\"\n","    if os.path.exists(checkpoint_dir) is False:\n","        os.mkdir(checkpoint_dir)\n","    main(args)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Initializing train dataset\n","Initializing val dataset\n","Epoch: [0][ 0/33]\tLoss 16.100201 (16.100201)\n","Epoch: [0][10/33]\tLoss 7.083632 (7.616940)\n","Epoch: [0][20/33]\tLoss 2.829256 (4.570406)\n","Epoch: [0][30/33]\tLoss 3.561652 (3.100152)\n","Epoch: [1][ 0/33]\tLoss 3.312482 (3.312482)\n","Epoch: [1][10/33]\tLoss 1.782539 (2.286602)\n","Epoch: [1][20/33]\tLoss 0.847081 (1.391889)\n","Epoch: [1][30/33]\tLoss 1.265034 (1.032633)\n","Epoch: [2][ 0/33]\tLoss 1.199269 (1.199269)\n","Epoch: [2][10/33]\tLoss 0.633799 (0.845751)\n","Epoch: [2][20/33]\tLoss 0.431246 (0.589664)\n","Epoch: [2][30/33]\tLoss 0.486424 (0.470015)\n","Epoch: [3][ 0/33]\tLoss 0.625495 (0.625495)\n","Epoch: [3][10/33]\tLoss 0.377817 (0.435576)\n","Epoch: [3][20/33]\tLoss 0.268975 (0.330516)\n","Epoch: [3][30/33]\tLoss 0.302700 (0.280947)\n","Epoch: [4][ 0/33]\tLoss 0.364747 (0.364747)\n","Epoch: [4][10/33]\tLoss 0.230663 (0.267225)\n","Epoch: [4][20/33]\tLoss 0.196201 (0.226490)\n","Epoch: [4][30/33]\tLoss 0.225594 (0.199682)\n","Epoch: [5][ 0/33]\tLoss 0.247603 (0.247603)\n","Epoch: [5][10/33]\tLoss 0.188450 (0.195492)\n","Epoch: [5][20/33]\tLoss 0.148667 (0.167348)\n","Epoch: [5][30/33]\tLoss 0.160465 (0.150269)\n","Epoch: [6][ 0/33]\tLoss 0.205249 (0.205249)\n","Epoch: [6][10/33]\tLoss 0.132486 (0.151146)\n","Epoch: [6][20/33]\tLoss 0.114718 (0.130723)\n","Epoch: [6][30/33]\tLoss 0.137749 (0.119964)\n","Epoch: [7][ 0/33]\tLoss 0.195005 (0.195005)\n","Epoch: [7][10/33]\tLoss 0.104219 (0.125398)\n","Epoch: [7][20/33]\tLoss 0.096066 (0.113446)\n","Epoch: [7][30/33]\tLoss 0.114489 (0.102848)\n","Epoch: [8][ 0/33]\tLoss 0.165034 (0.165034)\n","Epoch: [8][10/33]\tLoss 0.100124 (0.108755)\n","Epoch: [8][20/33]\tLoss 0.079415 (0.095155)\n","Epoch: [8][30/33]\tLoss 0.096767 (0.085823)\n","Epoch: [9][ 0/33]\tLoss 0.151339 (0.151339)\n","Epoch: [9][10/33]\tLoss 0.074797 (0.094605)\n","Epoch: [9][20/33]\tLoss 0.069927 (0.083895)\n","Epoch: [9][30/33]\tLoss 0.086420 (0.074879)\n","Epoch: [10][ 0/33]\tLoss 0.123785 (0.123785)\n","Epoch: [10][10/33]\tLoss 0.070396 (0.081385)\n","Epoch: [10][20/33]\tLoss 0.061572 (0.074306)\n","Epoch: [10][30/33]\tLoss 0.080984 (0.065577)\n","Epoch: [11][ 0/33]\tLoss 0.125031 (0.125031)\n","Epoch: [11][10/33]\tLoss 0.069503 (0.076889)\n","Epoch: [11][20/33]\tLoss 0.054309 (0.068712)\n","Epoch: [11][30/33]\tLoss 0.071589 (0.059813)\n","Epoch: [12][ 0/33]\tLoss 0.102976 (0.102976)\n","Epoch: [12][10/33]\tLoss 0.054901 (0.067194)\n","Epoch: [12][20/33]\tLoss 0.048561 (0.061073)\n","Epoch: [12][30/33]\tLoss 0.064899 (0.053148)\n","Epoch: [13][ 0/33]\tLoss 0.098140 (0.098140)\n","Epoch: [13][10/33]\tLoss 0.057899 (0.062840)\n","Epoch: [13][20/33]\tLoss 0.044502 (0.056578)\n","Epoch: [13][30/33]\tLoss 0.062388 (0.048182)\n","Epoch: [14][ 0/33]\tLoss 0.094363 (0.094363)\n","Epoch: [14][10/33]\tLoss 0.055551 (0.061246)\n","Epoch: [14][20/33]\tLoss 0.041441 (0.054010)\n","Epoch: [14][30/33]\tLoss 0.055804 (0.045366)\n","Epoch: [15][ 0/33]\tLoss 0.088105 (0.088105)\n","Epoch: [15][10/33]\tLoss 0.051757 (0.058064)\n","Epoch: [15][20/33]\tLoss 0.036191 (0.050753)\n","Epoch: [15][30/33]\tLoss 0.052355 (0.042505)\n","Epoch: [16][ 0/33]\tLoss 0.081090 (0.081090)\n","Epoch: [16][10/33]\tLoss 0.051532 (0.053110)\n","Epoch: [16][20/33]\tLoss 0.031755 (0.045796)\n","Epoch: [16][30/33]\tLoss 0.048321 (0.038718)\n","Epoch: [17][ 0/33]\tLoss 0.075401 (0.075401)\n","Epoch: [17][10/33]\tLoss 0.045349 (0.049132)\n","Epoch: [17][20/33]\tLoss 0.029474 (0.042457)\n","Epoch: [17][30/33]\tLoss 0.047994 (0.035453)\n","Epoch: [18][ 0/33]\tLoss 0.078821 (0.078821)\n","Epoch: [18][10/33]\tLoss 0.040929 (0.044746)\n","Epoch: [18][20/33]\tLoss 0.027014 (0.038384)\n","Epoch: [18][30/33]\tLoss 0.044299 (0.033145)\n","Epoch: [19][ 0/33]\tLoss 0.082979 (0.082979)\n","Epoch: [19][10/33]\tLoss 0.040830 (0.044137)\n","Epoch: [19][20/33]\tLoss 0.024302 (0.036504)\n","Epoch: [19][30/33]\tLoss 0.042798 (0.031398)\n","Epoch: [20][ 0/33]\tLoss 0.074817 (0.074817)\n","Epoch: [20][10/33]\tLoss 0.039810 (0.041161)\n","Epoch: [20][20/33]\tLoss 0.024483 (0.034687)\n","Epoch: [20][30/33]\tLoss 0.038053 (0.029910)\n","Epoch: [21][ 0/33]\tLoss 0.068859 (0.068859)\n","Epoch: [21][10/33]\tLoss 0.037018 (0.039460)\n","Epoch: [21][20/33]\tLoss 0.021316 (0.032547)\n","Epoch: [21][30/33]\tLoss 0.033856 (0.028142)\n","Epoch: [22][ 0/33]\tLoss 0.068435 (0.068435)\n","Epoch: [22][10/33]\tLoss 0.035472 (0.035847)\n","Epoch: [22][20/33]\tLoss 0.020668 (0.029743)\n","Epoch: [22][30/33]\tLoss 0.033322 (0.026079)\n","Epoch: [23][ 0/33]\tLoss 0.067331 (0.067331)\n","Epoch: [23][10/33]\tLoss 0.032314 (0.034641)\n","Epoch: [23][20/33]\tLoss 0.019643 (0.028948)\n","Epoch: [23][30/33]\tLoss 0.030424 (0.025524)\n","Epoch: [24][ 0/33]\tLoss 0.069210 (0.069210)\n","Epoch: [24][10/33]\tLoss 0.030904 (0.032044)\n","Epoch: [24][20/33]\tLoss 0.017749 (0.025149)\n","Epoch: [24][30/33]\tLoss 0.026191 (0.022340)\n","Epoch: [25][ 0/33]\tLoss 0.066504 (0.066504)\n","Epoch: [25][10/33]\tLoss 0.028177 (0.031206)\n","Epoch: [25][20/33]\tLoss 0.017545 (0.025116)\n","Epoch: [25][30/33]\tLoss 0.027925 (0.022207)\n","Epoch: [26][ 0/33]\tLoss 0.062699 (0.062699)\n","Epoch: [26][10/33]\tLoss 0.027772 (0.028860)\n","Epoch: [26][20/33]\tLoss 0.016799 (0.023511)\n","Epoch: [26][30/33]\tLoss 0.025942 (0.021074)\n","Epoch: [27][ 0/33]\tLoss 0.065403 (0.065403)\n","Epoch: [27][10/33]\tLoss 0.025595 (0.028128)\n","Epoch: [27][20/33]\tLoss 0.015892 (0.021933)\n","Epoch: [27][30/33]\tLoss 0.024340 (0.019679)\n","Epoch: [28][ 0/33]\tLoss 0.062134 (0.062134)\n","Epoch: [28][10/33]\tLoss 0.026341 (0.027871)\n","Epoch: [28][20/33]\tLoss 0.014221 (0.021688)\n","Epoch: [28][30/33]\tLoss 0.024072 (0.019419)\n","Epoch: [29][ 0/33]\tLoss 0.061249 (0.061249)\n","Epoch: [29][10/33]\tLoss 0.025550 (0.025319)\n","Epoch: [29][20/33]\tLoss 0.013376 (0.020045)\n","Epoch: [29][30/33]\tLoss 0.023483 (0.018411)\n","Epoch: [30][ 0/33]\tLoss 0.061328 (0.061328)\n","Epoch: [30][10/33]\tLoss 0.022085 (0.024477)\n","Epoch: [30][20/33]\tLoss 0.012893 (0.018949)\n","Epoch: [30][30/33]\tLoss 0.022896 (0.017572)\n","Epoch: [31][ 0/33]\tLoss 0.059072 (0.059072)\n","Epoch: [31][10/33]\tLoss 0.021339 (0.022900)\n","Epoch: [31][20/33]\tLoss 0.012087 (0.017580)\n","Epoch: [31][30/33]\tLoss 0.021276 (0.016210)\n","Epoch: [32][ 0/33]\tLoss 0.054720 (0.054720)\n","Epoch: [32][10/33]\tLoss 0.019914 (0.022482)\n","Epoch: [32][20/33]\tLoss 0.011779 (0.016899)\n","Epoch: [32][30/33]\tLoss 0.019989 (0.015711)\n","Epoch: [33][ 0/33]\tLoss 0.058528 (0.058528)\n","Epoch: [33][10/33]\tLoss 0.020996 (0.021911)\n","Epoch: [33][20/33]\tLoss 0.011412 (0.016328)\n","Epoch: [33][30/33]\tLoss 0.019777 (0.015233)\n","Epoch: [34][ 0/33]\tLoss 0.053880 (0.053880)\n","Epoch: [34][10/33]\tLoss 0.019691 (0.020862)\n","Epoch: [34][20/33]\tLoss 0.010950 (0.015706)\n","Epoch: [34][30/33]\tLoss 0.018027 (0.014438)\n","Epoch: [35][ 0/33]\tLoss 0.055540 (0.055540)\n","Epoch: [35][10/33]\tLoss 0.018436 (0.020220)\n","Epoch: [35][20/33]\tLoss 0.010804 (0.015305)\n","Epoch: [35][30/33]\tLoss 0.019191 (0.014315)\n","Epoch: [36][ 0/33]\tLoss 0.055073 (0.055073)\n","Epoch: [36][10/33]\tLoss 0.016729 (0.019336)\n","Epoch: [36][20/33]\tLoss 0.010805 (0.014368)\n","Epoch: [36][30/33]\tLoss 0.018352 (0.013157)\n","Epoch: [37][ 0/33]\tLoss 0.055059 (0.055059)\n","Epoch: [37][10/33]\tLoss 0.017678 (0.020487)\n","Epoch: [37][20/33]\tLoss 0.010933 (0.014913)\n","Epoch: [37][30/33]\tLoss 0.018492 (0.013623)\n","Epoch: [38][ 0/33]\tLoss 0.054628 (0.054628)\n","Epoch: [38][10/33]\tLoss 0.017309 (0.019751)\n","Epoch: [38][20/33]\tLoss 0.010595 (0.014218)\n","Epoch: [38][30/33]\tLoss 0.017950 (0.012997)\n","Epoch: [39][ 0/33]\tLoss 0.056267 (0.056267)\n","Epoch: [39][10/33]\tLoss 0.017178 (0.020761)\n","Epoch: [39][20/33]\tLoss 0.010777 (0.013983)\n","Epoch: [39][30/33]\tLoss 0.017000 (0.012418)\n","Epoch: [40][ 0/33]\tLoss 0.053257 (0.053257)\n","Epoch: [40][10/33]\tLoss 0.016104 (0.019133)\n","Epoch: [40][20/33]\tLoss 0.010491 (0.013274)\n","Epoch: [40][30/33]\tLoss 0.015505 (0.011859)\n","Epoch: [41][ 0/33]\tLoss 0.053360 (0.053360)\n","Epoch: [41][10/33]\tLoss 0.016032 (0.019184)\n","Epoch: [41][20/33]\tLoss 0.010445 (0.013006)\n","Epoch: [41][30/33]\tLoss 0.015000 (0.011500)\n","Epoch: [42][ 0/33]\tLoss 0.050896 (0.050896)\n","Epoch: [42][10/33]\tLoss 0.014628 (0.018498)\n","Epoch: [42][20/33]\tLoss 0.010777 (0.012617)\n","Epoch: [42][30/33]\tLoss 0.015069 (0.010784)\n","Epoch: [43][ 0/33]\tLoss 0.050027 (0.050027)\n","Epoch: [43][10/33]\tLoss 0.014416 (0.018328)\n","Epoch: [43][20/33]\tLoss 0.010425 (0.012372)\n","Epoch: [43][30/33]\tLoss 0.012697 (0.010646)\n","Epoch: [44][ 0/33]\tLoss 0.048413 (0.048413)\n","Epoch: [44][10/33]\tLoss 0.014003 (0.018111)\n","Epoch: [44][20/33]\tLoss 0.009447 (0.011742)\n","Epoch: [44][30/33]\tLoss 0.012027 (0.009692)\n","Epoch: [45][ 0/33]\tLoss 0.049843 (0.049843)\n","Epoch: [45][10/33]\tLoss 0.014254 (0.018703)\n","Epoch: [45][20/33]\tLoss 0.009352 (0.012013)\n","Epoch: [45][30/33]\tLoss 0.012728 (0.009731)\n","Epoch: [46][ 0/33]\tLoss 0.044796 (0.044796)\n","Epoch: [46][10/33]\tLoss 0.014186 (0.018130)\n","Epoch: [46][20/33]\tLoss 0.009644 (0.011852)\n","Epoch: [46][30/33]\tLoss 0.010773 (0.009480)\n","Epoch: [47][ 0/33]\tLoss 0.045557 (0.045557)\n","Epoch: [47][10/33]\tLoss 0.013838 (0.018768)\n","Epoch: [47][20/33]\tLoss 0.009080 (0.011763)\n","Epoch: [47][30/33]\tLoss 0.010862 (0.009291)\n","Epoch: [48][ 0/33]\tLoss 0.043431 (0.043431)\n","Epoch: [48][10/33]\tLoss 0.013544 (0.018183)\n","Epoch: [48][20/33]\tLoss 0.007731 (0.010969)\n","Epoch: [48][30/33]\tLoss 0.010606 (0.008580)\n","Epoch: [49][ 0/33]\tLoss 0.039916 (0.039916)\n","Epoch: [49][10/33]\tLoss 0.012838 (0.017175)\n","Epoch: [49][20/33]\tLoss 0.007202 (0.010409)\n","Epoch: [49][30/33]\tLoss 0.011158 (0.008360)\n","Epoch: [50][ 0/33]\tLoss 0.038280 (0.038280)\n","Epoch: [50][10/33]\tLoss 0.012465 (0.017058)\n","Epoch: [50][20/33]\tLoss 0.007134 (0.010255)\n","Epoch: [50][30/33]\tLoss 0.009822 (0.008109)\n","Epoch: [51][ 0/33]\tLoss 0.038865 (0.038865)\n","Epoch: [51][10/33]\tLoss 0.012562 (0.016547)\n","Epoch: [51][20/33]\tLoss 0.007244 (0.010066)\n","Epoch: [51][30/33]\tLoss 0.009497 (0.007951)\n","Epoch: [52][ 0/33]\tLoss 0.039304 (0.039304)\n","Epoch: [52][10/33]\tLoss 0.011353 (0.016951)\n","Epoch: [52][20/33]\tLoss 0.006205 (0.009990)\n","Epoch: [52][30/33]\tLoss 0.010123 (0.007633)\n","Epoch: [53][ 0/33]\tLoss 0.034851 (0.034851)\n","Epoch: [53][10/33]\tLoss 0.011050 (0.018578)\n","Epoch: [53][20/33]\tLoss 0.006022 (0.010255)\n","Epoch: [53][30/33]\tLoss 0.009706 (0.007724)\n","Epoch: [54][ 0/33]\tLoss 0.035304 (0.035304)\n","Epoch: [54][10/33]\tLoss 0.010537 (0.018032)\n","Epoch: [54][20/33]\tLoss 0.006165 (0.010138)\n","Epoch: [54][30/33]\tLoss 0.009726 (0.007561)\n","Epoch: [55][ 0/33]\tLoss 0.035319 (0.035319)\n","Epoch: [55][10/33]\tLoss 0.010538 (0.017072)\n","Epoch: [55][20/33]\tLoss 0.005703 (0.009712)\n","Epoch: [55][30/33]\tLoss 0.009129 (0.007347)\n","Epoch: [56][ 0/33]\tLoss 0.034382 (0.034382)\n","Epoch: [56][10/33]\tLoss 0.010040 (0.016866)\n","Epoch: [56][20/33]\tLoss 0.005490 (0.009319)\n","Epoch: [56][30/33]\tLoss 0.009625 (0.007026)\n","Epoch: [57][ 0/33]\tLoss 0.032116 (0.032116)\n","Epoch: [57][10/33]\tLoss 0.009265 (0.016455)\n","Epoch: [57][20/33]\tLoss 0.005001 (0.009188)\n","Epoch: [57][30/33]\tLoss 0.008707 (0.006957)\n","Epoch: [58][ 0/33]\tLoss 0.030922 (0.030922)\n","Epoch: [58][10/33]\tLoss 0.009201 (0.015571)\n","Epoch: [58][20/33]\tLoss 0.005245 (0.008703)\n","Epoch: [58][30/33]\tLoss 0.008563 (0.006560)\n","Epoch: [59][ 0/33]\tLoss 0.032296 (0.032296)\n","Epoch: [59][10/33]\tLoss 0.008720 (0.016747)\n","Epoch: [59][20/33]\tLoss 0.004896 (0.009222)\n","Epoch: [59][30/33]\tLoss 0.008436 (0.006810)\n","Epoch: [60][ 0/33]\tLoss 0.030249 (0.030249)\n","Epoch: [60][10/33]\tLoss 0.008247 (0.016428)\n","Epoch: [60][20/33]\tLoss 0.004712 (0.008821)\n","Epoch: [60][30/33]\tLoss 0.008056 (0.006530)\n","Epoch: [61][ 0/33]\tLoss 0.028213 (0.028213)\n","Epoch: [61][10/33]\tLoss 0.008475 (0.015295)\n","Epoch: [61][20/33]\tLoss 0.004316 (0.008363)\n","Epoch: [61][30/33]\tLoss 0.007216 (0.006267)\n","Epoch: [62][ 0/33]\tLoss 0.028113 (0.028113)\n","Epoch: [62][10/33]\tLoss 0.006766 (0.014020)\n","Epoch: [62][20/33]\tLoss 0.004555 (0.007915)\n","Epoch: [62][30/33]\tLoss 0.008259 (0.006025)\n","Epoch: [63][ 0/33]\tLoss 0.028976 (0.028976)\n","Epoch: [63][10/33]\tLoss 0.008215 (0.015406)\n","Epoch: [63][20/33]\tLoss 0.005051 (0.009177)\n","Epoch: [63][30/33]\tLoss 0.007888 (0.006817)\n","Epoch: [64][ 0/33]\tLoss 0.029756 (0.029756)\n","Epoch: [64][10/33]\tLoss 0.007949 (0.014831)\n","Epoch: [64][20/33]\tLoss 0.004479 (0.008342)\n","Epoch: [64][30/33]\tLoss 0.008440 (0.006201)\n","Epoch: [65][ 0/33]\tLoss 0.028181 (0.028181)\n","Epoch: [65][10/33]\tLoss 0.007574 (0.015372)\n","Epoch: [65][20/33]\tLoss 0.004842 (0.008617)\n","Epoch: [65][30/33]\tLoss 0.008194 (0.006437)\n","Epoch: [66][ 0/33]\tLoss 0.029421 (0.029421)\n","Epoch: [66][10/33]\tLoss 0.007372 (0.014677)\n","Epoch: [66][20/33]\tLoss 0.004020 (0.008244)\n","Epoch: [66][30/33]\tLoss 0.008078 (0.006130)\n","Epoch: [67][ 0/33]\tLoss 0.028768 (0.028768)\n","Epoch: [67][10/33]\tLoss 0.006930 (0.014292)\n","Epoch: [67][20/33]\tLoss 0.004386 (0.007835)\n","Epoch: [67][30/33]\tLoss 0.007561 (0.005836)\n","Epoch: [68][ 0/33]\tLoss 0.026651 (0.026651)\n","Epoch: [68][10/33]\tLoss 0.007767 (0.014162)\n","Epoch: [68][20/33]\tLoss 0.004158 (0.008032)\n","Epoch: [68][30/33]\tLoss 0.007760 (0.005978)\n","Epoch: [69][ 0/33]\tLoss 0.024445 (0.024445)\n","Epoch: [69][10/33]\tLoss 0.006441 (0.013094)\n","Epoch: [69][20/33]\tLoss 0.004235 (0.007594)\n","Epoch: [69][30/33]\tLoss 0.006963 (0.005695)\n","Epoch: [70][ 0/33]\tLoss 0.025335 (0.025335)\n","Epoch: [70][10/33]\tLoss 0.005821 (0.012396)\n","Epoch: [70][20/33]\tLoss 0.003735 (0.007145)\n","Epoch: [70][30/33]\tLoss 0.007954 (0.005459)\n","Epoch: [71][ 0/33]\tLoss 0.025824 (0.025824)\n","Epoch: [71][10/33]\tLoss 0.006601 (0.012598)\n","Epoch: [71][20/33]\tLoss 0.003881 (0.007858)\n","Epoch: [71][30/33]\tLoss 0.008062 (0.005957)\n","Epoch: [72][ 0/33]\tLoss 0.024905 (0.024905)\n","Epoch: [72][10/33]\tLoss 0.005658 (0.011918)\n","Epoch: [72][20/33]\tLoss 0.003950 (0.007176)\n","Epoch: [72][30/33]\tLoss 0.007065 (0.005394)\n","Epoch: [73][ 0/33]\tLoss 0.025332 (0.025332)\n","Epoch: [73][10/33]\tLoss 0.006073 (0.012011)\n","Epoch: [73][20/33]\tLoss 0.003521 (0.007107)\n","Epoch: [73][30/33]\tLoss 0.007450 (0.005278)\n","Epoch: [74][ 0/33]\tLoss 0.025322 (0.025322)\n","Epoch: [74][10/33]\tLoss 0.005113 (0.011681)\n","Epoch: [74][20/33]\tLoss 0.003520 (0.007226)\n","Epoch: [74][30/33]\tLoss 0.007490 (0.005462)\n","Epoch: [75][ 0/33]\tLoss 0.023472 (0.023472)\n","Epoch: [75][10/33]\tLoss 0.005179 (0.010478)\n","Epoch: [75][20/33]\tLoss 0.003789 (0.006786)\n","Epoch: [75][30/33]\tLoss 0.007070 (0.005229)\n","Epoch: [76][ 0/33]\tLoss 0.023596 (0.023596)\n","Epoch: [76][10/33]\tLoss 0.004922 (0.010355)\n","Epoch: [76][20/33]\tLoss 0.003170 (0.006655)\n","Epoch: [76][30/33]\tLoss 0.007577 (0.005184)\n","Epoch: [77][ 0/33]\tLoss 0.023366 (0.023366)\n","Epoch: [77][10/33]\tLoss 0.004748 (0.010398)\n","Epoch: [77][20/33]\tLoss 0.003230 (0.006725)\n","Epoch: [77][30/33]\tLoss 0.007538 (0.005241)\n","Epoch: [78][ 0/33]\tLoss 0.023257 (0.023257)\n","Epoch: [78][10/33]\tLoss 0.004670 (0.010121)\n","Epoch: [78][20/33]\tLoss 0.002976 (0.006252)\n","Epoch: [78][30/33]\tLoss 0.007532 (0.004784)\n","Epoch: [79][ 0/33]\tLoss 0.022376 (0.022376)\n","Epoch: [79][10/33]\tLoss 0.004624 (0.009533)\n","Epoch: [79][20/33]\tLoss 0.003077 (0.006378)\n","Epoch: [79][30/33]\tLoss 0.007736 (0.005032)\n","Epoch: [80][ 0/33]\tLoss 0.023799 (0.023799)\n","Epoch: [80][10/33]\tLoss 0.005208 (0.009674)\n","Epoch: [80][20/33]\tLoss 0.002730 (0.005944)\n","Epoch: [80][30/33]\tLoss 0.006704 (0.004611)\n","Epoch: [81][ 0/33]\tLoss 0.021383 (0.021383)\n","Epoch: [81][10/33]\tLoss 0.004562 (0.009413)\n","Epoch: [81][20/33]\tLoss 0.003053 (0.006473)\n","Epoch: [81][30/33]\tLoss 0.007557 (0.005061)\n","Epoch: [82][ 0/33]\tLoss 0.023143 (0.023143)\n","Epoch: [82][10/33]\tLoss 0.004256 (0.008986)\n","Epoch: [82][20/33]\tLoss 0.002745 (0.005956)\n","Epoch: [82][30/33]\tLoss 0.006888 (0.004648)\n","Epoch: [83][ 0/33]\tLoss 0.021831 (0.021831)\n","Epoch: [83][10/33]\tLoss 0.004435 (0.008834)\n","Epoch: [83][20/33]\tLoss 0.002646 (0.005797)\n","Epoch: [83][30/33]\tLoss 0.006926 (0.004529)\n","Epoch: [84][ 0/33]\tLoss 0.022480 (0.022480)\n","Epoch: [84][10/33]\tLoss 0.003974 (0.009189)\n","Epoch: [84][20/33]\tLoss 0.003010 (0.006379)\n","Epoch: [84][30/33]\tLoss 0.007302 (0.004964)\n","Epoch: [85][ 0/33]\tLoss 0.021707 (0.021707)\n","Epoch: [85][10/33]\tLoss 0.004116 (0.008339)\n","Epoch: [85][20/33]\tLoss 0.002591 (0.005698)\n","Epoch: [85][30/33]\tLoss 0.007559 (0.004555)\n","Epoch: [86][ 0/33]\tLoss 0.020579 (0.020579)\n","Epoch: [86][10/33]\tLoss 0.004140 (0.008453)\n","Epoch: [86][20/33]\tLoss 0.002855 (0.006326)\n","Epoch: [86][30/33]\tLoss 0.007725 (0.004986)\n","Epoch: [87][ 0/33]\tLoss 0.021770 (0.021770)\n","Epoch: [87][10/33]\tLoss 0.003538 (0.007921)\n","Epoch: [87][20/33]\tLoss 0.002534 (0.005335)\n","Epoch: [87][30/33]\tLoss 0.006173 (0.004209)\n","Epoch: [88][ 0/33]\tLoss 0.020575 (0.020575)\n","Epoch: [88][10/33]\tLoss 0.003832 (0.008194)\n","Epoch: [88][20/33]\tLoss 0.002433 (0.005459)\n","Epoch: [88][30/33]\tLoss 0.006824 (0.004312)\n","Epoch: [89][ 0/33]\tLoss 0.020763 (0.020763)\n","Epoch: [89][10/33]\tLoss 0.004009 (0.008163)\n","Epoch: [89][20/33]\tLoss 0.002673 (0.006185)\n","Epoch: [89][30/33]\tLoss 0.007243 (0.004844)\n","Epoch: [90][ 0/33]\tLoss 0.019861 (0.019861)\n","Epoch: [90][10/33]\tLoss 0.003755 (0.006846)\n","Epoch: [90][20/33]\tLoss 0.002575 (0.004322)\n","Epoch: [90][30/33]\tLoss 0.005362 (0.003465)\n","Epoch: [91][ 0/33]\tLoss 0.018295 (0.018295)\n","Epoch: [91][10/33]\tLoss 0.004225 (0.008187)\n","Epoch: [91][20/33]\tLoss 0.002609 (0.006392)\n","Epoch: [91][30/33]\tLoss 0.007797 (0.005086)\n","Epoch: [92][ 0/33]\tLoss 0.020726 (0.020726)\n","Epoch: [92][10/33]\tLoss 0.003505 (0.007020)\n","Epoch: [92][20/33]\tLoss 0.002468 (0.004911)\n","Epoch: [92][30/33]\tLoss 0.005890 (0.003889)\n","Epoch: [93][ 0/33]\tLoss 0.017663 (0.017663)\n","Epoch: [93][10/33]\tLoss 0.003605 (0.007166)\n","Epoch: [93][20/33]\tLoss 0.002474 (0.005264)\n","Epoch: [93][30/33]\tLoss 0.006290 (0.004162)\n","Epoch: [94][ 0/33]\tLoss 0.018351 (0.018351)\n","Epoch: [94][10/33]\tLoss 0.003546 (0.006428)\n","Epoch: [94][20/33]\tLoss 0.002422 (0.004587)\n","Epoch: [94][30/33]\tLoss 0.005942 (0.003730)\n","Epoch: [95][ 0/33]\tLoss 0.017414 (0.017414)\n","Epoch: [95][10/33]\tLoss 0.003499 (0.006577)\n","Epoch: [95][20/33]\tLoss 0.002625 (0.004791)\n","Epoch: [95][30/33]\tLoss 0.005466 (0.003804)\n","Epoch: [96][ 0/33]\tLoss 0.017519 (0.017519)\n","Epoch: [96][10/33]\tLoss 0.003331 (0.006278)\n","Epoch: [96][20/33]\tLoss 0.002606 (0.004761)\n","Epoch: [96][30/33]\tLoss 0.005215 (0.003849)\n","Epoch: [97][ 0/33]\tLoss 0.016679 (0.016679)\n","Epoch: [97][10/33]\tLoss 0.003390 (0.005986)\n","Epoch: [97][20/33]\tLoss 0.002786 (0.004782)\n","Epoch: [97][30/33]\tLoss 0.005010 (0.003885)\n","Epoch: [98][ 0/33]\tLoss 0.016642 (0.016642)\n","Epoch: [98][10/33]\tLoss 0.003368 (0.005402)\n","Epoch: [98][20/33]\tLoss 0.002556 (0.004272)\n","Epoch: [98][30/33]\tLoss 0.004966 (0.003529)\n","Epoch: [99][ 0/33]\tLoss 0.015749 (0.015749)\n","Epoch: [99][10/33]\tLoss 0.003052 (0.005322)\n","Epoch: [99][20/33]\tLoss 0.003377 (0.004351)\n","Epoch: [99][30/33]\tLoss 0.003998 (0.003543)\n","Epoch: [100][ 0/33]\tLoss 0.014679 (0.014679)\n","Epoch: [100][10/33]\tLoss 0.003148 (0.005299)\n","Epoch: [100][20/33]\tLoss 0.003192 (0.004501)\n","Epoch: [100][30/33]\tLoss 0.004447 (0.003755)\n","Epoch: [101][ 0/33]\tLoss 0.016405 (0.016405)\n","Epoch: [101][10/33]\tLoss 0.003214 (0.004979)\n","Epoch: [101][20/33]\tLoss 0.003801 (0.004439)\n","Epoch: [101][30/33]\tLoss 0.004040 (0.003711)\n","Epoch: [102][ 0/33]\tLoss 0.016409 (0.016409)\n","Epoch: [102][10/33]\tLoss 0.003344 (0.005208)\n","Epoch: [102][20/33]\tLoss 0.004469 (0.004887)\n","Epoch: [102][30/33]\tLoss 0.004277 (0.004047)\n","Epoch: [103][ 0/33]\tLoss 0.016078 (0.016078)\n","Epoch: [103][10/33]\tLoss 0.002587 (0.004445)\n","Epoch: [103][20/33]\tLoss 0.002973 (0.003602)\n","Epoch: [103][30/33]\tLoss 0.003328 (0.003079)\n","Epoch: [104][ 0/33]\tLoss 0.014841 (0.014841)\n","Epoch: [104][10/33]\tLoss 0.002732 (0.004288)\n","Epoch: [104][20/33]\tLoss 0.003626 (0.003743)\n","Epoch: [104][30/33]\tLoss 0.003668 (0.003154)\n","Epoch: [105][ 0/33]\tLoss 0.013719 (0.013719)\n","Epoch: [105][10/33]\tLoss 0.003185 (0.004582)\n","Epoch: [105][20/33]\tLoss 0.005533 (0.004913)\n","Epoch: [105][30/33]\tLoss 0.003917 (0.004167)\n","Epoch: [106][ 0/33]\tLoss 0.014553 (0.014553)\n","Epoch: [106][10/33]\tLoss 0.002757 (0.004161)\n","Epoch: [106][20/33]\tLoss 0.004173 (0.003974)\n","Epoch: [106][30/33]\tLoss 0.003501 (0.003372)\n","Epoch: [107][ 0/33]\tLoss 0.014097 (0.014097)\n","Epoch: [107][10/33]\tLoss 0.002860 (0.004114)\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-3f17d8c10e5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-3f17d8c10e5e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0mparam_group\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mtraining_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtraining_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0made\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-3f17d8c10e5e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, train_loader, optimizer, epoch, training_step, writer)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_traj_rel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             pred_traj_fake_rel = model(\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_traj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_start_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             )\n\u001b[1;32m    182\u001b[0m             l2_loss_rel.append(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, obs_traj_rel, obs_traj_pos, seq_start_end, teacher_forcing_ratio, training_step)\u001b[0m\n\u001b[1;32m    202\u001b[0m     ):\n\u001b[1;32m    203\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_traj_rel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mtraj_lstm_h_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_lstm_c_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden_traj_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mgraph_lstm_h_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_lstm_c_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden_graph_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mpred_traj_rel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/PhD/程式/TrajectoryPrediction/STGAT/STGAT/models.py\u001b[0m in \u001b[0;36minit_hidden_traj_lstm\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    169\u001b[0m         return (\n\u001b[1;32m    170\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraj_lstm_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraj_lstm_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         )\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}